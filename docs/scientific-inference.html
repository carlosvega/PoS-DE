<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Scientific Inference | Applied Philosophy of Science and Data Ethics</title>
  <meta name="description" content="This class book gathers the contents addressed in the course Applied Philosophy of Science and Data Ethics from the Master of Data Science at the University of Luxembourg. This class book will introduce basic philosophical and scientific concepts supported by examples and discussion." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Scientific Inference | Applied Philosophy of Science and Data Ethics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This class book gathers the contents addressed in the course Applied Philosophy of Science and Data Ethics from the Master of Data Science at the University of Luxembourg. This class book will introduce basic philosophical and scientific concepts supported by examples and discussion." />
  <meta name="github-repo" content="carlosvega/PoS-DE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Scientific Inference | Applied Philosophy of Science and Data Ethics" />
  
  <meta name="twitter:description" content="This class book gathers the contents addressed in the course Applied Philosophy of Science and Data Ethics from the Master of Data Science at the University of Luxembourg. This class book will introduce basic philosophical and scientific concepts supported by examples and discussion." />
  

<meta name="author" content="Dr. Carlos Vega" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="scientific-goals-methods-and-knowledge.html"/>
<link rel="next" href="empirical-practices.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-79429674-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-79429674-2');
</script>


<script type="text/javascript">
mattcrump=1;
</script>
 -->


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><strong>APPLIED PHILOSOPHY OF SCIENCE </br>AND DATA ETHICS</strong></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-presentation"><i class="fa fa-check"></i>Course presentation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-at-ul"><i class="fa fa-check"></i>Course at UL</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#target-audience"><i class="fa fa-check"></i>Target audience</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-objectives"><i class="fa fa-check"></i>Course objectives</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-structure"><i class="fa fa-check"></i>Course structure</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-course"><i class="fa fa-check"></i>About this course</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#roadmap-for-instructors"><i class="fa fa-check"></i>Roadmap for instructors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#disclaimer"><i class="fa fa-check"></i>Disclaimer</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the author</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-class-book"><i class="fa fa-check"></i>About this class book</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributing-to-the-book"><i class="fa fa-check"></i>Contributing to the book</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html"><i class="fa fa-check"></i><b>1</b> Scientific Goals, Methods and Knowledge</a>
<ul>
<li class="chapter" data-level="1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#what-is-science"><i class="fa fa-check"></i><b>1.1</b> What is Science?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#scientific-goals-and-knowledge"><i class="fa fa-check"></i><b>1.1.1</b> Scientific Goals and Knowledge</a>
<ul>
<li class="chapter" data-level="1.1.1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#data-information-and-knowledge"><i class="fa fa-check"></i><b>1.1.1.1</b> Data, information and knowledge</a></li>
</ul></li>
<li class="chapter" data-level="1.1.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#what-is-philosophy-of-science"><i class="fa fa-check"></i><b>1.1.2</b> What is Philosophy of Science?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#sci-method"><i class="fa fa-check"></i><b>1.2</b> The scientific method</a></li>
<li class="chapter" data-level="1.3" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#methodology"><i class="fa fa-check"></i><b>1.3</b> Methodology</a></li>
<li class="chapter" data-level="1.4" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#examples"><i class="fa fa-check"></i><b>1.4</b> Examples</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#neptune-vulcan"><i class="fa fa-check"></i><b>1.4.1</b> Neptune and Vulcan</a></li>
<li class="chapter" data-level="1.4.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#michelson-morley"><i class="fa fa-check"></i><b>1.4.2</b> The most famous “failed” experiment</a></li>
<li class="chapter" data-level="1.4.3" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#eddington-expeditions"><i class="fa fa-check"></i><b>1.4.3</b> Eddington expeditions</a></li>
<li class="chapter" data-level="1.4.4" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#smoke-debate"><i class="fa fa-check"></i><b>1.4.4</b> The smoke debate</a></li>
<li class="chapter" data-level="1.4.5" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#kekulés-dream"><i class="fa fa-check"></i><b>1.4.5</b> Kekulé’s dream</a></li>
<li class="chapter" data-level="1.4.6" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#why-most-published-research-findings-are-false"><i class="fa fa-check"></i><b>1.4.6</b> Why Most Published Research Findings Are False</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scientific-inference.html"><a href="scientific-inference.html"><i class="fa fa-check"></i><b>2</b> Scientific Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scientific-inference.html"><a href="scientific-inference.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="scientific-inference.html"><a href="scientific-inference.html#types-of-inferences"><i class="fa fa-check"></i><b>2.2</b> Types of inferences</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="scientific-inference.html"><a href="scientific-inference.html#deduction"><i class="fa fa-check"></i><b>2.2.1</b> Deduction and Induction</a></li>
<li class="chapter" data-level="2.2.2" data-path="scientific-inference.html"><a href="scientific-inference.html#modus"><i class="fa fa-check"></i><b>2.2.2</b> Modus ponens and Modus tollens</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="scientific-inference.html"><a href="scientific-inference.html#problem-induction"><i class="fa fa-check"></i><b>2.3</b> The problem(s) of induction</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="scientific-inference.html"><a href="scientific-inference.html#david-humes-problem-of-induction"><i class="fa fa-check"></i><b>2.3.1</b> David Hume’s Problem of Induction</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="scientific-inference.html"><a href="scientific-inference.html#the-hypothetico-deductive-method"><i class="fa fa-check"></i><b>2.4</b> The Hypothetico-deductive Method</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="scientific-inference.html"><a href="scientific-inference.html#a-good-hypothesis"><i class="fa fa-check"></i><b>2.4.1</b> A good hypothesis</a></li>
<li class="chapter" data-level="2.4.2" data-path="scientific-inference.html"><a href="scientific-inference.html#falsification"><i class="fa fa-check"></i><b>2.4.2</b> Falsification</a></li>
<li class="chapter" data-level="2.4.3" data-path="scientific-inference.html"><a href="scientific-inference.html#confirmation"><i class="fa fa-check"></i><b>2.4.3</b> Confirmation</a></li>
<li class="chapter" data-level="2.4.4" data-path="scientific-inference.html"><a href="scientific-inference.html#bayesian-inference"><i class="fa fa-check"></i><b>2.4.4</b> Beyond the Hypothetico-Deductive Method: Bayesian Inference and the Logic of Uncertainty</a>
<ul>
<li class="chapter" data-level="2.4.4.1" data-path="scientific-inference.html"><a href="scientific-inference.html#limitations-of-the-hd-method-in-probabilistic-contexts"><i class="fa fa-check"></i><b>2.4.4.1</b> Limitations of the HD method in probabilistic contexts</a></li>
<li class="chapter" data-level="2.4.4.2" data-path="scientific-inference.html"><a href="scientific-inference.html#bayesian-epistemology-and-conditionalization"><i class="fa fa-check"></i><b>2.4.4.2</b> Bayesian Epistemology and Conditionalization</a></li>
<li class="chapter" data-level="2.4.4.3" data-path="scientific-inference.html"><a href="scientific-inference.html#bayesian-vs-frequentist-views"><i class="fa fa-check"></i><b>2.4.4.3</b> Bayesian vs Frequentist Views</a></li>
<li class="chapter" data-level="2.4.4.4" data-path="scientific-inference.html"><a href="scientific-inference.html#bayesian-inference-and-the-problem-of-induction"><i class="fa fa-check"></i><b>2.4.4.4</b> Bayesian Inference and the Problem of Induction</a></li>
<li class="chapter" data-level="2.4.4.5" data-path="scientific-inference.html"><a href="scientific-inference.html#underdetermination-and-bayesian-model-selection"><i class="fa fa-check"></i><b>2.4.4.5</b> Underdetermination and Bayesian Model Selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="scientific-inference.html"><a href="scientific-inference.html#other-types-of-inference"><i class="fa fa-check"></i><b>2.5</b> Other types of inference</a></li>
<li class="chapter" data-level="2.6" data-path="scientific-inference.html"><a href="scientific-inference.html#non-monotonic-logic-and-defeasible-reasoning"><i class="fa fa-check"></i><b>2.6</b> Non-Monotonic logic and defeasible reasoning</a></li>
<li class="chapter" data-level="2.7" data-path="scientific-inference.html"><a href="scientific-inference.html#explanation"><i class="fa fa-check"></i><b>2.7</b> Explanation</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="scientific-inference.html"><a href="scientific-inference.html#explanation-and-causality"><i class="fa fa-check"></i><b>2.7.1</b> Explanation and causality</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="scientific-inference.html"><a href="scientific-inference.html#examples-1"><i class="fa fa-check"></i><b>2.8</b> Examples</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="scientific-inference.html"><a href="scientific-inference.html#semmelweis"><i class="fa fa-check"></i><b>2.8.1</b> The problem is in your hands!</a>
<ul>
<li class="chapter" data-level="2.8.1.1" data-path="scientific-inference.html"><a href="scientific-inference.html#how-a-hypothesis-is-tested"><i class="fa fa-check"></i><b>2.8.1.1</b> How a hypothesis is tested</a></li>
</ul></li>
<li class="chapter" data-level="2.8.2" data-path="scientific-inference.html"><a href="scientific-inference.html#wason"><i class="fa fa-check"></i><b>2.8.2</b> Wason selection task</a></li>
<li class="chapter" data-level="2.8.3" data-path="scientific-inference.html"><a href="scientific-inference.html#u.s.a.-presidents"><i class="fa fa-check"></i><b>2.8.3</b> U.S.A. Presidents</a></li>
<li class="chapter" data-level="2.8.4" data-path="scientific-inference.html"><a href="scientific-inference.html#yersinia-pestis"><i class="fa fa-check"></i><b>2.8.4</b> Yersinia pestis</a></li>
<li class="chapter" data-level="2.8.5" data-path="scientific-inference.html"><a href="scientific-inference.html#risks-of-induction-and-non-epistemic-values-in-ml"><i class="fa fa-check"></i><b>2.8.5</b> Risks of induction and non-epistemic values in ML</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="empirical-practices.html"><a href="empirical-practices.html"><i class="fa fa-check"></i><b>3</b> Empirical Practices and Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="empirical-practices.html"><a href="empirical-practices.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="empirical-practices.html"><a href="empirical-practices.html#experiments"><i class="fa fa-check"></i><b>3.2</b> Experiments</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="empirical-practices.html"><a href="empirical-practices.html#observational-studies"><i class="fa fa-check"></i><b>3.2.1</b> Observational studies</a>
<ul>
<li class="chapter" data-level="3.2.1.1" data-path="empirical-practices.html"><a href="empirical-practices.html#natural-experiments"><i class="fa fa-check"></i><b>3.2.1.1</b> Natural experiments</a></li>
<li class="chapter" data-level="3.2.1.2" data-path="empirical-practices.html"><a href="empirical-practices.html#observability"><i class="fa fa-check"></i><b>3.2.1.2</b> Observability</a></li>
<li class="chapter" data-level="3.2.1.3" data-path="empirical-practices.html"><a href="empirical-practices.html#indicators"><i class="fa fa-check"></i><b>3.2.1.3</b> Indicators</a></li>
<li class="chapter" data-level="3.2.1.4" data-path="empirical-practices.html"><a href="empirical-practices.html#data-and-evidence"><i class="fa fa-check"></i><b>3.2.1.4</b> Data and Evidence</a></li>
</ul></li>
<li class="chapter" data-level="3.2.2" data-path="empirical-practices.html"><a href="empirical-practices.html#field-laboratory-and-simulation-experiments"><i class="fa fa-check"></i><b>3.2.2</b> Field, laboratory and simulation experiments</a>
<ul>
<li class="chapter" data-level="3.2.2.1" data-path="empirical-practices.html"><a href="empirical-practices.html#field-experiments"><i class="fa fa-check"></i><b>3.2.2.1</b> Field experiments</a></li>
<li class="chapter" data-level="3.2.2.2" data-path="empirical-practices.html"><a href="empirical-practices.html#laboratory-experiments"><i class="fa fa-check"></i><b>3.2.2.2</b> Laboratory experiments</a></li>
<li class="chapter" data-level="3.2.2.3" data-path="empirical-practices.html"><a href="empirical-practices.html#simulation-experiments"><i class="fa fa-check"></i><b>3.2.2.3</b> Simulation experiments</a></li>
</ul></li>
<li class="chapter" data-level="3.2.3" data-path="empirical-practices.html"><a href="empirical-practices.html#summary-of-the-different-experiments"><i class="fa fa-check"></i><b>3.2.3</b> Summary of the different experiments</a></li>
<li class="chapter" data-level="3.2.4" data-path="empirical-practices.html"><a href="empirical-practices.html#how-to-evaluate-experiment-success"><i class="fa fa-check"></i><b>3.2.4</b> How to evaluate experiment success</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="empirical-practices.html"><a href="empirical-practices.html#scientific-models"><i class="fa fa-check"></i><b>3.3</b> Scientific models</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="empirical-practices.html"><a href="empirical-practices.html#the-models-of-the-atom"><i class="fa fa-check"></i><b>3.3.1</b> The models of the atom</a></li>
<li class="chapter" data-level="3.3.2" data-path="empirical-practices.html"><a href="empirical-practices.html#the-models-of-benzene"><i class="fa fa-check"></i><b>3.3.2</b> The models of benzene</a></li>
<li class="chapter" data-level="3.3.3" data-path="empirical-practices.html"><a href="empirical-practices.html#models-as-analogies"><i class="fa fa-check"></i><b>3.3.3</b> Models as analogies</a></li>
<li class="chapter" data-level="3.3.4" data-path="empirical-practices.html"><a href="empirical-practices.html#differences-between-models-and-experiments"><i class="fa fa-check"></i><b>3.3.4</b> Differences between Models and Experiments</a></li>
<li class="chapter" data-level="3.3.5" data-path="empirical-practices.html"><a href="empirical-practices.html#what-makes-a-good-model"><i class="fa fa-check"></i><b>3.3.5</b> What makes a good model?</a></li>
<li class="chapter" data-level="3.3.6" data-path="empirical-practices.html"><a href="empirical-practices.html#models-as-mirrors"><i class="fa fa-check"></i><b>3.3.6</b> Models as mirrors</a></li>
<li class="chapter" data-level="3.3.7" data-path="empirical-practices.html"><a href="empirical-practices.html#models-as-isolations"><i class="fa fa-check"></i><b>3.3.7</b> Models as isolations</a></li>
<li class="chapter" data-level="3.3.8" data-path="empirical-practices.html"><a href="empirical-practices.html#summary-of-the-different-model-views"><i class="fa fa-check"></i><b>3.3.8</b> Summary of the different model views</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="empirical-practices.html"><a href="empirical-practices.html#a-tool-for-scientific-reasoning"><i class="fa fa-check"></i><b>3.4</b> A tool for scientific reasoning</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="empirical-practices.html"><a href="empirical-practices.html#a-case-of-negative-evidence.-gene-analysis-upsets-turtle-theory"><i class="fa fa-check"></i><b>3.4.1</b> A Case of Negative Evidence. “Gene Analysis Upsets Turtle Theory”</a></li>
<li class="chapter" data-level="3.4.2" data-path="empirical-practices.html"><a href="empirical-practices.html#a-case-of-positive-evidence.-new-view-of-the-mind-gives-unconscious-an-expanded-role"><i class="fa fa-check"></i><b>3.4.2</b> A Case of Positive Evidence. “New View of the Mind Gives Unconscious an Expanded Role”</a></li>
<li class="chapter" data-level="3.4.3" data-path="empirical-practices.html"><a href="empirical-practices.html#inconclusive-data.-was-that-a-greenhouse-effect-it-depends-on-your-theory"><i class="fa fa-check"></i><b>3.4.3</b> Inconclusive Data. “Was That a Greenhouse Effect? It Depends on Your Theory”</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="empirical-practices.html"><a href="empirical-practices.html#examples-2"><i class="fa fa-check"></i><b>3.5</b> Examples</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="empirical-practices.html"><a href="empirical-practices.html#willow"><i class="fa fa-check"></i><b>3.5.1</b> Willow tree experiment</a></li>
<li class="chapter" data-level="3.5.2" data-path="empirical-practices.html"><a href="empirical-practices.html#john-snow"><i class="fa fa-check"></i><b>3.5.2</b> 1854 Broad Street cholera outbreak</a></li>
<li class="chapter" data-level="3.5.3" data-path="empirical-practices.html"><a href="empirical-practices.html#causal-models"><i class="fa fa-check"></i><b>3.5.3</b> Causal models: Estimating treatment effect in the pressence of a confounder</a>
<ul>
<li class="chapter" data-level="3.5.3.1" data-path="empirical-practices.html"><a href="empirical-practices.html#backdoor-criterion"><i class="fa fa-check"></i><b>3.5.3.1</b> Backdoor criterion</a></li>
</ul></li>
<li class="chapter" data-level="3.5.4" data-path="empirical-practices.html"><a href="empirical-practices.html#causal-models-overestimation"><i class="fa fa-check"></i><b>3.5.4</b> Causal models: Detecting an overestimation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stats-abuse.html"><a href="stats-abuse.html"><i class="fa fa-check"></i><b>4</b> Experimental Control and Statistical Abuse</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stats-abuse.html"><a href="stats-abuse.html#stats-overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="stats-abuse.html"><a href="stats-abuse.html#the-smoke-debate---part-ii"><i class="fa fa-check"></i><b>4.2</b> The smoke debate - Part II</a></li>
<li class="chapter" data-level="4.3" data-path="stats-abuse.html"><a href="stats-abuse.html#experimental-control"><i class="fa fa-check"></i><b>4.3</b> Experimental Control</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="stats-abuse.html"><a href="stats-abuse.html#other-experimental-control-techniques"><i class="fa fa-check"></i><b>4.3.1</b> Other experimental control techniques</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="stats-abuse.html"><a href="stats-abuse.html#randomised-control-trials"><i class="fa fa-check"></i><b>4.4</b> Randomised Control Trials</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="stats-abuse.html"><a href="stats-abuse.html#origins-of-rcts"><i class="fa fa-check"></i><b>4.4.1</b> Origins of RCTs</a></li>
<li class="chapter" data-level="4.4.2" data-path="stats-abuse.html"><a href="stats-abuse.html#validity"><i class="fa fa-check"></i><b>4.4.2</b> Validity</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="stats-abuse.html"><a href="stats-abuse.html#cross-validation-in-machine-learning"><i class="fa fa-check"></i><b>4.5</b> Cross-validation in Machine Learning</a></li>
<li class="chapter" data-level="4.6" data-path="stats-abuse.html"><a href="stats-abuse.html#surrogates-proxies-confounders-and-colliders"><i class="fa fa-check"></i><b>4.6</b> Surrogates, Proxies, Confounders and Colliders</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="stats-abuse.html"><a href="stats-abuse.html#surrogates-and-proxies"><i class="fa fa-check"></i><b>4.6.1</b> Surrogates and Proxies</a></li>
<li class="chapter" data-level="4.6.2" data-path="stats-abuse.html"><a href="stats-abuse.html#confounding-factors"><i class="fa fa-check"></i><b>4.6.2</b> Confounding factors</a></li>
<li class="chapter" data-level="4.6.3" data-path="stats-abuse.html"><a href="stats-abuse.html#collider-bias-and-m-bias"><i class="fa fa-check"></i><b>4.6.3</b> Collider bias and M-bias</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="stats-abuse.html"><a href="stats-abuse.html#data-is-not-enough"><i class="fa fa-check"></i><b>4.7</b> Data alone is not enough</a></li>
<li class="chapter" data-level="4.8" data-path="stats-abuse.html"><a href="stats-abuse.html#examples-3"><i class="fa fa-check"></i><b>4.8</b> Examples</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="stats-abuse.html"><a href="stats-abuse.html#covid-israel"><i class="fa fa-check"></i><b>4.8.1</b> Covid-19: How can efficacy versus severe disease be strong when 60% of hospitalized are vaccinated?</a></li>
<li class="chapter" data-level="4.8.2" data-path="stats-abuse.html"><a href="stats-abuse.html#viz-hurricane"><i class="fa fa-check"></i><b>4.8.2</b> Misinterpretations of hurricane forecast maps</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html"><i class="fa fa-check"></i><b>5</b> Ethics and Responsibility</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#overview-2"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#morality-and-ethics"><i class="fa fa-check"></i><b>5.2</b> Morality and Ethics</a></li>
<li class="chapter" data-level="5.3" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#ethical-frameworks"><i class="fa fa-check"></i><b>5.3</b> Ethical Frameworks</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#consequentialism"><i class="fa fa-check"></i><b>5.3.1</b> Consequentialism</a></li>
<li class="chapter" data-level="5.3.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#deontology"><i class="fa fa-check"></i><b>5.3.2</b> Deontology</a></li>
<li class="chapter" data-level="5.3.3" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#virtues"><i class="fa fa-check"></i><b>5.3.3</b> Virtues</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#values-in-science"><i class="fa fa-check"></i><b>5.4</b> Values in Science</a></li>
<li class="chapter" data-level="5.5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#ethics-in-action"><i class="fa fa-check"></i><b>5.5</b> Ethics in action</a></li>
<li class="chapter" data-level="5.6" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#data-ethics"><i class="fa fa-check"></i><b>5.6</b> Data Ethics</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#origins"><i class="fa fa-check"></i><b>5.6.1</b> Origins</a></li>
<li class="chapter" data-level="5.6.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#what-are-data-ethics"><i class="fa fa-check"></i><b>5.6.2</b> What are data ethics?</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#gdpr"><i class="fa fa-check"></i><b>5.7</b> General Data Protection Regulation (GDPR)</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#personal-data"><i class="fa fa-check"></i><b>5.7.1</b> Personal data</a>
<ul>
<li class="chapter" data-level="5.7.1.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#special-category-data"><i class="fa fa-check"></i><b>5.7.1.1</b> Special Category Data</a></li>
<li class="chapter" data-level="5.7.1.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#childrens-data"><i class="fa fa-check"></i><b>5.7.1.2</b> Children’s data</a></li>
</ul></li>
<li class="chapter" data-level="5.7.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#principles-gdpr"><i class="fa fa-check"></i><b>5.7.2</b> Principles GDPR</a>
<ul>
<li class="chapter" data-level="5.7.2.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#lawfulness-fairness-and-transparency"><i class="fa fa-check"></i><b>5.7.2.1</b> Lawfulness, Fairness and Transparency</a></li>
<li class="chapter" data-level="5.7.2.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#purpose-limitation"><i class="fa fa-check"></i><b>5.7.2.2</b> Purpose Limitation</a></li>
<li class="chapter" data-level="5.7.2.3" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#data-minimization"><i class="fa fa-check"></i><b>5.7.2.3</b> Data Minimization</a></li>
<li class="chapter" data-level="5.7.2.4" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#storage-limitation"><i class="fa fa-check"></i><b>5.7.2.4</b> Storage Limitation</a></li>
<li class="chapter" data-level="5.7.2.5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#integrity-and-confidentiality"><i class="fa fa-check"></i><b>5.7.2.5</b> Integrity and Confidentiality</a></li>
<li class="chapter" data-level="5.7.2.6" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#accountability"><i class="fa fa-check"></i><b>5.7.2.6</b> Accountability</a></li>
</ul></li>
<li class="chapter" data-level="5.7.3" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#controllers-processors-and-subjects."><i class="fa fa-check"></i><b>5.7.3</b> Controllers, Processors and Subjects.</a></li>
<li class="chapter" data-level="5.7.4" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#rights-of-the-data-subject"><i class="fa fa-check"></i><b>5.7.4</b> Rights of the data subject</a></li>
<li class="chapter" data-level="5.7.5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#international-transfers"><i class="fa fa-check"></i><b>5.7.5</b> International transfers</a></li>
<li class="chapter" data-level="5.7.6" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#data-breaches"><i class="fa fa-check"></i><b>5.7.6</b> Data breaches</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#ethic-examples"><i class="fa fa-check"></i><b>5.8</b> Examples</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#a-genocide-incited-on-facebook"><i class="fa fa-check"></i><b>5.8.1</b> A Genocide Incited on Facebook</a></li>
<li class="chapter" data-level="5.8.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#the-theranos-scandal---a-drop-of-blood-for-hundreds-of-different-assays"><i class="fa fa-check"></i><b>5.8.2</b> The Theranos scandal - A drop of blood for hundreds of different assays</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="wont-fix.html"><a href="wont-fix.html"><i class="fa fa-check"></i><b>6</b> Extra Material</a>
<ul>
<li class="chapter" data-level="6.1" data-path="wont-fix.html"><a href="wont-fix.html#history-of-science"><i class="fa fa-check"></i><b>6.1</b> History of science</a></li>
<li class="chapter" data-level="6.2" data-path="wont-fix.html"><a href="wont-fix.html#theory-relatedness-of-observations"><i class="fa fa-check"></i><b>6.2</b> Theory-relatedness of observations</a></li>
<li class="chapter" data-level="6.3" data-path="wont-fix.html"><a href="wont-fix.html#thomas-kuhn-and-the-idea-of-scientific-revolutions"><i class="fa fa-check"></i><b>6.3</b> Thomas Kuhn and the idea of scientific revolutions</a></li>
<li class="chapter" data-level="6.4" data-path="wont-fix.html"><a href="wont-fix.html#gettier-problems"><i class="fa fa-check"></i><b>6.4</b> Gettier problems</a></li>
<li class="chapter" data-level="6.5" data-path="wont-fix.html"><a href="wont-fix.html#realism"><i class="fa fa-check"></i><b>6.5</b> Realism and anti-realism</a></li>
<li class="chapter" data-level="6.6" data-path="wont-fix.html"><a href="wont-fix.html#pessimistic-meta-induction"><i class="fa fa-check"></i><b>6.6</b> Pessimistic meta-induction</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Built with Bookdown + RStudio</a></li>
<li><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Philosophy of Science and Data Ethics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="scientific-inference" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Scientific Inference<a href="scientific-inference.html#scientific-inference" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<blockquote>
<p>“Knowledge can be communicated, but not wisdom. One can find it, live it, be fortified by it, do wonders through it, but one cannot communicate and teach it.” — Hermann Hesse</p>
</blockquote>
<div id="overview" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Overview<a href="scientific-inference.html#overview" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One of the fundamental questions of the philosophy of science is “How can we obtain knowledge as opposed to mere belief or opinion?” <span class="citation">(<a href="#ref-ladyman2012understanding">Ladyman 2012</a>)</span>. Humans have a natural ability to conjecture and spot relationships about the world, <em>jumping</em> from hypotheses to conclusions. The scientific attitude is to keep such <em>jumps</em> under control and use a well defined procedure to arrive to a conclusion from an hypothesis. This chapter taughts how conclusions can be reached from known facts in different ways. For this, a sound basis of logic is needed to understand more complex concepts from this course. The reader will tackle deductive and inductive arguments and link them to data science applications. With this the reader will be equipped to tackle other topics of scientific inference such as the problem of induction, the Hypothetico-deductive method and Falsificationism.</p>
<figure style="text-align: center">
<video width="500"
  frameborder="0" controls>
<source src="videos/sagan.mp4" type="video/mp4">
</video>
<figcaption>
Clip from the television series Cosmos: A Personal Voyage, presented by Carl Sagan. </br> The clip can also be found in <a href="https://youtu.be/_GVhzZCt4yI?">YouTube</a>.
</figcaption>
</figure>
<blockquote>
<p>But our sun is only one of a billion-trillion stars within the observable universe. And those countless suns all obey natural laws some of which are already known to us. How did we discover that there are such laws? If we lived on a planet where nothing ever changed, there wouldn’t be much to do, there’d be nothing to figure out. There’d be no impetus for science. And if we lived in an unpredictable world where things changed in random or very complex ways, we wouldn’t be able to figure things out. And again, there’d be no such thing as science. But we live in an in between universe where things change alright, but according to patterns, rules, or as we call them, laws of nature. If I throw a stick up in the air, it always falls down. If the sun sets in the west, it always rises again the next morning in the east. And so it’s possible to figure things out. We can do science. And with it we can improve our lives. — Carl Sagan</p>
</blockquote>
<div class="simplebox">
<div data-latex="">
<p><strong>Course objectives</strong></p>
</div>
<p>A foundational grasp of logic is essential to understand scientific inference. This chapter content supports objectives 3, 4 and 6 through examples that motivate in-class debate (e.g., Hume, Popper, Hempel) with a narrative that moves from initial naïve support of theories, to a deeper reflection of their weaknesses and later emphasis on the relevant pieces that affect the practice of data science.</p>
</div>
</div>
<div id="types-of-inferences" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Types of inferences<a href="scientific-inference.html#types-of-inferences" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Most scientific conclusions are uncanny at first glance and difficult to believe without more information and proper explanations about them (e.g. expansion of the universe, electromagnetism, etc.). How do scientists reach such unlikely conclusions? An inference is the act of reaching a conclusion from known facts but there are multiple types as we will see below.</p>
<div id="deduction" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Deduction and Induction<a href="scientific-inference.html#deduction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A good argument is one whose conclusions follow from its premises. But how do we tell if the conclusion is a consequence of its premises? Is often assumed that as long as the premises are valid, the conclusions will be valid too. This does not imply that the conclusion is also true. The premises might not be true, but if they are true, then the conclusion will also be true. However, is the truth of the premises always <em>necessarily sufficient</em> for the truth of the conclusions? Logicians distinguish between deductive and inductive inference. <span class="citation">(<a href="#ref-sep-abduction">Douven 2021</a>)</span></p>
<p>Below there is an example of a deductive inference with two premises followed by a conclusion.</p>
<pre><code>All Frenchmen like cheese
Loubin is a Frenchman
------------------------------
Therefore, Loubin likes cheese</code></pre>
<pre><code>All As are Bs
a is an A
--------------------
Therefore, a is a B</code></pre>
<p>We call an inference <em>deductive</em> whenever the conclusion <em>necessarily</em> follows from the premises. <strong>The truth of the premises <em>guarantees</em> the truth of the conclusion.</strong> Or in other words, what is inferred is <em>necessarily</em> true if the premises from which it is inferred are true. We call this type of inferences <em>explicative</em>.</p>
<p>Not all inferences are deductive. For example:</p>
<pre><code>The first five eggs in the box were good.
All the eggs have the same best-before date stamped on them.
------------------------------------------------------------
Therefore, the next egg will be good too.</code></pre>
<p>In this case, the premises do not entail the conclusion. Even if the previous eggs were good, it is possible that the next egg will be rotten. In this case, is logically possible for the premises to be true and yet the conclusion false. We call this type of inferences <em>inductive</em>. Contrary to deduction, where the truth of the premises guarantees the truth of the conclusion, <strong>inductive inferences are <em>ampliative</em> — since whose conclusions go beyond what is contained in their premises —</strong> and their conclusions could be totally wrong even if infinitely many examples confirm them. <span class="citation">(<a href="#ref-bergadano1991problem">Bergadano 1991</a>)</span></p>
<p>In these regards, deduction seems safer than induction. Whenever we reason deductively we can be sure that given true premises we will reach true conclusions. On the other hand, <strong>inductive reasoning can take us from true premises to a false conclusion</strong>. Notwithstanding, we rely on inductive reasoning every day. For instance, every day we turn on our computers and we are confident they will not explode in our faces. <span class="citation">(<a href="#ref-okasha-pos">Okasha 2016</a>)</span> But why? Simply because we do it every morning and it has never exploded up to now.</p>
<p>We are sure that the sun will rise tomorrow, and if we are asked why we believe so, we will naturally answer “Because it always does”. We believe that it will rise in the future because it has risen in the past. Of course, when we are challenged to answer what <em>justifies</em> our belief we can refer to the laws of motion and nature. But will the laws of motion remain the same tomorrow? <span class="citation">(<a href="#ref-russell2001problems">Russell 1912</a>)</span></p>
</div>
<div id="modus" class="section level3 hasAnchor" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Modus ponens and Modus tollens<a href="scientific-inference.html#modus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="notebox">
<div class="center">
<p><strong>Course Note:</strong></p>
</div>
<p>The following content relates to deduction and is usually taught in high school philosophy courses as part of propositional calculus. It will help getting a better understanding of the deductive inference rules. If this is already clear to you, feel free to jump to the problem(s) of induction <a href="scientific-inference.html#problem-induction">2.3</a>.</p>
</div>
<p>There are two rules of inference in deductive reasoning. Deduction constitutes top-down logic because particular conclusions are drawn from general premises. Whereas in bottom-up logic the conclusion is reached by generalizing from specific cases.</p>
<ul>
<li>Modus ponens: <code>P implies Q. P is true. Therefore Q must also be true.</code></li>
<li>Modus tollens: <code>If P, then Q. Not Q. Therefore, not P.</code></li>
</ul>
<p>The form of a <strong>modus ponens</strong> argument looks like a syllogism consisting of two premises and a conclusion. The first premise is a conditional if-then claim (e.g. <code>P implies Q</code>). The second premise is an assertion that <span class="math inline">\(P\)</span> (the antecedent of the first premise) is indeed true. From these two premises, it can be concluded that <span class="math inline">\(Q\)</span>, (the consequent of the first premise) must be true as well.</p>
<pre><code>If P, then Q.
P.
--------------
Therefore, Q.</code></pre>
<p>The next example fits the form of <em>modus ponens</em>.</p>
<pre><code>If today rains, John will take the umbrella.
Today is raining.
------------------
Therefore, John will take the umbrella.</code></pre>
<p>The argument is valid but it doesn’t matter if the statements in the argument are actually true. An argument can be valid but nonetheless unsound if their premises are false. <em>Modus ponens</em> rule can be written as <span class="math inline">\(P \rightarrow Q, P \vdash Q\)</span>. In logic, an argument is sound if it is both valid in form and its premises are true.</p>
<p>On the other hand, the form of a <strong>modus tollens</strong> argument also consists of two premises and a conclusion. The first premise is a conditional if-then claim (e.g. <code>P implies Q</code>). The second premise is an assertion that <span class="math inline">\(Q\)</span> (the consequent of the conditional claim) is not the case. From these two premises, it can be concluded that <span class="math inline">\(P\)</span> is also not the case. <em>Modus tollens</em> rule can be written as <span class="math inline">\(P \rightarrow Q, \lnot Q \vdash \lnot P\)</span>.</p>
<pre><code>If P, then Q.
Not Q.
-----------------
Therefore, not P.</code></pre>
<p>Modus tollens is specially important in falsification (see <a href="scientific-inference.html#falsification">2.4.2</a>). For instance, we take our hypothesis H to test and assume that is true. If <span class="math inline">\(H\)</span> is true, then consequent <span class="math inline">\(C\)</span> is true. We make an observation and see that <span class="math inline">\(C\)</span> is false. Therefore, we conclude that H is false.</p>
<pre><code>If H, then C.
C is false.
-----------------
Therefore, H is false.</code></pre>
<hr />
<p>Other forms of arguments are apparently <strong>similar but invalid forms</strong>.</p>
<p><strong>Affirming the consequent</strong>. This formal fallacy consists of taking a true conditional statement <span class="math inline">\(P \rightarrow Q\)</span> and invalidly inferring its converse <span class="math inline">\(Q \rightarrow P\)</span>. For example, the statement “if the light is broken, the room would be dark” does not justify inferring the converse “the room is dark, therefore the lamp is broken”. This situations may arise when a consequent has more than one possible antecedent.</p>
<p><strong>Denying the antecedent</strong>. This fallacy is committed by reasoning in the form: <code>If P, then Q. Therefore, if not P, then not Q</code>. This kind of arguments can seem valid at first glance. Consider this famous example from Alan Turing:</p>
<blockquote>
<p>If each man had a definite set of rules of conduct by which he regulated his life he would be no better than a machine. But there are no such rules, so men cannot be machines. — Alan Turing</p>
</blockquote>
<p>Men could still be machines that do not follow a definite set of rules.</p>
<p>Another trivial example of this second fallacy.</p>
<pre><code>If you are a bus driver, then you have a job.
You are not a bus driver.
---------------------------
Therefore, you have no job.</code></pre>
<!-- ### Propositional knowledge

[@johansson2016philosophy] -->
</div>
</div>
<div id="problem-induction" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> The problem(s) of induction<a href="scientific-inference.html#problem-induction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Do scientists use induction?</strong> Pretty much all the time. Whenever scientists move from limited data to general conclusions scientists reason inductively. <strong>In inductively valid arguments, the (joint) truth of the premises is very likely (but not necessarily) sufficient for the truth of the conclusion.</strong> For instance, a newspaper may run the headline “scientists find experimental proof that transgenic maize is safe to eat”. This means scientists tested transgenic maize on a large number of people without finding any issues. Does this <em>strictly prove</em> that transgenic maize is safe? Is this prove as strong as the proof of the Pythagoras’ theorem? Going from “the transgenic maize didn’t harm any of the people on whom it was tested” to “the transgenic maize will not harm anyone” is an inductive inference, not deductive.</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Writing Note:</strong></p>
</div>
<p>Suppose the following inductive inference <span class="math inline">\(I\)</span>: If the probability of observing <span class="math inline">\(R\)</span>, given that <span class="math inline">\(H\)</span> is true, is smaller than a significance level of 0.05, then reject <span class="math inline">\(H\)</span>. Is important to distinguish between the two following things:</p>
<ul>
<li>Justification <em>with</em> an inference rule: Justifying the conclusion by pointing to the premise and the inference rule. Inference rules justify conclusions.</li>
<li>Justification <em>of</em> an inference rule: What makes <span class="math inline">\(I\)</span> a good inductive inference? Why not choosing other parameters? The choice of a particular inference rule must be justified.</li>
</ul>
</div>
<div id="david-humes-problem-of-induction" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> David Hume’s Problem of Induction<a href="scientific-inference.html#david-humes-problem-of-induction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<figure class="wrap-figure">
<img src="Figures/David_Hume.jpg">
<figcaption>
Portrait of David Hume </br>
by Allan Ramsay.
</figcaption>
</figure>
<p>We use induction to justify our statements but how do we justify induction itself? How would you convince someone else that induction is a good inference method? The Scottish philosopher David Hume (1711-76) argued that the use of induction cannot be rationally justified at all. In 1739, still under the shadow of the bubonic plague in Europe, David Hume publishes <em>A Treatise of Human Nature</em>, presumably without knowing that his work would not only continue to be debated more than 200 years later, but also still remarkably relevant in the technological advances of our time. In <em>the problem of induction</em> Hume argues that we cannot make a causal inference just by <em>a priori</em> means, and poses the question of how we can conclude from the observed to the unobserved.</p>
<p>Hume admitted that we use induction all the time in everyday life and science but insisted that this is just a matter of brute animal habit. What does he mean by that? Bertrand Russell (1872-1970) gives us a good example on this. He argues that the inductive association is also present in animals.</p>
<blockquote>
<p>“And this kind of association is not confined to men; in animals also it is very strong. A horse which has been often driven along a certain road resists the attempt to drive him in a different direction. Domestic animals expect food when they see the person who usually feeds them. We know that all these rather crude expectations of uniformity are liable to be misleading. The man who has fed the chicken every day throughout its life at last wrings its neck instead, showing that more refined views as to the uniformity of nature would have been useful to the chicken. […] The mere fact that something has happened a certain number of times causes animals and men to expect that it will happen again. Thus our instincts certainly cause us to believe that the sun will rise to-morrow, but we may be in no better a position than the chicken which unexpectedly has its neck wrung.” — <span class="citation">(<a href="#ref-russell2001problems">Russell 1912</a>)</span></p>
</blockquote>
<p>Hume arrived to this conclusion by noting that whenever we make inductive inferences we presuppose the <em>uniformity of nature</em>. Remember the eggs box example in § <a href="scientific-inference.html#deduction">2.2.1</a> ? Our reasoning depends on the assumption that objects that we have not examined yet will resemble those objects that we have already examined. Then, Hume argues that we cannot prove the truth of the uniformity assumption. Basically, from the mere act of being able to imagine a world where nature is not uniform but changes at random it follows that we cannot prove that the uniformity assumption is true. Also, if we try to argue for the uniformity assumption on empirical grounds, we end up reasoning in a circle.</p>
<p>The conclusion then is that our tendency to project past regularities into the future is not underpinned by reason. The problem of induction is to find a way to avoid this conclusion, despite Hume’s argument <span class="citation">(<a href="#ref-sep-induction-problem">Henderson 2020</a>)</span>. <strong>Hume’s problem of induction is still an active area of research for philosophers</strong>. There are many different ways to respond to Hume’s argument, yet none is fully convincing. Peter Strawson (1950s) used the following analogy: justifying induction is like asking whether the law is itself legal. This is rather odd, since the law is the standard against which the legality of other things is judged. Others, like Karl Popper (1902-1994) argued that science is not in fact based on inductive inferences at all and presented a deductivist view of science. We will study this in detail in § <a href="scientific-inference.html#falsification">2.4.2</a>.</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Note on uniformity of nature:</strong></p>
</div>
<p>Notice how ML models can be regarded as inductive machines performing inductive inferences based on previous observations. For the ML model to perform well on novel data, is often assumed that novel data will resemble past data.</p>
<p>Hume refers to this assumption as the Principle of Uniformity of Nature: <em>“If reason determined us, it would proceed upon that principle, that instances, of which we have had no experience, must resemble those, of which we have had experience, and that the course of nature continues always uniformly the same.”</em></p>
<p>And it continues: <em>“Our foregoing method of reasoning will easily convince us, that there can be no demonstrative arguments to prove, that those instances, of which we have had no experience, resemble those, of which we have had experience. We can at least conceive a change in the course of nature; which sufficiently proves, that such a change is not absolutely impossible. To form a clear idea of any thing, is an undeniable argument for its possibility, and is alone a refutation of any pretended demonstration against it.”</em></p>
<p><span class="citation">(<a href="#ref-hume1739treatise">Hume 1739</a>)</span> T. 1.3.6.4</p>
</div>
<p>As scientists, Hume’s problem of induction may leave a huge void in our heart. An empty feeling that science is indeed fallible and the sudden realisation of the impossibility of establishing the truth or falsity of scientific laws <span class="citation">(<a href="#ref-rosenberg2019philosophy">Rosenberg and McIntyre 2019</a>)</span>. But perhaps there is a way to fill such gap, and perhaps big part of the effort of science is put on filling this void with as much certainty as possible.</p>
<p>Hume’s argument concerns specific inductive inferences such as <code>All observed instances of A have been B</code> and <code>The next instance of A will be B</code>. Hume’s argument proceeds as follows:</p>
<ul>
<li>Every inference is either inductive or deductive.</li>
<li>To justify an inductive inference rule <span class="math inline">\(I\)</span>, this rule must be inferred from some premises.</li>
<li>Is not possible to infer the rule <span class="math inline">\(I\)</span> deductively, because there are no necessary connection between past and future inferences.</li>
<li>Therefore, the rule <span class="math inline">\(I\)</span> must be inferred inductively.</li>
<li>When inferring <span class="math inline">\(I\)</span> inductively, we must invoke another inductive inference rule <span class="math inline">\(J\)</span> to justify this induction. But then, how do we justify <span class="math inline">\(J\)</span>? … [<em>infinite regress</em>]</li>
</ul>
<p>Just because an inference rule has yield true conclusions in the past does not necessarily imply that it will do so in the future.
Consequently, Hume concludes that no inductive inference rule can be justified. But, does this mean all scientific inductive inferences are not justified?</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>If we visualise the data as points in a plane; every set of finite points belongs to infinite functions or curves. The problem of induction, in this case, consists in establishing criteria that allow us to say that the finite series of data confirms only one of the functions, or less dramatically but just as problematic, that one is more confirmed than the others <span class="citation">(<a href="#ref-diez1997fundamentos">Dı́ez and Moulines 1997</a>)</span>. (See the problem of underdetermination in §<a href="scientific-inference.html#confirmation">2.4.3</a>).</p>
</div>
<div class="simplebox">
<div data-latex="">
<p><strong>Ancient views on the regress argument</strong></p>
</div>
<p>Pyrrhonist philosopher Sextus Empiricus (mid-late 2nd century CE) raised concerns which applied to all types of knowledge and doubted the validity of induction long before David Hume, raising the regress argument against all forms of reasoning (<a href="https://en.wikipedia.org/wiki/Sextus_Empiricus#Philosophy">Wikipedia</a>). This view is known as Pyrrhonian skepticism.</p>
<blockquote>
<p>Those who claim for themselves to judge the truth are bound to possess a criterion of truth. This criterion, then, either is without a judge’s approval or has been approved. But if it is without approval, whence comes it that it is trustworthy? For no matter of dispute is to be trusted without judging. And, if it has been approved, that which approves it, in turn, either has been approved or has not been approved, and so on ad infinitum. – Sextus Empiricus</p>
</blockquote>
</div>
</div>
</div>
<div id="the-hypothetico-deductive-method" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> The Hypothetico-deductive Method<a href="scientific-inference.html#the-hypothetico-deductive-method" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the section about the <a href="scientific-goals-methods-and-knowledge.html#sci-method">scientific method</a>, we learnt how scientists begin proposing (or guessing) unproven hypotheses. After an initial consideration of the problem and collection of data a conjecture or hypothesis to explain a particular phenomena is formulated. Afterwards, deduction is used to derive consequences or observable implications <span class="math inline">\(\{C_i\}\)</span> from such hypotheses <span class="math inline">\(H\)</span>. These consequences should be relevant for <span class="math inline">\(H\)</span> and observable directly or with the help of instruments (e.g. microscope, MRI, etc.). Next, hypotheses are put to test and either based on the results scientists decrease or increase the confidence over the hypotheses.</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>Propose a hypothesis <span class="math inline">\(H\)</span>.</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Deduce observable consequences <span class="math inline">\(\{C_i\}\)</span> from <span class="math inline">\(H\)</span>.</li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>Test. Look for evidence that conflicts with the predicted consequences <span class="math inline">\(\{C_i\}\)</span> in order to disprove <span class="math inline">\(H\)</span>.</li>
</ol></li>
<li><ol start="4" style="list-style-type: decimal">
<li>If <span class="math inline">\(\{C_i\}\)</span> is false, infer that <span class="math inline">\(H\)</span> is false, reformulate <span class="math inline">\(H\)</span>. (See § <a href="scientific-inference.html#falsification">2.4.2</a>)</li>
</ol></li>
<li><ol start="5" style="list-style-type: decimal">
<li>If <span class="math inline">\(\{C_i\}\)</span> is true, increase confidence in <span class="math inline">\(H\)</span>. (See § <a href="scientific-inference.html#confirmation">2.4.3</a>)</li>
</ol></li>
</ul>
<p>For relevant examples, check <a href="scientific-inference.html#semmelweis">2.8.1</a> and <a href="scientific-inference.html#wason">2.8.2</a>.</p>
<div id="a-good-hypothesis" class="section level3 hasAnchor" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> A good hypothesis<a href="scientific-inference.html#a-good-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:xkcd-hypothesis"></span>
<img src="Figures/hypothesis_generation.png" alt="The key aspect being conveyed in this simple exchange is that one of the many good practices in science (no matter the aspect, though the specifics may change according to the precise field of study) is that one should first have an idea of what you can test and then perform the test to confirm (or rule out) your idea. Title text: &quot;Frazzled scientists are requesting that everyone please stop generating hypotheses for a little bit while they work through the backlog&quot;. Source: xkcd.com." width="66%" />
<p class="caption">
Figure 2.1: The key aspect being conveyed in this simple exchange is that one of the many good practices in science (no matter the aspect, though the specifics may change according to the precise field of study) is that one should first have an idea of what you can test and then perform the test to confirm (or rule out) your idea. Title text: “Frazzled scientists are requesting that everyone please stop generating hypotheses for a little bit while they work through the backlog”. Source: xkcd.com.
</p>
</div>
<p>Still, there are some criteria for a <a href="https://opentext.wsu.edu/carriecuttler/chapter/developing-a-hypothesis/">good hypothesis</a>. Apart from criteria such as parsimony, scope, fruitfulness and conservatism, these are other criteria to recall.</p>
<ul>
<li><p>It should be an statement that can be either true or false (e.g. “Boiling point of a liquid increases with increase in pressure”). In other words, it should be <strong>testable and falsifiable</strong>. We must be able to test the hypothesis using the methods of science and according to Popper’s falsifiability criterion, it must be possible to gather evidence that will reject the hypothesis if it is indeed false.</p></li>
<li><p>A hypothesis must not be a tautology (i.e. claims that are necessarily true or false; e.g. “Either it will rain tomorrow or it will not rain.” or “all bachelors are unmarried”).</p></li>
<li><p>Hypotheses should be informed by previous theories or observations and logical reasoning.</p></li>
<li><p>Finally, the hypothesis should be positive. That is, the hypothesis should make a positive statement about the existence of a relationship or effect, rather than a statement that a relationship or effect does not exist.</p></li>
<li><p>Finally, it should have some generality (e.g. “things of certain type…”) or be about some non-directly observable property of a particular.</p></li>
</ul>
</div>
<div id="falsification" class="section level3 hasAnchor" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Falsification<a href="scientific-inference.html#falsification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<figure class="wrap-figure">
<img src="Figures/Karl_Popper.jpg">
<figcaption>
Karl Popper in the 1980’s.
</figcaption>
</figure>
<p>According to the Hypothetico-deductive method (H-D), a hypothesis is formulated, then relevant consequences are deduced, and finally we observe whether these consequences are false or true. Depending on these observations the hypothesis will be either falsified or confirmed.</p>
<p>Is important to note a key difference between confirmation and falsification. In step 4 of the <strong>H-D method</strong> we can infer the falsity of the hypothesis from the falsity of even a single one of the expected consequences. In contrast, in step 5 confirmation of the hypothesis is not inferred from the truth of even a large set of the consequences. Instead, we only increase our confidence on the hypothesis after finding that many consequences of the hypothesis are true. This difference is referred as the <strong>asymmetry between confirmation and falsification</strong>. Although a scientific theory can never be proved true by a finite amount of data, it can be proved false, or refuted by a single experiment.</p>
<blockquote>
<p>“No amount of experimentation can ever prove me right; a single experiment can prove me wrong.” — Albert Einstein</p>
</blockquote>
<p>This asymmetry forms the basics of Karl Popper’s (1902-1994) falsificationism.</p>
<ul>
<li>Propose falsifiable hypotheses.</li>
<li>Try to falsify these hypotheses with observable evidence.</li>
<li>Reject any falsified hypothesis as false.</li>
<li>Never accept any hypothesis as true - consider non-falsified hypotheses as “not-rejected yet”.</li>
</ul>
<blockquote>
<p>One objection to this [the asymmetry between confirmation and falsification] holds that the asymmetry is an illusion, because whenever we refute a universal statement we thereby verify its negation. A universal statement “All x are y” is equivalent to “There is no non-y x.” Therefore, when we refute “All apples are green” we automatically verify “There is a non-green apple.” — <span class="citation">(<a href="#ref-percival2015confirmation">Percival 2015</a>)</span></p>
</blockquote>
<p>Popper is quite radical in this last step. For him, confirmation places no role at all. One can never infer the truth of hypotheses - Popper argues - from the observations regarding their implications. Not even increase the confidence in the truth of the hypothesis. Popper hoped to avoid Hume’s problem of induction by not employing induction in science. Popper thought that science was and should be deductive, and therefore that the lack of justification for inductive inferences was not as damaging for science. Below example is illustrative.</p>
<blockquote>
<p>Suppose a scientist is testing the hypothesis that all pieces of metal conduct electricity. Even if every piece of metal they examine conducts electricity, this doesn’t prove that the hypothesis is true, for reasons that we’ve seen. But if the scientist finds even one piece of metal that fails to conduct electricity, this conclusively refutes the theory. For the inference from ‘this piece of metal does not conduct electricity’ to ‘it is false that all pieces of metal conduct electricity’ is a deductive inference—the premise entails the conclusion. So if a scientist were trying to refute their theory, rather than establish its truth, their goal could be accomplished without the use of induction. — <span class="citation">(<a href="#ref-okasha-pos">Okasha 2016</a>)</span></p>
</blockquote>
<p>However, this view of the scientific process could be rather limiting with respect to the actual scientific practice. First, it does not allow to distinguish between non-falsified hypotheses. Popper argues that obtaining evidence in favour of a given theory is generally easy, and holds that such <em>corroboration</em> should count scientifically only if it is the positive result of a genuinely <em>risky</em> prediction, which might conceivably have been false.</p>
<blockquote>
<p>It is logically impossible to verify a universal proposition by reference to experience (as Hume saw clearly), but a single genuine counter-instance falsifies the corresponding universal law. In a word, an exception, far from “proving” a rule, conclusively refutes it. — <span class="citation">(<a href="#ref-sep-popper">Thornton 2021</a>)</span></p>
</blockquote>
<p>Second, in scientific practice hypotheses rarely have immediate observable consequences, they often require measurements or experiments to do so. For instance, the hypothesis “this liquid contains 3 substances” does not entail any direct observable consequence. We might use distillation or chromatography to test such hypothesis but this requires relying on <strong>auxiliary hypothesis</strong> (e.g. the distillation machine works properly). This consideration quite changes the <strong>H-D method</strong> steps. Moreover, we never test a single hypothesis alone, but only in conjunction with various auxiliary hypotheses (Duhem-Quine Thesis). One relevant example is the work of Galileo Galilei and his reports of mountains on the moon and Jupiter satellites. Philosophers such as Cesare Cremonini refused to look through the telescope, arguing that the instrument itself might have introduced artefacts, producing a visual illusion. Therefore, Duhem-Quine thesis states that in order to falsify a hypothesis we must be confident that the responsible for falsity of the consequence are not the auxiliary hypotheses but the main hypothesis.</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>Propose a hypothesis <span class="math inline">\(H\)</span>.</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>Deduce observable consequences <span class="math inline">\(\{C_i\}\)</span> from <span class="math inline">\(H\)</span> in conjunction with auxiliary hypotheses <span class="math inline">\({AH_j}\)</span></li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>Test. Look for evidence that conflicts with the predicted consequences <span class="math inline">\(\{C_i\}\)</span> in order to disprove <span class="math inline">\(H\)</span>.</li>
</ol></li>
<li><ol start="4" style="list-style-type: decimal">
<li>If <span class="math inline">\(\{C_i\}\)</span> is false, infer that <span class="math inline">\(H \&amp; \{AH_j\}\)</span> is false, reformulate <span class="math inline">\(H\)</span>.</li>
</ol></li>
<li><ol start="5" style="list-style-type: decimal">
<li>If <span class="math inline">\(\{C_i\}\)</span> is true, increase confidence in <span class="math inline">\(H \&amp; \{AH_j\}\)</span>.</li>
</ol></li>
</ul>
<div class="tipbox">
<div data-latex="">
<p><strong>Semantic Note:</strong></p>
</div>
<p>Note the difference between <em>falsifiable</em> and <em>falsified</em>.</p>
<p><strong>Falsifiability</strong> is a quality of a hypothesis or a theory. Is the quality of a conjecture or hypothesis to be proven wrong. Some theories have no empirical implications. Popper claimed that astrology and Freud’s psychoanalysis were not falsifiable. He argued that <em>falsifiability</em> demarcates whether a theory is scientific or not (see the <a href="https://plato.stanford.edu/entries/pseudo-science/">demarcation problem</a> <span class="citation">(<a href="#ref-sep-pseudo-science">Hansson 2021</a>)</span>). Similarly, some hypotheses might be more falsifiable than others because they have more empirically testable implications. For example, Newton’s law of gravitation is falsifiable (e.g. it is falsified by “The brick fell upwards when released”).</p>
<p><strong>Falsification</strong> is the observation that an implication of a hypothesis is not true which implies (by <em>modus tollens</em>) the falsity of the hypothesis. Hypothesis can only be falsified if they are falsifiable.</p>
<blockquote>
<p>Falsification uses the valid inference modus tollens: if from a statement <span class="math inline">\(P\)</span> we logically deduce <span class="math inline">\(Q\)</span>, but what is observed is <span class="math inline">\(\lnot Q\)</span>, we infer that <span class="math inline">\(P\)</span> is false. For example, given the statement “all swans are white” and the initial condition “there is a swan here”, we can deduce “the swan here is white”, but if what is observed is “the swan here is not white” (say black), then “all swans are white” is false, or it was not a swan.</p>
</blockquote>
</div>
<p>The take-away message from falsification is that despite proposing an unrealistically restrictive practice of science, it might be a useful inference method for scientists. However, they should be aware of its limitations and for instance, bear in mind the pitfalls of <em>ad-hoc</em> modifications. (See negative weight in phlogiston theory <span class="citation">(<a href="#ref-phlogiston">Grünbaum 1976</a>)</span>). An <em>ad-hoc</em> hypothesis is added to a theory to save it from being falsified. A modification is considered <em>ad-hoc</em> if it reduces the falsifiability of the hypothesis in question.</p>
</div>
<div id="confirmation" class="section level3 hasAnchor" number="2.4.3">
<h3><span class="header-section-number">2.4.3</span> Confirmation<a href="scientific-inference.html#confirmation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<!-- [rewrite] -->
<p>Confirmation is the act of using evidence to justify increasing the confidence in the hypothesis.
Confirmation is not based on deductively valid inferences. For instance, in the <strong>H-D method</strong> we identify some <span class="math inline">\(C\)</span> that is an implication of <span class="math inline">\(H\)</span>. <span class="math inline">\(H\)</span> implies <span class="math inline">\(C\)</span>, then if <span class="math inline">\(H\)</span> is true we conclude (by <em>modus ponens</em>) that <span class="math inline">\(C\)</span> is also true. Moreover, if we observe than <span class="math inline">\(C\)</span> is false, then we conclude (by <em>modus tollens</em>) that <span class="math inline">\(H\)</span> is false as well.</p>
<pre><code>Modus ponens     Modus tollens    Induction

H, then C        H, then C        H, then C
H                not C            C
-----------      -----------      =========
C                not H            H </code></pre>
<p>While these two inference rules are deductively valid, they do not tell us what to conclude if the implication <span class="math inline">\(C\)</span> is true. There is no valid deductive rule that can be used for the case where <span class="math inline">\(H\)</span> implies <span class="math inline">\(C\)</span> and <span class="math inline">\(C\)</span> is true. We cannot deduce anything from that.</p>
<p>Instead, any rule used here must amplify the information contained in the premises to infer the conclusions. Therefore we must make use of inductive inferences. Inductive inferences are fallible (inductions that fail are common e.g. predicting the weather, stock investing). But fallibility comes in degrees and this degree is affected by the kind and quality of the evidence as well as the inference rule employed. Scientists have attempted to quantify confidence, most prominently by using probabilities. For instance, if an observation <span class="math inline">\(O\)</span> confirms hypothesis <span class="math inline">\(H\)</span>, therefore we say that <span class="math inline">\(P(H|O)\)</span> is greater than <span class="math inline">\(P(H|\lnot O)\)</span> where <span class="math inline">\(P(H|O)\)</span> means “the probability of <span class="math inline">\(H\)</span> given <span class="math inline">\(O\)</span>”.</p>
<p>There is certain debate on this last point. Not everybody agrees that it makes sense to assign probabilities to hypotheses because they differ on the interpretation of the concept of probability. <strong>Frequentists</strong> interpret the probabilities as the frequencies of repeatable observable events. Therefore probabilities cannot be assigned to hypotheses since these are not events, nor observable or repeatable. Another problem is that probabilities are already used to express a property different from confidence. For instance, we may say that the probability of tails when throwing a coin is 50%. But then someone may ask us how confident we are about our claim. Even if we can also answer that second question with a probability, is clear that these two numbers express different things.</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>Is important to note the relevance of frequentist and Bayesian approaches in artificial intelligence. Both frequentist and Bayesian are statistical approaches to learning from data. But there is a broad distinction between the frequentist and Bayesian. The frequentist learning only depends on the given data, while the Bayesian learning is performed by the prior belief as well as the given data <span class="citation">(<a href="#ref-jun2016frequentist">Jun 2016</a>)</span>.</p>
<p>The frequentist computes the probability of result or data <span class="math inline">\(D\)</span> given hypothesis <span class="math inline">\(H\)</span> is true, i.e. <span class="math inline">\(P(D|H)\)</span>. In comparison, the Bayesian approach focus on the probability of hypothesis <span class="math inline">\(H\)</span> when the result or data <span class="math inline">\(D\)</span> occurs, i.e. <span class="math inline">\(P(H|D)\)</span> <span class="citation">(<a href="#ref-orloffcomparison">Orloff and Bloom 2014</a>)</span>.</p>
</div>
<p>Understanding that confirmation comes in degrees may help clarify the last step of <strong>H-D method</strong>. Observing <span class="math inline">\(C\)</span> to be true, increases our degree of confidence that <span class="math inline">\(H\)</span> is true. But why is this? A naïve answer to this question is that observing <span class="math inline">\(C\)</span> confirms <span class="math inline">\(H\)</span> because <span class="math inline">\(H\)</span> is compatible with <span class="math inline">\(C\)</span>. But this seems rather weak justification. Indefinitely irrelevant implications could be inferred from a hypothesis. For instance:</p>
<pre><code>I have pancreas cancer, then I have a pancreas
I have a pancreas    
---------
I have pancreas cancer</code></pre>
<p>A clear deductive consequence from this example is that indeed I have a pancreas. However, observing that I do have a pancreas should not confirm the claim that I have pancreas cancer. To solve this issue we should introduce a criteria for relevance to make sure that the chosen implications are relevant to the question. This is key part of the scientific process as this often depends on the domain knowledge we have about the matter we are investigating.</p>
<p>An additional problem to the compatibility issue, is that very many hypotheses are compatible with any given observation. This is called the problem of underdetermination.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:chart-underdetermination"></span>
<img src="Figures/underdetermination_small.png" alt="The problem of underdetermination illustrated with a chart." width="75%" />
<p class="caption">
Figure 2.2: The problem of underdetermination illustrated with a chart.
</p>
</div>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>According to <strong>anti-realists</strong>, there will always be multiple <strong>competing</strong> theories about unobservable entities (e.g. atoms) which can account for the data equally well. In other words, such theories are <strong>undetermined</strong> by the empirical data. But then, how do scientists justify choosing one theory over another? <strong>Realists</strong> often reply that aforementioned scenario is only possible in the trivial sense. In fact, scientists often struggle to find even <em>one</em> theory that fits the data properly.</p>
<p>But why is this important for data scientists? Often you will find many ML models or solutions that fit your available data or fulfil your requirements, and yet you will have to decide which model/solution is best. If possible, validation with external data and other assessments must be conducted, but sometimes solutions are also chosen based on <em>non-epistemic</em> values, such as making society more just or making money.</p>
<p>Is also important to notice how the problem of underdetermination relates to the popular <strong>No Free Lunch Theorem</strong> which is very relevant in the Machine Learning community <span class="citation">(<a href="#ref-dotan2020theory">Dotan 2020</a>)</span>. For more on the NFL read <span class="citation">(<a href="#ref-domingos2015master">Domingos 2015</a>)</span>.</p>
</div>
</div>
<div id="bayesian-inference" class="section level3 hasAnchor" number="2.4.4">
<h3><span class="header-section-number">2.4.4</span> Beyond the Hypothetico-Deductive Method: Bayesian Inference and the Logic of Uncertainty<a href="scientific-inference.html#bayesian-inference" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>While the HD method offers a simple and useful framework to think about how science proceeds, from hypothesis formation to testing via deduction, it has important limitations. These become especially clear in data-driven disciplines such as machine learning, statistics, and empirical sciences that rely on probabilistic reasoning. Here, we examine alternative approaches that better accommodate uncertainty, quantify degrees of belief, and reflect how inference is conducted in real-world contexts.</p>
<div id="limitations-of-the-hd-method-in-probabilistic-contexts" class="section level4 hasAnchor" number="2.4.4.1">
<h4><span class="header-section-number">2.4.4.1</span> Limitations of the HD method in probabilistic contexts<a href="scientific-inference.html#limitations-of-the-hd-method-in-probabilistic-contexts" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In the HD method, hypotheses are tested by deducing observable consequences and then checking whether those consequences occur. If any of the deduced implications are false, the hypothesis is rejected (falsified). If they are all true, the hypothesis is not proven true, but may be confirmed.</p>
<p>However, most scientific theories, especially those in statistical sciences, are not structured as strict universal generalizations like “all swans are white”. Instead, they are probabilistic in nature. For example:</p>
<ul>
<li>“If a drug is effective, then 80% of patients will recover.”</li>
<li>“If a coin is fair, then heads will appear approximately 50% of the time.”</li>
</ul>
<p>Here, the predictions are not strictly entailed by the hypothesis. They are probabilistic expectations. This weakens the applicability of modus tollens: if only 60% of patients recover, is the hypothesis falsified? Not necessarily. In probabilistic contexts, observing an outcome that deviates from the expected does not conclusively falsify the hypothesis, because such deviations are themselves expected to occur with some probability. <strong>The data may be compatible with both the hypothesis and the null hypothesis</strong>, making it difficult to draw a sharp deductive conclusion. Instead of strict falsification, we assess how well the data supports one hypothesis over another, often in terms of likelihood or posterior probability.</p>
<p>Moreover, empirical data is noisy. Measurement error, incomplete information, and stochastic processes mean that consequences of a hypothesis may deviate from what is expected even if the hypothesis is “mostly” correct. Under these circumstances, we need a more flexible form of inference, i.e., probabilistic inference, that allows us to reason under uncertainty.</p>
</div>
<div id="bayesian-epistemology-and-conditionalization" class="section level4 hasAnchor" number="2.4.4.2">
<h4><span class="header-section-number">2.4.4.2</span> Bayesian Epistemology and Conditionalization<a href="scientific-inference.html#bayesian-epistemology-and-conditionalization" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Bayesian inference offers a model of rational belief revision. In contrast to the HD method, which evaluates hypotheses in an all-or-nothing fashion, the Bayesian approach updates degrees of belief (probabilities) in light of new evidence. Suppose we have a hypothesis <span class="math inline">\(H\)</span> and we observe some data <span class="math inline">\(D\)</span>. The central rule of Bayesian updating is Bayes’ theorem:</p>
<p>Bayes’ theorem: <span class="math inline">\(P(H \mid D) = \frac{P(D \mid H) \cdot P(H)}{P(D)}\)</span></p>
<p>This formula tells us how to update our belief in <span class="math inline">\(H\)</span> after observing <span class="math inline">\(D\)</span>. Key terms:</p>
<ul>
<li><span class="math inline">\(P(H)\)</span>: the prior probability of the hypothesis before seeing the data.</li>
<li><span class="math inline">\(P(D \mid H)\)</span>: the likelihood of the data assuming the hypothesis is true.</li>
<li><span class="math inline">\(P(H \mid D)\)</span>: the posterior probability of the hypothesis after updating with the data.</li>
</ul>
<p>This rule allows beliefs to change incrementally as new evidence becomes available, reflecting both prior knowledge and the strength of the data. It avoids the binary logic of the HD method and instead provides a continuous scale of confidence. Where the HD method discards a hypothesis after a single negative test, Bayesian inference merely lowers its probability, unless the evidence is truly decisive <span class="citation">(<a href="#ref-howson2006scientific">Howson and Urbach 2006</a>)</span>.</p>
</div>
<div id="bayesian-vs-frequentist-views" class="section level4 hasAnchor" number="2.4.4.3">
<h4><span class="header-section-number">2.4.4.3</span> Bayesian vs Frequentist Views<a href="scientific-inference.html#bayesian-vs-frequentist-views" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There are two dominant interpretations of probability in scientific inference:</p>
<ul>
<li>Frequentist: Probabilities refer to long-run relative frequencies of observable events. Hypotheses are fixed and not assigned probabilities. Evidence is used to reject or fail to reject a hypothesis.</li>
<li>Bayesian: Probabilities reflect subjective or rational degrees of belief. Hypotheses themselves are uncertain, and can be compared based on their posterior probabilities.</li>
</ul>
<p>Both perspectives are widely used in science and data analysis. For example:</p>
<table>
<colgroup>
<col width="20%" />
<col width="39%" />
<col width="39%" />
</colgroup>
<thead>
<tr class="header">
<th>Topic</th>
<th>Frequentist Perspective</th>
<th>Bayesian Perspective</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Interpretation of Probability</td>
<td>Long-run frequency of events</td>
<td>Degree of belief (subjective or epistemic)</td>
</tr>
<tr class="even">
<td>Hypotheses</td>
<td>Fixed and not assigned probabilities</td>
<td>Treated as uncertain; assigned prior and updated posterior</td>
</tr>
<tr class="odd">
<td>Learning from Data</td>
<td>Estimation via Maximum Likelihood (MLE), confidence intervals</td>
<td>Posterior inference via Bayes’ Theorem</td>
</tr>
<tr class="even">
<td>Inference</td>
<td>Hypothesis testing using p-values</td>
<td>Probability of hypothesis given data, i.e., <code>P(H|D)</code></td>
</tr>
<tr class="odd">
<td>Updating</td>
<td>No explicit mechanism; fixed once data is observed</td>
<td>Prior updated with data to form posterior</td>
</tr>
<tr class="even">
<td>ML applications</td>
<td>Parameter estimation, frequentist confidence</td>
<td>Bayesian networks, uncertainty quantification</td>
</tr>
</tbody>
</table>
<p>Bayesian inference is especially relevant in machine learning, where models are constantly updated as new data is acquired. For example, recommender systems revise their predictions as user preferences evolve, and autonomous vehicles update environmental models in real time.</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>In Bayesian Machine Learning, priors allow incorporation of domain knowledge into model training. For instance, prior beliefs about plausible parameter ranges can prevent overfitting in small-data regimes. In deep learning, Bayesian neural networks use probability distributions over weights, allowing uncertainty estimation in predictions. These methods are crucial in high-stakes applications such as medical diagnosis, where not knowing the confidence of a prediction can be dangerous.</p>
</div>
</div>
<div id="bayesian-inference-and-the-problem-of-induction" class="section level4 hasAnchor" number="2.4.4.4">
<h4><span class="header-section-number">2.4.4.4</span> Bayesian Inference and the Problem of Induction<a href="scientific-inference.html#bayesian-inference-and-the-problem-of-induction" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Bayesian epistemology offers one response to Hume’s problem of induction. It does not deny the fallibility of inductive inference, but rather makes it explicit. In Bayesian terms, learning from experience is about adjusting belief in hypotheses as new evidence accumulates.</p>
<p>However, this still does not justify induction in the absolute sense. It formalizes how we might reasonably behave given certain starting beliefs and observations, but it does not explain why those beliefs are justified in the first place. As some philosophers argue, Bayesianism presupposes that some inductive inferences are valid; it does not solve Hume’s problem but reframes it.</p>
<!-- 
check the quote

"The Bayesian model shows how a rational agent should update beliefs, but it still takes for granted that the prior beliefs are reasonable." — [@Talbott2020bayesian]

-->
</div>
<div id="underdetermination-and-bayesian-model-selection" class="section level4 hasAnchor" number="2.4.4.5">
<h4><span class="header-section-number">2.4.4.5</span> Underdetermination and Bayesian Model Selection<a href="scientific-inference.html#underdetermination-and-bayesian-model-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>As seen with Confirmation in section <a href="scientific-inference.html#confirmation">2.4.3</a>, many hypotheses can be consistent with the same data. This is known as the problem of underdetermination. Bayesian reasoning provides one approach to this problem by allowing us to compare models in terms of their posterior probabilities. Models with higher likelihood given the data, and more plausible priors, are preferred.</p>
<p>Still, choosing priors is an open issue. Different priors can lead to different posterior conclusions, raising philosophical concerns about <strong>subjectivity</strong>. In practice, however, prior sensitivity can be tested and robustified through sensitivity analysis and hierarchical modeling.</p>
</div>
</div>
</div>
<div id="other-types-of-inference" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Other types of inference<a href="scientific-inference.html#other-types-of-inference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="notebox">
<div class="center">
<p><strong>Course Note:</strong></p>
</div>
<p>The following content is under construction but might as well be taught during the course.
This section will superficially tackle abduction and causal inferences and its relation to data science regarding non-monotonic logic.</p>
</div>
<!--

The following types of inference are very common in science.

#### Abduction

Abduction or Inference to the Best Explanation (IBE)...

#### Causal Inference

#### Probability and Inference

Mention non-monotonic logic, defeasible reasoning and tweety.

-->
</div>
<div id="non-monotonic-logic-and-defeasible-reasoning" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Non-Monotonic logic and defeasible reasoning<a href="scientific-inference.html#non-monotonic-logic-and-defeasible-reasoning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In its epistemic sense, monotonicity expresses the fact that adding more premises to an argument allows you to derive all the same conclusions as you could with fewer <span class="citation">(<a href="#ref-sep-logic-nonmonotonic">Strasser and Antonelli 2019</a>)</span>. Specifically, under monotonic reasoning, if a conclusion <span class="math inline">\(p\)</span> follows from a set of premises <span class="math inline">\(A\)</span>, (denoted as <span class="math inline">\(A\)</span> <span class="math inline">\(p\)</span>), adding another set of premises <span class="math inline">\(B\)</span> doesn’t alter the conclusion (i.e. <span class="math inline">\(A ∧ B \vdash p\)</span> also holds). Therefore, reasoning is <a href="https://plato.stanford.edu/entries/logic-nonmonotonic/">non-monotonic</a> when a conclusion supported by a set of premises can be retracted in the light of new information. Or in other words, we can infer certain conclusions from a subset of a set <span class="math inline">\(S\)</span> of premises which cannot be inferred from <span class="math inline">\(S\)</span> as a whole. Medical diagnosis fits very well under such definition.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tweety"></span>
<img src="Figures/PenguinFlies.png" alt="Double arrows indicate non-defeasible inferences (hard fact), single arrows depict defeasible inferences, and strikethrough arrows denote a negation. It can be read as: Penguins are birds (no exceptions); Birds usually fly; and Penguins usually don’t fly." width="33%" />
<p class="caption">
Figure 2.3: Double arrows indicate non-defeasible inferences (hard fact), single arrows depict defeasible inferences, and strikethrough arrows denote a negation. It can be read as: Penguins are birds (no exceptions); Birds usually fly; and Penguins usually don’t fly.
</p>
</div>
<p>Defeasible reasoning deals with tentative relationships between premises and conclusions, which can be <em>defeated</em> by additional information, allowing for the retraction of inferences. For instance, while we may infer that Tweety flies based on the information that Tweety is a bird and the domain knowledge that birds generally fly, we can retract this inference when we learn that Tweety is a penguin. Tweety is indeed a bird but it cannot fly. Defeasible reasoning is not exempt from limitations, requiring from causal information to properly derive conclusions under certain scenarios. Consider, for example, this problem of Judea Pearl: if the sprinkler is on, then normally the sidewalk is wet, and, if the sidewalk is wet, then normally it is raining. However, we should not infer that it is raining from the fact that the sprinkler is on <span class="citation">(<a href="#ref-pearl2014probabilistic">Pearl 2014</a>)</span>. Conflicts may arise between hard facts and defeasible conclusions. For instance, both arguments in Figure <a href="scientific-inference.html#fig:tweety">2.3</a> <span class="math inline">\(Penguin ⇒ Bird → flies\)</span> and <span class="math inline">\(Penguin → ¬flies\)</span> finish with a defeasible inference. The transitivity rule <span class="math inline">\((a → b, b → c) ⇒ a → c\)</span> cannot be applied to the first argument. In this case, according to their specificity we can give priority to the argument with more a specific antecedent but is not always as trivial, and complex conflicts can remain unresolved.</p>
<blockquote>
<p>Reasoning is defeasible when the corresponding argument is rationally compelling but not deductively valid. The truth of the premises of a good defeasible argument provide support for the conclusion, even though it is possible for the premises to be true and the conclusion false. In other words, the relationship of support between premises and conclusion is a tentative one, potentially defeated by additional information. — <span class="citation">(<a href="#ref-sep-reasoning-defeasible">Koons 2021</a>)</span>.</p>
</blockquote>
<blockquote>
<p>Defeasible reasoning is a particular kind of non-demonstrative reasoning, where the reasoning does not produce a full, complete, or final demonstration of a claim, i.e., where fallibility and corrigibility of a conclusion are acknowledged. In other words, defeasible reasoning produces a contingent statement or claim. Defeasible reasoning is also a kind of ampliative reasoning because its conclusions reach beyond the pure meanings of the premises. Defeasible reasoning finds its fullest expression in jurisprudence, ethics and moral philosophy, epistemology, pragmatics and conversational conventions in linguistics, constructivist decision theories, and in knowledge representation and planning in artificial intelligence. — Wikipedia</p>
</blockquote>
</div>
<div id="explanation" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Explanation<a href="scientific-inference.html#explanation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<figure class="wrap-figure">
<img src="Figures/Carl_Gustav_Hempel.jpg">
<figcaption>
Carl Hempel (1905 - 1997).
</figcaption>
</figure>
<p>At this point, many of you probably have already related data science to two of the goals of science: explanation and prediction. But how do they relate to one another? and what is a scientific explanation? Either to satisfy our natural curiosity or for a further purpose, science has always attempted to understand how the world works. The German philosopher Carl Hempel attempted to answer this question in the 1950s with what is known as the <em>covering law</em> model of explanation. He stated that a scientific explanation is an answer given in response to <em>explanation-seeking why-questions</em> (e.g. why salt dissolves in water).</p>
<p>According to Hempel, explanations are structured like an argument, i.e. a set of premises followed by a conclusion. Therefore, the conclusion of such an argument states that certain phenomenon occurs, e.g. “salt dissolves in water”. On the other hand, the premises indicate why the conclusion is true. Then, the challenge lays in the relationship that should follow between such premises and the conclusion. For Hempel, the premises should all be true and entail the conclusion, i.e. the argument should be deductive and <em>sound</em>. Additionally, the premises should contain at least one general law (e.g. all metals conduct electricity), a.k.a. <em>laws of nature</em>. The name of the model comes from that fact that the phenomenon to be explained is “covered” by some general law.</p>
<ol style="list-style-type: decimal">
<li>The <em>explanandum</em> must be a valid deductive argument.</li>
<li>The <em>explanans</em> must contain at least one general law actually needed in the deduction.</li>
<li>The <em>explanans</em> must be empirically testable.</li>
<li>The sentences in the <em>explanans</em> must be true.</li>
</ol>
<p>For instance, Newton explained the elliptical orbits of planets alluding a general rule (his law of universal gravitation) together with some minor assumptions. This example fits Hempel’s model very well, but not all scientific explanations do.</p>
<pre><code>General Law      (explanans)
Particular Facts (explanans)
---------
Phenomenon to be explained (explanandum)</code></pre>
<p>An interesting consequence of this model lays in the relationship between explanation and prediction. Hempel argued that these are two sides of the same coin. Whenever a phenomenon is explained with the help of a covering law, the laws and the particular facts we use could have allowed us to predict the occurrence of the phenomenon. Hempel expressed this by saying that every scientific explanation is potentially a prediction. Hempel argued that the opposite is also true: every prediction is potentially an explanation. <strong>For Hempel, explanation and prediction are structurally symmetric</strong>. For instance, the same information we could use to predict an animal species extinction before it happened will serve to explain that very same fact after it has happened.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:flagpole"></span>
<img src="Figures/flagpole.png" alt="A 15-metre flagpole casts a shadow of 20 metres when the sun is 37° overhead. Figure from (Okasha 2016)." width="75%" />
<p class="caption">
Figure 2.4: A 15-metre flagpole casts a shadow of 20 metres when the sun is 37° overhead. Figure from <span class="citation">(<a href="#ref-okasha-pos">Okasha 2016</a>)</span>.
</p>
</div>
<p>Hempel’s model might be too liberal, as it faces a number of odd counterexamples. For example, consider Figure <a href="scientific-inference.html#fig:flagpole">2.4</a>. In order to explain why the shadow is 20 metres long. Indeed, this is a <em>explanation-seeking why-question</em> and a possible answer could be the following: The light rays from the sun hit the flagpole (15 metres high), the sun’s elevation angle is 37° and light travels in straight lines. The trigonometric calculation <span class="math inline">\(tan(37°) = 15/20\)</span> demonstrates that the flagpole will cast a shadow of 20 metres long. This example can be found in both <span class="citation">(<a href="#ref-rosenberg2019philosophy">Rosenberg and McIntyre 2019</a>)</span> and <span class="citation">(<a href="#ref-okasha-pos">Okasha 2016</a>)</span>.</p>
<pre><code>General Law      (Light travels in straight lines)
General Law      (Trigonometric laws)
Particular Fact  (Flagpole is 15 metres high)
Particular Fact  (Sun&#39;s angle of elevation is 37°)
---------
Phenomenon to be explained (Shadow is 20 metres long)</code></pre>
<p>This explanation can be structured according to Hempel’s schema and indeed fits Hempel’s covering law model. However, when we swap the <em>explanandum</em> with the particular fact that the flagpole is 15 metres high, a problem arises. The explanation still complies with the covering law pattern, but it would be rather odd to regard it as an explanation of why the flagpole is 15 metres high. In this case, we know that the height of the flagpole is not conditioned by the sun’s angle of elevation but rather because it was manufactured with such height. We can <em>calculate</em> or <em>predict</em> its height but this height will not change upon the other variables, so they do not <em>explain</em> the flagpole height.</p>
<pre><code>General Law      (Light travels in straight lines)
General Law      (Trigonometric laws)
Particular Fact  (Shadow is 20 metres long)
Particular Fact  (Sun&#39;s angle of elevation is 37°)
---------
Phenomenon to be explained (Flagpole is 15 metres high)</code></pre>
<p>The moral of this example is that the concept of explanation showcases an important <strong>asymmetry</strong>. The length of the shadow can be explained by the height of the flagpole, given aforementioned general laws. But this does not happen in the other direction. In general, if <span class="math inline">\(x\)</span> explains <span class="math inline">\(y\)</span>, then it will not be true that <span class="math inline">\(y\)</span> explains <span class="math inline">\(x\)</span> given the same laws and facts. Explanation is then an asymetric relation and Hempel’s covering law model does not respect such asymmetry. Information that allow us to predict a fact before we know it does not serve to explain that very same fact after we know it, which <strong>contradicts Hempel’s thesis</strong>.
The general conclusion is that a good explanation of a phenomenon should contain information that is relevant to the phenomenon’s occurrence.</p>
<div id="explanation-and-causality" class="section level3 hasAnchor" number="2.7.1">
<h3><span class="header-section-number">2.7.1</span> Explanation and causality<a href="scientific-inference.html#explanation-and-causality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are alternatives to the covering law model that help us understanding scientific explanation. For many, explaining a phenomenon is simply to say what caused it. Obviously, causality is also an asymmetric relation. If a faulty appliance caused a fire, then is clear that the fire did not cause the appliance’s failure. The asymmetry of explanation derives from the asymmetry of causality.</p>
<p>However, the criticism against Hempel covering law is a bit unfair as he was an empiricist. Empiricists are sceptical about the concept of causality and argue that all our knowledge comes from experience. David Hume argued that is impossible to experience causal relations, and that causality is just what we humans project to understand the world.</p>
<p>There are however some examples were explanation and causality do not match. For example, to say that an object’s temperature is the average kinetic energy of its molecules is to explain what temperature <em>is</em>, but this does not yield the cause of such temperature.</p>
<p>The law <span class="math inline">\(PV = nRT.\)</span> explains the temperature of a gas at equilibrium by appeal to its pressure and the volume it takes up. But volume and pressure cannot be <em>causes</em> of temperature since all of them — the temperature, the volume, and the pressure — vary, in the way the law describes, instantaneously. The changes in volume at one time do not cause changes in temperature at a later time; instead, the change in temperature occurs during exactly the same interval that pressure is changing <span class="citation">(<a href="#ref-rosenberg2019philosophy">Rosenberg and McIntyre 2019</a>)</span>. The nature of causation is still an open debate, but most philosophers have agreed that causes somehow necessitate their effects and that mere regularity cannot express this necessity.</p>
<p>Another example, this time from <span class="citation">(<a href="#ref-book-of-why">Pearl and Mackenzie 2018</a>)</span>, show us the gap between causal vocabulary and ordinary scientific vocabulary. Consider the problem of expressing the following causal relationship: The barometer reading <span class="math inline">\(B\)</span> tracks the atmospheric pressure <span class="math inline">\(P\)</span>. We can write down the relationship as <span class="math inline">\(B = kP\)</span>, where <span class="math inline">\(k\)</span> is a constant of proportionality. Thanks to algebra we can rewrite the equation in multiple ways such as: <span class="math inline">\(P = B/k\)</span>, <span class="math inline">\(k = B/P\)</span>, or <span class="math inline">\(B-kP = 0\)</span>. They mean the same and given two of the variables we can calculate the third. But in these equations there is no account of directionality. We cannot express that is the pressure which <em>causes</em> the barometer to change and not the other way around. Similarly, we cannot express the fact that the singing of the rooster <em>does not cause</em> the sun to rise. Why have scientists not captured such facts in formulas as is done in other areas like mechanics, geometry or optics? For a better understanding of causation and its role in data science I recommend you the Book of Why <span class="citation">(<a href="#ref-book-of-why">Pearl and Mackenzie 2018</a>)</span>.</p>
<blockquote>
<p>Data can tell you that the people who took a medicine recovered faster than those who did not take it, but they can’t tell you why. — Book of Why</p>
</blockquote>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>In the biological and social sciences, instead of strict laws one finds statements of probabilities, or statistical regularities, and explanations that appeal to them. In the medical contexts, explanations often employ relations that are reported in statistical form in order to express causal relationships. For instance, it is accepted that smoking causes lung cancer because it is associated with a big increase in the probability of contracting lung cancer. Nonetheless, we know that <strong>statistical correlation does not warrant causal connection</strong>. There are some problems with the statement that smoking causes cancer. Some smokers never contract cancer, while some lung cancer victims never smoked. The latter issue is easy, smoking is not the only cause of lung cancer. However, the first problem is harder to tackle.</p>
<blockquote>
<p>Smoking can be said to cause cancer if and only if, among all the different background conditions we know about (heredity, diet, exercise, air pollution, etc.), there is no correlation between smoking and a lower than average incidence of lung cancer, and in one or more of these background conditions, smoking is correlated with a higher incidence in lung cancer rates. — <span class="citation">(<a href="#ref-rosenberg2019philosophy">Rosenberg and McIntyre 2019</a>)</span></p>
</blockquote>
</div>
</div>
</div>
<div id="examples-1" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Examples<a href="scientific-inference.html#examples-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="semmelweis" class="section level3 hasAnchor" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> The problem is in your hands!<a href="scientific-inference.html#semmelweis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<figure class="wrap-figure">
<img src="Figures/Semmelweis.jpg">
<figcaption>
Dr. Ignaz Semmelweis, aged 42 in 1860 copperplate engraving by Jenő Doby.
</figcaption>
</figure>
<p>Ignaz Semmelweis, a Hungarian physician, was a member of the First Maternity Division at the Vienna General Hospital from 1844 to 1848. Semmelweis was distressed to find a big proportion of the women who delivered their babies contracted a serious and often fatal illness known as childbed fever. In 1844, 8.2% of mothers died from the disease, 6.8% in 1845 and 11.4% in 1846. However, in the adjacent Second Maternity Division which had as many women as the first, the death toll was much lower (2.3%, 2% and 2.7% respectively).</p>
<p>From this moment on, various explanations were considered, subjected to test and then rejected.</p>
<p>The first explanation attributed the issue to “epidemic influences” described as “atmospheric-cosmic-telluric changes” spreading over districts and causing childbed fever. This hypothesis did not explain why the first division had more cases than the second. Neither explained the lack of cases in the city of Vienna. Epidemics such as cholera are not so selective. Finally, Semmelweis notes that women who had to give birth in the street on their way to the hospital had a lower death rate than the average for the first division.</p>
<table>
<colgroup>
<col width="23%" />
<col width="37%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th>Year</th>
<th>First Division Mortality (%)</th>
<th>Second Division Mortality (%)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1844</td>
<td>8.20</td>
<td>2.30</td>
</tr>
<tr class="even">
<td>1845</td>
<td>6.80</td>
<td>2.00</td>
</tr>
<tr class="odd">
<td>1846</td>
<td>11.40</td>
<td>2.70</td>
</tr>
</tbody>
</table>
<p>On a different view, overcrowding of the first division was proposed as a cause but Semmelweis pointed out that the second division was much crowded. Moreover, there were no differences regarding diet or general care of the patients.</p>
<p>In 1846, a commission was appointed to investigate the issue, which attributed the prevalence to injuries in the first division resulting from rough examination by medical students. Semmelweis refuted this view since: a) the injuries of birth itself are more extensive than those from the examination. b) midwives’ examinations from the second division were similar. c) as a consequence of the commission the number of students was halved and the examinations were reduced to a minimum. The mortality increased.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ignazhyp"></span>
<img src="Figures/IgnazSemmelweisHyp.png" alt="Summary of the hypotheses considered to explain the deaths in the first division." width="75%" />
<p class="caption">
Figure 2.5: Summary of the hypotheses considered to explain the deaths in the first division.
</p>
</div>
<p>After considering peculiar conjectures (e.g. delivery position, priest visits), an accident gave Semmelweis the decisive clue. In 1847, a colleague of his received a puncture wound in the finger, from the scalpel of a student while performing an autopsy. His colleague died after an illness with similar symptoms to those observed in the victims of childbed fever. Note, that the role of micro-organisms had not yet been recognized at the time. Semmelweis ordered all medical students to wash their hands with a chlorinated lime solution before making examinations, especially after performing dissections in the autopsy room.</p>
<p>Mortality fell to 1.27% in the First Division compared to 1.33% in the second. In further support of his hypothesis, Semmelweis notes that midwives from the Second Division did not dissect cadavers. This also explained the “street births” low mortality since women were rarely examined as they already gave birth. Semmelweis concluded that the cause was infection by cadaveric material and putrid matter.</p>
<p>At the time, Semmelweis’s findings lacked a scientific explanation. This understanding only emerged in the 1860s and 1870s, thanks to the work of Louis Pasteur, Joseph Lister, and others who advanced the germ theory of disease. Semmelweis’s idea that a single cause existed, centered solely on cleanliness, was considered radical at that time and was mostly ignored, rejected, or mocked. He was politically dismissed from the hospital and faced harassment from the medical community in Vienna, ultimately leading him to relocate to Budapest. People close to him, including his wife, believed he was losing his mind, and in 1865, he was admitted to a lunatic asylum, where he died just 14 days later. Semmelweis’s practices gained widespread acceptance only years after his death, when Louis Pasteur further refined the germ theory of disease, providing a theoretical basis for Semmelweis’s observations.</p>
<div class="rnote">
<p>Example and discussion extracted from Chapter 2 of <span class="citation">(<a href="#ref-hempel-pos">Hempel 1966</a>)</span></p>
</div>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>Notice how this story relates to data science in many aspects. First, Semmelweis considered multiple factors (diet, division sizes, etc.) and collected information about them. Similarly, in data science, the quality and variety of data can significantly help in the data analysis. Semmelweis formulated a hypothesis based on his observations and sought to test it through intervention (handwashing). In data science, hypotheses are also formulated and contrasted using data to compare pre-intervention and post-intervention observations. The medical community initially rejected Semmelweis’s hypothesis despite evidence. This reflects a common bias in scientific inquiry where existing beliefs can overshadow new findings. In data science, <strong>confirmation bias</strong> can lead researchers to favour results that confirm pre-existing hypotheses rather than exploring contrary evidence. Semmelweis’s approach demonstrates the iterative process of refining hypotheses based on new data and observations. Importantly, data showed that Semmelweis was probably right, but only after the advent of the germ theory an explanation could be provided. This shows the importat role of domain knowledge in the interpretation of data-driven results.</p>
</div>
<div id="how-a-hypothesis-is-tested" class="section level4 hasAnchor" number="2.8.1.1">
<h4><span class="header-section-number">2.8.1.1</span> How a hypothesis is tested<a href="scientific-inference.html#how-a-hypothesis-is-tested" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Some conjectures (e.g. differences in diet, crowding or care) were trivial to test as their assumptions conflict with readily observable facts (e.g., there were no differences in diet across divisions). Others were not as straightforward and required certain interventions. For example, changing the routine of the priest or the birth position. If the hypothesis <span class="math inline">\(H\)</span> is true, then certain observable events <span class="math inline">\(I\)</span> should occur (e.g. drop in mortality) under specified circumstances (e.g. lateral delivery position). Semmelweis experiment showed the test implication to be false (he changed the routine of the priest or the delivery position and did not find different results in mortality), rejecting the hypothesis in consequence.</p>
<pre><code>If H is true, then so is I.
But (as the evidence shows) I is not true.
---------------
H is not true.</code></pre>
<p>This is a good example of <em>modus tollens</em> (see <a href="scientific-inference.html#modus">2.2.2</a>). However, let us consider now the case where observation or experiment confirms the test implication <span class="math inline">\(I\)</span>. From the hypothesis that childbed fever is blood poisoning produced by cadaveric matter, Semmelweis infers that antiseptic measures will reduce mortality rates. Now, the experiment shows the test implication to be true. But this favourable outcome does not prove the hypothesis true.</p>
<pre><code>If H is true, then so is I.
(as the evidence shows) I is true.
---------------
H is true.</code></pre>
<p>This reasoning is deductively invalid and referred to as the <em>fallacy of affirming the consequent</em> (see <a href="scientific-inference.html#modus">2.2.2</a>). The conclusion may be false even if its premises are true. Thus, even if many implications of a hypothesis have been confirmed by tests, the hypothesis may still be false.</p>
<pre><code>If H is true, then so are I1, I2, ...
(as the evidence shows) I1, I2, ... are all true.
---------------
H is true.</code></pre>
<p>Above’s argument still commits the fallacy. Note that although the many tests do not provide conclusive proof for a hypothesis, they provide at least some support or confirmation for it.</p>
<div class="rnote">
<p>Chapter 4 of <span class="citation">(<a href="#ref-hempel-pos">Hempel 1966</a>)</span> continues on this.</p>
</div>
<blockquote>
<p>In the absence of unfavorable evidence, the confirmation of a hypothesis will normally be regarded as increasing with the number of favorable test findings. […] <strong>the increase in confirmation effected by one new favorable instance will generally become smaller as the number of previously established favorable instances grows.</strong> If thousands of confirmatory cases are already available, <strong>the addition of one more favorable finding will raise the confirmation but little.</strong></p>
</blockquote>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>Notice how ML models can also be affected by the previous statement. Many researchers blindly rely on the dogma <em>the more data, the merrier</em> but is not just the amount of data that matters but also its variety. The greater the variety, the stronger the resulting support for the trained model.</p>
</div>
</div>
</div>
<div id="wason" class="section level3 hasAnchor" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span> Wason selection task<a href="scientific-inference.html#wason" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wason-cards"></span>
<img src="Figures/wason_cards.png" alt="Wason selection task or four-card problem." width="25%" />
<p class="caption">
Figure 2.6: Wason selection task or four-card problem.
</p>
</div>
<p>Consider the following hypothetico-deductive reasoning problem created by Peter Cathcart Wason employing the logical rule of implication:</p>
<blockquote>
<p>You are shown a set of four cards placed on a table, each of which has a number on one side and a colored patch on the other side. The visible faces of the cards show 3, 8, red and brown. Which card(s) must you turn over in order to test the truth of the proposition that if a card shows an even number on one face, then its opposite face is red?</p>
</blockquote>
<p>Hypothesis H: “If a card shows an even number on one face, then its opposite face is red”</p>
<p>Test whether H is false. Which consequences of H do you need to consider - i.e. which cards do you need to turn over? Under what conditions would this statement be false?</p>
<!-- - When a card is even and its opposite face is not red. => $H$ is falsified by observing a brown even-number card.
- need to turn over even-number cards and brown cards! -->
<p>These are the possible situations:</p>
<ul>
<li>If the 3 card is red (or brown), that doesn’t violate the rule. The rule makes no claims about odd numbers. (Denying the antecedent)</li>
<li>If the 8 card is not red, it violates the rule. (Modus ponens)</li>
<li>If the red card is odd (or even), that doesn’t violate the rule. The red color is not exclusive to even numbers. (Affirming the consequent)</li>
<li>If the brown card is even, it violates the rule. (Modus tollens)</li>
</ul>
<table>
<caption>Truth table for <span class="math inline">\(p \rightarrow q\)</span>. </br> <strong>(*)</strong> In instances of <em>modus ponens</em> we assume as premises that <span class="math inline">\(p \rightarrow q\)</span> is true and <span class="math inline">\(p\)</span> is true. Only one line of the truth table — the first — satisfies these two conditions (<span class="math inline">\(p\)</span> and <span class="math inline">\(p \rightarrow q\)</span>). On this line, <span class="math inline">\(q\)</span> is also true. Therefore, whenever <span class="math inline">\(p \rightarrow q\)</span> is true and <span class="math inline">\(p\)</span> is true, <span class="math inline">\(q\)</span> must also be true. </br> <strong>(**)</strong> In instances of <em>modus tollens</em> we assume as premises that <span class="math inline">\(p \rightarrow q\)</span> is true and <span class="math inline">\(q\)</span> is false. There is only one line of the truth table — the fourth line — which satisfies these two conditions. In this line, <span class="math inline">\(p\)</span> is false. Therefore, in every instance in which <span class="math inline">\(p \rightarrow q\)</span> is true and <span class="math inline">\(q\)</span> is false, <span class="math inline">\(p\)</span> must also be false.</caption>
<thead>
<tr class="header">
<th align="left"><span class="math inline">\(p\)</span></th>
<th align="left"><span class="math inline">\(q\)</span></th>
<th align="right"><span class="math inline">\(p \rightarrow q\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">T</td>
<td align="left">T</td>
<td align="right">*T</td>
</tr>
<tr class="even">
<td align="left">T</td>
<td align="left">F</td>
<td align="right">F</td>
</tr>
<tr class="odd">
<td align="left">F</td>
<td align="left">T</td>
<td align="right">T</td>
</tr>
<tr class="even">
<td align="left">F</td>
<td align="left">F</td>
<td align="right">**T</td>
</tr>
</tbody>
</table>


<p>There are two ways to face the problem and reach the solution. First, we can choose the cards based on <em>modus ponens</em> and <em>modus tollens</em> as follows: From <em>modus ponens</em> we need to check the cards that are even. If even cards are not red, then the claim is false.</p>
<pre><code>If even, then red. (claim)
even               (obs)
-----------------
Therefore, red.    (conclusion)</code></pre>
<p>From <em>modus tollens</em> we need to check the cards that are not red i.e. brown. If brown cards are even, then the claim is false.</p>
<pre><code>If even, then red. (claim)
not red            (obs)
-----------------
Therefore, not even (conclusion)</code></pre>
<p>Another approach is to take the truth table of <span class="math inline">\(p \rightarrow q\)</span> and take the case where <span class="math inline">\(p \rightarrow q\)</span> is false - second line - i.e. when <span class="math inline">\(p\)</span> is true and <span class="math inline">\(q\)</span> is false or for our case, when a card is even and its back not red (so brown). From this we need to take the cards that are <span class="math inline">\(p\)</span> and <span class="math inline">\(\lnot q\)</span> i.e. even cards and brown cards.</p>
</div>
<div id="u.s.a.-presidents" class="section level3 hasAnchor" number="2.8.3">
<h3><span class="header-section-number">2.8.3</span> U.S.A. Presidents<a href="scientific-inference.html#u.s.a.-presidents" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:us-presidents"></span>
<img src="Figures/usa_presidents.jpeg" alt="Presidents of the United States of America as of 2021." width="100%" />
<p class="caption">
Figure 2.7: Presidents of the United States of America as of 2021.
</p>
</div>
<p>Suppose we aim to predict whether the next president of the United States of America will be a woman or not. If we rely solely on the gender of previous presidents, by induction we will predict a zero chance. But by understanding how a person becomes a presidential candidate, and how previously became a candidate for their party, we can take into account the network of people involved in the process and recalculate our forecast with higher precision. In this case the rules are clearly defined in the law. Pouring these bits of domain knowledge into our model will show that chances are increasing over time. Encoding the rules behind the data heavily increased the robustness and precision of our model. Thanks to these rules our inference became deductive rather than inductive, since the conclusion necessarily follows from the premises; and as long as the premises are true the conclusion will also be true.</p>
<p>We can identify two issues in the first approach of our example: First, partial data can misrepresent the underlying phenomena that shapes the data, producing a model that does not resemble the real world. This is especially notable in the case of bias and confounders which are further aggravated by the lack of domain knowledge in designing the solutions. The second issue relates to induction. Contrary to deduction, where the truth of the premises guarantees the truth of the conclusion, inductive inferences are <em>ampliative</em> — since whose conclusions go beyond what is contained in their premises — and their conclusions could be totally wrong even if infinitely many examples confirm them <span class="citation">(<a href="#ref-bergadano1991problem">Bergadano 1991</a>)</span>. This <em>ampliative</em> factor has also an amplifying effect over the partial data from which we infer a conclusion. In this case, considering only the final results of the elections amplified the bias derived from a partial collection of the data, reducing the chances of women being predicted as president to zero.</p>
<div class="rnote">
<p>From <span class="citation">(<a href="#ref-vega2021hume">Vega 2021</a>)</span>.</p>
</div>
</div>
<div id="yersinia-pestis" class="section level3 hasAnchor" number="2.8.4">
<h3><span class="header-section-number">2.8.4</span> Yersinia pestis<a href="scientific-inference.html#yersinia-pestis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<figure class="wrap-figure">
<img src="Figures/yersin.jpg">
<figcaption>
Alexandre Yersin.
</figcaption>
</figure>
<p>This excerpt from Plague and Cholera is a great example of how laboratory conditions can act as an unintended auxiliary hypothesis that must be taken into account during research. It was 1894 in Hong Kong and all was set for an intellectual duel between Alexandre Yersin and Kitasato Shibasaburō that eventually unveiled the cause of the disease plague.</p>
<blockquote>
<p>From the moment of his disembarkation in torrential rain, Yersin sees the bodies of plague victims lying in the street, in pools of standing water, in parks, aboard moored junks. British soldiers, acting on authority, remove the sick and empty their houses, pile everything up and set fire to it. […]</p>
</blockquote>
<blockquote>
<p>‘I notice many dead rats lying on the ground.’ The first note scribbled by Yersin that evening concerns sewers spewing out decomposed bodies of rats. Since Camus, that has seemed obvious, but not then. […] By telegram, and as a concession to diplomacy, British governor Sir William Robinson gives Yersin explicit authority to come and study plague in Hong Kong. However, bad faith on the British side is clear to see, and it is even worse with the Japanese team under Shibasaburo Kitasato, who intends to reserve all autopsies for himself. […]</p>
</blockquote>
<blockquote>
<p>Never again, in the history of humanity, will there be such an opportunity to become the person who vanquished plague. A few more weeks of devastation will mean a few thousand more bodies to study. […] Kitasato, though, has a handicap advantage. Not a single cadaver will be placed at Yersin’s disposal. […]</p>
</blockquote>
<blockquote>
<p>For Yersin’s benefit he [Father Vigano] arranges, in just two days, to have a bamboo-framed, straw-covered hut erected near the Alice Memorial Hospital. With the matter of his living quarters and laboratory settled, Yersin installs a camp bed, unlocks the cabin trunk, and sets out microscope and test tubes. Vigano then greases the palms of the British sailors in charge of the hospital mortuary, where the bodies are stacked prior to being cremated or buried, and buys several from them. Yersin proceeds to ply his scalpel. […] ‘The bubo is quite distinct. In less than a minute I have it out and take it up to my laboratory. I make a quick preparation and place it under the microscope. One glance reveals a veritable mess of microbes, all similar. They are small stubby rods with rounded ends.’ […] Yersin becomes the first human being to observe the plague bacillus, as Pasteur was the first to observe those of silkworm pebrine, ovine anthrax, chicken cholera and canine rabies.</p>
</blockquote>
<blockquote>
<p>What Kitasato describes, having sampled organs and blood and disregarded the bubo, is the pneumococcus of a collateral infection, which he mistakes for the plague bacillus. Without luck, without chance, genius is nothing. The agnostic Yersin is blessed by the gods. Subsequent studies will show that one reason for Kitasato’s failure is that he enjoyed the benefits of a proper hospital laboratory, including an incubator set at the temperature of the human body, a temperature at which pneumococcus proliferates, whereas the plague bacillus develops best at approximately twenty-eight degrees centigrade, the mean temperature in Hong Kong at that time of year and the temperature at which Yersin, with no incubator, conducts his observations.</p>
</blockquote>
<div class="rnote">
<p>From Plague and Cholera, by Patrick Deville. <span class="citation">(<a href="#ref-deville2014plague">Deville 2014</a>)</span></p>
</div>
<p>I absolutely recommend this book about Alexandre Yersin life. A Swiss-French physician and bacteriologist, pupil of Louis Pasteur, that trying to run away from himself became an agronomist and an explorer of the highlands of Vietnam and Cambodia.</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>In scientific and data science research, having too much control over experimental conditions can limit our understanding of complex phenomena. The text illustrates this through the contrasting approaches of Alexandre Yersin and Kitasato Shibasaburō during their investigation of the plague. Yersin’s observations were conducted in a hut laboratory without the ideal conditions, which allowed him to discover the plague bacillus by directly examining the natural state of the environment. In contrast, Kitasato’s access to a fully equipped hospital laboratory may have created an environment that favoured the growth of contaminants, leading to his misidentification of the pneumococcus as the plague bacillus. This situation highlights the importance of balancing control (like in a laboratory setting) and real-world conditions in scientific inquiry; while controlled experiments are essential for reproducibility, they can also obscure critical variables and insights that emerge from more natural settings. Thus, understanding how much control to exert is crucial for ensuring the validity and applicability of scientific findings.</p>
</div>
</div>
<div id="risks-of-induction-and-non-epistemic-values-in-ml" class="section level3 hasAnchor" number="2.8.5">
<h3><span class="header-section-number">2.8.5</span> Risks of induction and non-epistemic values in ML<a href="scientific-inference.html#risks-of-induction-and-non-epistemic-values-in-ml" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>I recommend the following <a href="https://simonfischer.me/the-necessity-of-non-epistemic-values-in-machine-learning-modelling/">blog post</a> from Simon Fischer. I copy a fragment here but the whole article is very interesting.</p>
<blockquote>
<p>For example, when we think of the problem of <em>filter bubbles</em> we are less and less confronted with opposing world views. Moreover, the idea that the future resembles the past, gives us examples of how Amazon has developed an algorithm for recruiting new staff which only hired males (Dastin, 2018). Even though the model might be correct from an epistemological point of view, such as accuracy or simplicity, it questions non-epistemic values, such as fairness. […]</p>
</blockquote>
<blockquote>
<p>Another problem arises with regard to Popper’s falsification approach. We cannot be sure what we have falsified: the hypothesis, the auxiliary assumptions, or even both? Consequently, under these considerations, it appears that the risks of drawing conclusions from machine learning outweigh the benefits. […]</p>
</blockquote>
<blockquote>
<p>In the case of Amazon the false hypothesis and background assumptions were found rather quickly. But there could be more subtle biases around us which we are not yet aware. This again shows the twofold consequences in terms of inductive risk: The danger of scientists implementing these biases into the algorithms and the benefit of amplifying these biases, and thus making them visible to us. — <span class="citation">(<a href="#ref-fischer_2020">Fischer 2020</a>)</span></p>
</blockquote>
<!--- https://en.wikipedia.org/wiki/Underdetermination Any phenomenon can be explained by a multiplicity of hypotheses. How, then, can data ever be sufficient to prove a theory? This is the "epistemological problem of the indeterminacy of data to theory".

  -->
<!--

## Takeaway Messages

1. A
2. B
3. C
4. D
5. E

-->

</div>
</div>
</div>
<h3> References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-bergadano1991problem" class="csl-entry">
Bergadano, Francesco. 1991. <span>“The Problem of Induction and Machine Learning.”</span> In <em>IJCAI</em>.
</div>
<div id="ref-deville2014plague" class="csl-entry">
Deville, Patrick. 2014. <em>Plague and Cholera</em>. Hachette UK.
</div>
<div id="ref-diez1997fundamentos" class="csl-entry">
Dı́ez, José A, and Carles Ulises Moulines. 1997. <span>“Fundamentos de Filosof<span>ı́</span>a de La Ciencia.”</span>
</div>
<div id="ref-domingos2015master" class="csl-entry">
———. 2015. <em>The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World</em>. Basic Books.
</div>
<div id="ref-dotan2020theory" class="csl-entry">
Dotan, Ravit. 2020. <span>“Theory Choice, Non-Epistemic Values, and Machine Learning.”</span> <em>Synthese</em>, 1–21.
</div>
<div id="ref-sep-abduction" class="csl-entry">
Douven, Igor. 2021. <span>“<span>Abduction</span>.”</span> In <em>The <span>Stanford</span> Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, <span>S</span>ummer 2021. <a href="https://plato.stanford.edu/archives/sum2021/entries/abduction/" class="uri">https://plato.stanford.edu/archives/sum2021/entries/abduction/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-fischer_2020" class="csl-entry">
Fischer, Simon. 2020. <span>“The Necessitiy of Non-Epistemic Values in Machine Learning Modelling.”</span> <em>Online and Offline (Being Either Connected or Disconnected)</em>. <a href="https://simonfischer.me/the-necessity-of-non-epistemic-values-in-machine-learning-modelling/">https://simonfischer.me/the-necessity-of-non-epistemic-values-in-machine-learning-modelling/</a>.
</div>
<div id="ref-phlogiston" class="csl-entry">
Grünbaum, Adolf. 1976. <span>“Ad Hoc Auxiliary Hypotheses and Falsificationism.”</span> <em>The British Journal for the Philosophy of Science</em> 27 (4): 329–62. <a href="http://www.jstor.org/stable/686862">http://www.jstor.org/stable/686862</a>.
</div>
<div id="ref-sep-pseudo-science" class="csl-entry">
Hansson, Sven Ove. 2021. <span>“<span class="nocase">Science and Pseudo-Science</span>.”</span> In <em>The <span>Stanford</span> Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, <span>S</span>ummer 2021. <a href="https://plato.stanford.edu/archives/sum2021/entries/pseudo-science/" class="uri">https://plato.stanford.edu/archives/sum2021/entries/pseudo-science/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-hempel-pos" class="csl-entry">
Hempel, Carl G. 1966. <em>Philosophy of Natural Science</em>. Book. Prentice-Hall Englewood Cliffs, N.J.
</div>
<div id="ref-sep-induction-problem" class="csl-entry">
Henderson, Leah. 2020. <span>“<span class="nocase">The Problem of Induction</span>.”</span> In <em>The <span>Stanford</span> Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, <span>S</span>pring 2020. <a href="https://plato.stanford.edu/archives/spr2020/entries/induction-problem/" class="uri">https://plato.stanford.edu/archives/spr2020/entries/induction-problem/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-howson2006scientific" class="csl-entry">
Howson, Colin, and Peter Urbach. 2006. <em>Scientific Reasoning: The Bayesian Approach</em>. Open Court Publishing.
</div>
<div id="ref-hume1739treatise" class="csl-entry">
Hume, David. 1739. <em>A Treatise Upon Human Nature</em>. Oxford: Oxford University Press.
</div>
<div id="ref-jun2016frequentist" class="csl-entry">
Jun, Sunghae. 2016. <span>“Frequentist and Bayesian Learning Approaches to Artificial Intelligence.”</span> <em>International Journal of Fuzzy Logic and Intelligent Systems</em> 16 (2): 111–18.
</div>
<div id="ref-sep-reasoning-defeasible" class="csl-entry">
Koons, Robert. 2021. <span>“<span>Defeasible Reasoning</span>.”</span> In <em>The <span>Stanford</span> Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, <span>F</span>all 2021. <a href="https://plato.stanford.edu/archives/fall2021/entries/reasoning-defeasible/" class="uri">https://plato.stanford.edu/archives/fall2021/entries/reasoning-defeasible/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-ladyman2012understanding" class="csl-entry">
Ladyman, James. 2012. <em>Understanding Philosophy of Science</em>. Routledge.
</div>
<div id="ref-okasha-pos" class="csl-entry">
Okasha, Samir. 2016. <em>Philosophy of Science: Very Short Introduction</em>. Oxford University Press.
</div>
<div id="ref-orloffcomparison" class="csl-entry">
Orloff, Jeremy, and Jonathan Bloom. 2014. <span>“Comparison of Frequentist and Bayesian Inference. Class 20, 18.05, Spring 2014.”</span>
</div>
<div id="ref-pearl2014probabilistic" class="csl-entry">
———. 2014. <em>Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</em>. Elsevier.
</div>
<div id="ref-book-of-why" class="csl-entry">
Pearl, Judea, and Dana Mackenzie. 2018. <em>The Book of Why: The New Science of Cause and Effect</em>. 1st ed. USA: Basic Books, Inc.
</div>
<div id="ref-percival2015confirmation" class="csl-entry">
Percival, Ray Scott. 2015. <span>“Confirmation Versus Falsificationism.”</span>
</div>
<div id="ref-rosenberg2019philosophy" class="csl-entry">
Rosenberg, Alex, and Lee McIntyre. 2019. <em>Philosophy of Science: A Contemporary Introduction</em>. Routledge.
</div>
<div id="ref-russell2001problems" class="csl-entry">
Russell, Bertrand. 1912. <em>The Problems of Philosophy</em>.
</div>
<div id="ref-sep-logic-nonmonotonic" class="csl-entry">
Strasser, Christian, and G. Aldo Antonelli. 2019. <span>“<span class="nocase">Non-monotonic Logic</span>.”</span> In <em>The <span>Stanford</span> Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, <span>S</span>ummer 2019. <a href="https://plato.stanford.edu/archives/sum2019/entries/logic-nonmonotonic/" class="uri">https://plato.stanford.edu/archives/sum2019/entries/logic-nonmonotonic/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-sep-popper" class="csl-entry">
Thornton, Stephen. 2021. <span>“<span>Karl Popper</span>.”</span> In <em>The <span>Stanford</span> Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, <span>S</span>pring 2021. <a href="https://plato.stanford.edu/archives/spr2021/entries/popper/" class="uri">https://plato.stanford.edu/archives/spr2021/entries/popper/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-vega2021hume" class="csl-entry">
Vega, Carlos. 2021. <span>“From Hume to Wuhan: An Epistemological Journey on the Problem of Induction in COVID-19 Machine Learning Models and Its Impact Upon Medical Research.”</span> <em>IEEE Access</em> 9: 97243–50. <a href="https://doi.org/10.1109/ACCESS.2021.3095222">https://doi.org/10.1109/ACCESS.2021.3095222</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="scientific-goals-methods-and-knowledge.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="empirical-practices.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["POSDE_bookdown.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
