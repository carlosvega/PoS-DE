<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Empirical Practices and Models | Applied Philosophy of Science and Data Ethics</title>
  <meta name="description" content="This class book gathers the contents addressed in the course Applied Philosophy of Science and Data Ethics from the Master of Data Science at the University of Luxembourg. This class book will introduce basic philosophical and scientific concepts supported by examples and discussion." />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Empirical Practices and Models | Applied Philosophy of Science and Data Ethics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This class book gathers the contents addressed in the course Applied Philosophy of Science and Data Ethics from the Master of Data Science at the University of Luxembourg. This class book will introduce basic philosophical and scientific concepts supported by examples and discussion." />
  <meta name="github-repo" content="carlosvega/PoS-DE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Empirical Practices and Models | Applied Philosophy of Science and Data Ethics" />
  
  <meta name="twitter:description" content="This class book gathers the contents addressed in the course Applied Philosophy of Science and Data Ethics from the Master of Data Science at the University of Luxembourg. This class book will introduce basic philosophical and scientific concepts supported by examples and discussion." />
  

<meta name="author" content="Dr. Carlos Vega" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="scientific-inference.html"/>
<link rel="next" href="stats-abuse.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-79429674-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-79429674-2');
</script>


<script type="text/javascript">
mattcrump=1;
</script>
 -->


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><strong>APPLIED PHILOSOPHY OF SCIENCE </br>AND DATA ETHICS</strong></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-presentation"><i class="fa fa-check"></i>Course presentation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-at-ul"><i class="fa fa-check"></i>Course at UL</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#disclaimer"><i class="fa fa-check"></i>Disclaimer</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-outcomes"><i class="fa fa-check"></i>Learning outcomes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-course"><i class="fa fa-check"></i>About this course</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-class-book"><i class="fa fa-check"></i>About this class book</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the author</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributing-to-the-book"><i class="fa fa-check"></i>Contributing to the book</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html"><i class="fa fa-check"></i><b>1</b> Scientific Goals, Methods and Knowledge</a>
<ul>
<li class="chapter" data-level="1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#what-is-science"><i class="fa fa-check"></i><b>1.1</b> What is Science?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#scientific-goals-and-knowledge"><i class="fa fa-check"></i><b>1.1.1</b> Scientific Goals and Knowledge</a>
<ul>
<li class="chapter" data-level="1.1.1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#data-information-and-knowledge"><i class="fa fa-check"></i><b>1.1.1.1</b> Data, information and knowledge</a></li>
</ul></li>
<li class="chapter" data-level="1.1.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#what-is-philosophy-of-science"><i class="fa fa-check"></i><b>1.1.2</b> What is Philosophy of Science?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#sci-method"><i class="fa fa-check"></i><b>1.2</b> The scientific method</a></li>
<li class="chapter" data-level="1.3" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#methodology"><i class="fa fa-check"></i><b>1.3</b> Methodology</a></li>
<li class="chapter" data-level="1.4" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#examples"><i class="fa fa-check"></i><b>1.4</b> Examples</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#neptune-vulcan"><i class="fa fa-check"></i><b>1.4.1</b> Neptune and Vulcan</a></li>
<li class="chapter" data-level="1.4.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#michelson-morley"><i class="fa fa-check"></i><b>1.4.2</b> The most famous “failed” experiment</a></li>
<li class="chapter" data-level="1.4.3" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#eddington-expeditions"><i class="fa fa-check"></i><b>1.4.3</b> Eddington expeditions</a></li>
<li class="chapter" data-level="1.4.4" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#smoke-debate"><i class="fa fa-check"></i><b>1.4.4</b> The smoke debate</a></li>
<li class="chapter" data-level="1.4.5" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#kekulés-dream"><i class="fa fa-check"></i><b>1.4.5</b> Kekulé’s dream</a></li>
<li class="chapter" data-level="1.4.6" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#why-most-published-research-findings-are-false"><i class="fa fa-check"></i><b>1.4.6</b> Why Most Published Research Findings Are False</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scientific-inference.html"><a href="scientific-inference.html"><i class="fa fa-check"></i><b>2</b> Scientific Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scientific-inference.html"><a href="scientific-inference.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="scientific-inference.html"><a href="scientific-inference.html#types-of-inferences"><i class="fa fa-check"></i><b>2.2</b> Types of inferences</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="scientific-inference.html"><a href="scientific-inference.html#deduction"><i class="fa fa-check"></i><b>2.2.1</b> Deduction and Induction</a></li>
<li class="chapter" data-level="2.2.2" data-path="scientific-inference.html"><a href="scientific-inference.html#modus"><i class="fa fa-check"></i><b>2.2.2</b> Modus ponens and Modus tollens</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="scientific-inference.html"><a href="scientific-inference.html#problem-induction"><i class="fa fa-check"></i><b>2.3</b> The problem(s) of induction</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="scientific-inference.html"><a href="scientific-inference.html#david-humes-problem-of-induction"><i class="fa fa-check"></i><b>2.3.1</b> David Hume’s Problem of Induction</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="scientific-inference.html"><a href="scientific-inference.html#the-hypothetico-deductive-method"><i class="fa fa-check"></i><b>2.4</b> The Hypothetico-deductive Method</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="scientific-inference.html"><a href="scientific-inference.html#a-good-hypothesis"><i class="fa fa-check"></i><b>2.4.1</b> A good hypothesis</a></li>
<li class="chapter" data-level="2.4.2" data-path="scientific-inference.html"><a href="scientific-inference.html#falsification"><i class="fa fa-check"></i><b>2.4.2</b> Falsification</a></li>
<li class="chapter" data-level="2.4.3" data-path="scientific-inference.html"><a href="scientific-inference.html#confirmation"><i class="fa fa-check"></i><b>2.4.3</b> Confirmation</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="scientific-inference.html"><a href="scientific-inference.html#other-types-of-inference"><i class="fa fa-check"></i><b>2.5</b> Other types of inference</a></li>
<li class="chapter" data-level="2.6" data-path="scientific-inference.html"><a href="scientific-inference.html#non-monotonic-logic-and-defeasible-reasoning"><i class="fa fa-check"></i><b>2.6</b> Non-Monotonic logic and defeasible reasoning</a></li>
<li class="chapter" data-level="2.7" data-path="scientific-inference.html"><a href="scientific-inference.html#explanation"><i class="fa fa-check"></i><b>2.7</b> Explanation</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="scientific-inference.html"><a href="scientific-inference.html#explanation-and-causality"><i class="fa fa-check"></i><b>2.7.1</b> Explanation and causality</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="scientific-inference.html"><a href="scientific-inference.html#examples-1"><i class="fa fa-check"></i><b>2.8</b> Examples</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="scientific-inference.html"><a href="scientific-inference.html#semmelweis"><i class="fa fa-check"></i><b>2.8.1</b> The problem is in your hands!</a>
<ul>
<li class="chapter" data-level="2.8.1.1" data-path="scientific-inference.html"><a href="scientific-inference.html#how-a-hypothesis-is-tested"><i class="fa fa-check"></i><b>2.8.1.1</b> How a hypothesis is tested</a></li>
</ul></li>
<li class="chapter" data-level="2.8.2" data-path="scientific-inference.html"><a href="scientific-inference.html#wason"><i class="fa fa-check"></i><b>2.8.2</b> Wason selection task</a></li>
<li class="chapter" data-level="2.8.3" data-path="scientific-inference.html"><a href="scientific-inference.html#u.s.a.-presidents"><i class="fa fa-check"></i><b>2.8.3</b> U.S.A. Presidents</a></li>
<li class="chapter" data-level="2.8.4" data-path="scientific-inference.html"><a href="scientific-inference.html#yersinia-pestis"><i class="fa fa-check"></i><b>2.8.4</b> Yersinia pestis</a></li>
<li class="chapter" data-level="2.8.5" data-path="scientific-inference.html"><a href="scientific-inference.html#risks-of-induction-and-non-epistemic-values-in-ml"><i class="fa fa-check"></i><b>2.8.5</b> Risks of induction and non-epistemic values in ML</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="empirical-practices.html"><a href="empirical-practices.html"><i class="fa fa-check"></i><b>3</b> Empirical Practices and Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="empirical-practices.html"><a href="empirical-practices.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="empirical-practices.html"><a href="empirical-practices.html#what-is-an-experiment"><i class="fa fa-check"></i><b>3.2</b> What is an experiment?</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="empirical-practices.html"><a href="empirical-practices.html#observational-studies"><i class="fa fa-check"></i><b>3.2.1</b> Observational studies</a>
<ul>
<li class="chapter" data-level="3.2.1.1" data-path="empirical-practices.html"><a href="empirical-practices.html#natural-experiments"><i class="fa fa-check"></i><b>3.2.1.1</b> Natural experiments</a></li>
<li class="chapter" data-level="3.2.1.2" data-path="empirical-practices.html"><a href="empirical-practices.html#observability"><i class="fa fa-check"></i><b>3.2.1.2</b> Observability</a></li>
<li class="chapter" data-level="3.2.1.3" data-path="empirical-practices.html"><a href="empirical-practices.html#indicators"><i class="fa fa-check"></i><b>3.2.1.3</b> Indicators</a></li>
<li class="chapter" data-level="3.2.1.4" data-path="empirical-practices.html"><a href="empirical-practices.html#data-and-evidence"><i class="fa fa-check"></i><b>3.2.1.4</b> Data and Evidence</a></li>
</ul></li>
<li class="chapter" data-level="3.2.2" data-path="empirical-practices.html"><a href="empirical-practices.html#field-laboratory-and-simulation-experiments"><i class="fa fa-check"></i><b>3.2.2</b> Field, laboratory and simulation experiments</a>
<ul>
<li class="chapter" data-level="3.2.2.1" data-path="empirical-practices.html"><a href="empirical-practices.html#field-experiments"><i class="fa fa-check"></i><b>3.2.2.1</b> Field experiments</a></li>
<li class="chapter" data-level="3.2.2.2" data-path="empirical-practices.html"><a href="empirical-practices.html#laboratory-experiments"><i class="fa fa-check"></i><b>3.2.2.2</b> Laboratory experiments</a></li>
<li class="chapter" data-level="3.2.2.3" data-path="empirical-practices.html"><a href="empirical-practices.html#simulation-experiments"><i class="fa fa-check"></i><b>3.2.2.3</b> Simulation experiments</a></li>
<li class="chapter" data-level="3.2.2.4" data-path="empirical-practices.html"><a href="empirical-practices.html#wrap-up"><i class="fa fa-check"></i><b>3.2.2.4</b> Wrap-up</a></li>
</ul></li>
<li class="chapter" data-level="3.2.3" data-path="empirical-practices.html"><a href="empirical-practices.html#how-to-evaluate-experiment-success"><i class="fa fa-check"></i><b>3.2.3</b> How to evaluate experiment success</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="empirical-practices.html"><a href="empirical-practices.html#scientific-models"><i class="fa fa-check"></i><b>3.3</b> Scientific models</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="empirical-practices.html"><a href="empirical-practices.html#the-models-of-the-atom"><i class="fa fa-check"></i><b>3.3.1</b> The models of the atom</a></li>
<li class="chapter" data-level="3.3.2" data-path="empirical-practices.html"><a href="empirical-practices.html#the-models-of-benzene"><i class="fa fa-check"></i><b>3.3.2</b> The models of benzene</a></li>
<li class="chapter" data-level="3.3.3" data-path="empirical-practices.html"><a href="empirical-practices.html#models-as-analogies"><i class="fa fa-check"></i><b>3.3.3</b> Models as analogies</a></li>
<li class="chapter" data-level="3.3.4" data-path="empirical-practices.html"><a href="empirical-practices.html#differences-between-models-and-experiments"><i class="fa fa-check"></i><b>3.3.4</b> Differences between Models and Experiments</a></li>
<li class="chapter" data-level="3.3.5" data-path="empirical-practices.html"><a href="empirical-practices.html#what-makes-a-good-model"><i class="fa fa-check"></i><b>3.3.5</b> What makes a good model?</a></li>
<li class="chapter" data-level="3.3.6" data-path="empirical-practices.html"><a href="empirical-practices.html#models-as-mirrors"><i class="fa fa-check"></i><b>3.3.6</b> Models as mirrors</a></li>
<li class="chapter" data-level="3.3.7" data-path="empirical-practices.html"><a href="empirical-practices.html#models-as-isolations"><i class="fa fa-check"></i><b>3.3.7</b> Models as isolations</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="empirical-practices.html"><a href="empirical-practices.html#examples-2"><i class="fa fa-check"></i><b>3.4</b> Examples</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="empirical-practices.html"><a href="empirical-practices.html#willow"><i class="fa fa-check"></i><b>3.4.1</b> Willow tree experiment</a></li>
<li class="chapter" data-level="3.4.2" data-path="empirical-practices.html"><a href="empirical-practices.html#john-snow"><i class="fa fa-check"></i><b>3.4.2</b> 1854 Broad Street cholera outbreak</a></li>
<li class="chapter" data-level="3.4.3" data-path="empirical-practices.html"><a href="empirical-practices.html#causal-models"><i class="fa fa-check"></i><b>3.4.3</b> Causal models: Estimating treatment effect in the pressence of a confounder</a>
<ul>
<li class="chapter" data-level="3.4.3.1" data-path="empirical-practices.html"><a href="empirical-practices.html#backdoor-criterion"><i class="fa fa-check"></i><b>3.4.3.1</b> Backdoor criterion</a></li>
</ul></li>
<li class="chapter" data-level="3.4.4" data-path="empirical-practices.html"><a href="empirical-practices.html#causal-models-overestimation"><i class="fa fa-check"></i><b>3.4.4</b> Causal models: Detecting an overestimation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stats-abuse.html"><a href="stats-abuse.html"><i class="fa fa-check"></i><b>4</b> Experimental Control and Statistical Abuse</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stats-abuse.html"><a href="stats-abuse.html#stats-overview"><i class="fa fa-check"></i><b>4.1</b> Overview</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="stats-abuse.html"><a href="stats-abuse.html#the-smoke-debate---part-ii"><i class="fa fa-check"></i><b>4.1.1</b> The smoke debate - Part II</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="stats-abuse.html"><a href="stats-abuse.html#experimental-control"><i class="fa fa-check"></i><b>4.2</b> Experimental Control</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="stats-abuse.html"><a href="stats-abuse.html#other-experimental-control-techniques"><i class="fa fa-check"></i><b>4.2.1</b> Other experimental control techniques</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="stats-abuse.html"><a href="stats-abuse.html#randomised-control-trials"><i class="fa fa-check"></i><b>4.3</b> Randomised Control Trials</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="stats-abuse.html"><a href="stats-abuse.html#origins-of-rcts"><i class="fa fa-check"></i><b>4.3.1</b> Origins of RCTs</a></li>
<li class="chapter" data-level="4.3.2" data-path="stats-abuse.html"><a href="stats-abuse.html#validity"><i class="fa fa-check"></i><b>4.3.2</b> Validity</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="stats-abuse.html"><a href="stats-abuse.html#cross-validation-in-machine-learning"><i class="fa fa-check"></i><b>4.4</b> Cross-validation in Machine Learning</a></li>
<li class="chapter" data-level="4.5" data-path="stats-abuse.html"><a href="stats-abuse.html#surrogates-proxies-confounders-and-colliders"><i class="fa fa-check"></i><b>4.5</b> Surrogates, Proxies, Confounders and Colliders</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="stats-abuse.html"><a href="stats-abuse.html#surrogates-and-proxies"><i class="fa fa-check"></i><b>4.5.1</b> Surrogates and Proxies</a></li>
<li class="chapter" data-level="4.5.2" data-path="stats-abuse.html"><a href="stats-abuse.html#confounding-factors"><i class="fa fa-check"></i><b>4.5.2</b> Confounding factors</a></li>
<li class="chapter" data-level="4.5.3" data-path="stats-abuse.html"><a href="stats-abuse.html#collider-bias-and-m-bias"><i class="fa fa-check"></i><b>4.5.3</b> Collider bias and M-bias</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="stats-abuse.html"><a href="stats-abuse.html#data-is-not-enough"><i class="fa fa-check"></i><b>4.6</b> Data alone is not enough</a></li>
<li class="chapter" data-level="4.7" data-path="stats-abuse.html"><a href="stats-abuse.html#examples-3"><i class="fa fa-check"></i><b>4.7</b> Examples</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="stats-abuse.html"><a href="stats-abuse.html#covid-israel"><i class="fa fa-check"></i><b>4.7.1</b> Covid-19: How can efficacy versus severe disease be strong when 60% of hospitalized are vaccinated?</a></li>
<li class="chapter" data-level="4.7.2" data-path="stats-abuse.html"><a href="stats-abuse.html#viz-hurricane"><i class="fa fa-check"></i><b>4.7.2</b> Misinterpretations of hurricane forecast maps</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html"><i class="fa fa-check"></i><b>5</b> Ethics and Responsibility</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#overview-2"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#morality-and-ethics"><i class="fa fa-check"></i><b>5.2</b> Morality and Ethics</a></li>
<li class="chapter" data-level="5.3" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#ethical-frameworks"><i class="fa fa-check"></i><b>5.3</b> Ethical Frameworks</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#consequentialism"><i class="fa fa-check"></i><b>5.3.1</b> Consequentialism</a></li>
<li class="chapter" data-level="5.3.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#deontology"><i class="fa fa-check"></i><b>5.3.2</b> Deontology</a></li>
<li class="chapter" data-level="5.3.3" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#virtues"><i class="fa fa-check"></i><b>5.3.3</b> Virtues</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#values-in-science"><i class="fa fa-check"></i><b>5.4</b> Values in Science</a></li>
<li class="chapter" data-level="5.5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#ethics-in-action"><i class="fa fa-check"></i><b>5.5</b> Ethics in action</a></li>
<li class="chapter" data-level="5.6" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#data-ethics"><i class="fa fa-check"></i><b>5.6</b> Data Ethics</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#origins"><i class="fa fa-check"></i><b>5.6.1</b> Origins</a></li>
<li class="chapter" data-level="5.6.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#what-are-data-ethics"><i class="fa fa-check"></i><b>5.6.2</b> What are data ethics?</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#gdpr"><i class="fa fa-check"></i><b>5.7</b> General Data Protection Regulation (GDPR)</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#personal-data"><i class="fa fa-check"></i><b>5.7.1</b> Personal data</a>
<ul>
<li class="chapter" data-level="5.7.1.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#special-category-data"><i class="fa fa-check"></i><b>5.7.1.1</b> Special Category Data</a></li>
<li class="chapter" data-level="5.7.1.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#childrens-data"><i class="fa fa-check"></i><b>5.7.1.2</b> Children’s data</a></li>
</ul></li>
<li class="chapter" data-level="5.7.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#principles-gdpr"><i class="fa fa-check"></i><b>5.7.2</b> Principles GDPR</a>
<ul>
<li class="chapter" data-level="5.7.2.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#lawfulness-fairness-and-transparency"><i class="fa fa-check"></i><b>5.7.2.1</b> Lawfulness, Fairness and Transparency</a></li>
<li class="chapter" data-level="5.7.2.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#purpose-limitation"><i class="fa fa-check"></i><b>5.7.2.2</b> Purpose Limitation</a></li>
<li class="chapter" data-level="5.7.2.3" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#data-minimization"><i class="fa fa-check"></i><b>5.7.2.3</b> Data Minimization</a></li>
<li class="chapter" data-level="5.7.2.4" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#storage-limitation"><i class="fa fa-check"></i><b>5.7.2.4</b> Storage Limitation</a></li>
<li class="chapter" data-level="5.7.2.5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#integrity-and-confidentiality"><i class="fa fa-check"></i><b>5.7.2.5</b> Integrity and Confidentiality</a></li>
<li class="chapter" data-level="5.7.2.6" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#accountability"><i class="fa fa-check"></i><b>5.7.2.6</b> Accountability</a></li>
</ul></li>
<li class="chapter" data-level="5.7.3" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#controllers-processors-and-subjects."><i class="fa fa-check"></i><b>5.7.3</b> Controllers, Processors and Subjects.</a></li>
<li class="chapter" data-level="5.7.4" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#rights-of-the-data-subject"><i class="fa fa-check"></i><b>5.7.4</b> Rights of the data subject</a></li>
<li class="chapter" data-level="5.7.5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#international-transfers"><i class="fa fa-check"></i><b>5.7.5</b> International transfers</a></li>
<li class="chapter" data-level="5.7.6" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#data-breaches"><i class="fa fa-check"></i><b>5.7.6</b> Data breaches</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#ethic-examples"><i class="fa fa-check"></i><b>5.8</b> Examples</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#a-genocide-incited-on-facebook"><i class="fa fa-check"></i><b>5.8.1</b> A Genocide Incited on Facebook</a></li>
<li class="chapter" data-level="5.8.2" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html#the-theranos-scandal---a-drop-of-blood-for-hundreds-of-different-assays"><i class="fa fa-check"></i><b>5.8.2</b> The Theranos scandal - A drop of blood for hundreds of different assays</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="wont-fix.html"><a href="wont-fix.html"><i class="fa fa-check"></i><b>6</b> Extra Material</a>
<ul>
<li class="chapter" data-level="6.1" data-path="wont-fix.html"><a href="wont-fix.html#history-of-science"><i class="fa fa-check"></i><b>6.1</b> History of science</a></li>
<li class="chapter" data-level="6.2" data-path="wont-fix.html"><a href="wont-fix.html#theory-relatedness-of-observations"><i class="fa fa-check"></i><b>6.2</b> Theory-relatedness of observations</a></li>
<li class="chapter" data-level="6.3" data-path="wont-fix.html"><a href="wont-fix.html#thomas-kuhn-and-the-idea-of-scientific-revolutions"><i class="fa fa-check"></i><b>6.3</b> Thomas Kuhn and the idea of scientific revolutions</a></li>
<li class="chapter" data-level="6.4" data-path="wont-fix.html"><a href="wont-fix.html#gettier-problems"><i class="fa fa-check"></i><b>6.4</b> Gettier problems</a></li>
<li class="chapter" data-level="6.5" data-path="wont-fix.html"><a href="wont-fix.html#realism"><i class="fa fa-check"></i><b>6.5</b> Realism and anti-realism</a></li>
<li class="chapter" data-level="6.6" data-path="wont-fix.html"><a href="wont-fix.html#pessimistic-meta-induction"><i class="fa fa-check"></i><b>6.6</b> Pessimistic meta-induction</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Built with Bookdown + RStudio</a></li>
<li><a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Philosophy of Science and Data Ethics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="empirical-practices" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Empirical Practices and Models<a href="empirical-practices.html#empirical-practices" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="overview-1" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Overview<a href="empirical-practices.html#overview-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p><em>Empirical</em>: based on, concerned with, or verifiable by observation or experience rather than theory or pure logic.</p>
</blockquote>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:daniel-part-one"></span>
<img src="Figures/Daniel_part_1.jpg" alt="Daniel interprets Nebuchadnezzar's Dream." width="33%" />
<p class="caption">
Figure 3.1: Daniel interprets Nebuchadnezzar’s Dream.
</p>
</div>
<p>I would like to introduce this chapter in the same way the Book of Why <span class="citation">(<a href="#ref-book-of-why">Pearl and Mackenzie 2018</a>)</span> introduces its fourth chapter “Slaying the lurking variable”. During the times of Babylonian King Nebuchadnezzar (642 BC - 562 BC), one captive – Daniel – refused to eat royal meat offered by the King as part of their education and service in the court since it did not comply with his religious beliefs. Instead, Daniel asked to be fed on a vegetable diet. The overseer was reluctant as he thought the servants would lose weight and become weaker. Daniel proposed an experiment to convince his overseer. For ten days, one group of servants would be given a vegetable diet, while another group of servants would eat the king’s meat. Then, the overseer would compare both groups and see that the vegetable diet did not reduce their strength. Of course, the experiment was a success, and the king was so impressed that he granted Daniel a favoured place in the court.</p>
<p>This example synthesizes the process of controlled experiments employed nowadays in experimental science. The overseer poses a question, <em>will the vegetarian diet cause my servants to lose weight?</em>. There it is our hypothesis. To address the question, Daniel proposed a methodology. Divide the servants in two identical groups. Give one group a new treatment (e.g. diet or a drug), while another group (control) remains under no special treatment. Of course, the two groups should be comparable and representative of some population in order to transfer the conclusions to the population at large. This process allowed Daniel to show the <em>causal effect</em> (beware, we will tackle this in Chapter <a href="stats-abuse.html#stats-abuse">4</a>) of the diet. Moreover, Daniel’s experiment was prospective (in contrast to retrospective studies) as the groups were chosen in advance. Prospective controlled trials are a common characteristic of sound science. Still, Daniel did not think of everything, but we will see that in Chapter <a href="stats-abuse.html#stats-abuse">4</a>.</p>
</div>
<div id="what-is-an-experiment" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> What is an experiment?<a href="empirical-practices.html#what-is-an-experiment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Many data scientists believe their role should be limited to data analysis, but experiment design is fundamental for data collection, which conditions how the data must be analysed. Conclusions drawn from data can be biased or determined by decisions and errors taken during experiment design. Understanding this can help you spot issues during the data analysis and ask the right questions to your colleagues in charge of the experiments.</p>
<p>An experiment is an observation process in which we control background variables through manipulation, intervene on target variable (through manipulation) and observe the difference produced by such intervention thanks to measurements.</p>
<blockquote>
<p>Experiment is the kind of scientific experience in which some change is deliberately provoked, and its outcome observed, recorded and interpreted with a cognitive aim. — <span class="citation">(<a href="#ref-bunge2017philosophy">Bunge 2017</a>)</span></p>
</blockquote>
<!-- consider adding mill's method of difference -->
<div id="observational-studies" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Observational studies<a href="empirical-practices.html#observational-studies" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>However, there are whole research areas were scientists cannot make experiments. For instance, astrophysics is mainly observational and theoretical as is not possible to manipulate the observed entities (e.g. stars). It aims to find out measurable implications of physical models. Sometimes is not feasible, legal or ethical to conduct certain types of experiments, conducting observational studies instead. So, in <strong>observational studies</strong> there is no manipulation, no intervention on the target variable, neither control of background variables.</p>
<div id="natural-experiments" class="section level4 hasAnchor" number="3.2.1.1">
<h4><span class="header-section-number">3.2.1.1</span> Natural experiments<a href="empirical-practices.html#natural-experiments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><a href="https://en.wikipedia.org/wiki/Natural_experiment"><strong>Natural experiments</strong></a> on the other side share the first two characteristics but is possible to control background variables (but not through manipulation though). See § <a href="empirical-practices.html#john-snow">3.4.2</a> for an example. A major limitation of natural experiments when inferring causation is the presence of unmeasured confounding factors. Natural experiments are appealing for public health research because they enable the evaluation of events or interventions that are difficult or impossible to manipulate experimentally, such as many policy and health system reforms <span class="citation">(<a href="#ref-de2021conceptualising">Vocht et al. 2021</a>)</span>.</p>
<blockquote>
<p>For example the Canterbury earthquakes in 2010-2011 could be used to study the impact of such disasters because about half of a well-studied birth cohort lived in the affected area with the remainder living outside. […] More recently, the use of the term ‘natural’ has been understood more broadly as an event which did not involve the deliberate manipulation of exposure for research purposes, even if human agency was involved. […] Natural experiments describing the study of an event which did not involve the deliberate manipulation of an exposure but involved human agency, such as the impact of a new policy, are the mainstay of ‘natural experimental research’ in public health. — <span class="citation">(<a href="#ref-de2021conceptualising">Vocht et al. 2021</a>)</span></p>
</blockquote>
<p>See Figure <a href="empirical-practices.html#fig:diagram-experiments">3.2</a> for an schema depicting the conceptualisation of natural and quasi-experiments. Some authors differentiate between natural experiments and <em>quasi-experiments</em>. In a quasi-experiment, the criterion for group assignment of the study units (e.g. study participants) is selected by the researchers, whereas, in a natural experiment, the assignment occurs <em>naturally</em>, without the intervention of the researchers.</p>
<blockquote>
<p>Quasi-experiment: A quasi-experiment is an empirical interventional study used to estimate the causal impact of an intervention on target population without random assignment. Quasi-experimental research shares similarities with the traditional experimental design or randomized controlled trial, but it specifically lacks the element of random assignment to treatment or control. Instead, quasi-experimental designs typically allow the researcher to control the assignment to the treatment condition, but using some criterion other than random assignment. Quasi-experiments are subject to concerns regarding internal validity, because the treatment and control groups may not be comparable at baseline. In other words, it may not be possible to convincingly demonstrate a causal link between the treatment condition and observed outcomes. This is particularly true if there are confounding variables that cannot be controlled or accounted for. — Wikipedia on <span class="citation">(<a href="#ref-rossi1985evaluation">Rossi, Freeman, and Wright 1985</a>)</span> and <span class="citation">(<a href="#ref-dinardo2010natural">DiNardo 2010</a>)</span>.</p>
</blockquote>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:diagram-experiments"></span>
<img src="Figures/natural-experiments.png" alt="Diagram depicting the conceptualisation of natural and quasi-experiments within the evaluation framework of Thad Dunning. Re-drawn from (Vocht et al. 2021). Note that the same article provides three additional conceptualisations from different frameworks. For example, a different conceptualisation makes a distinction between quasi and natural experiments, arguing that natural experiments describe unplanned events whereas quasi-experiments describe events that are planned (but not controlled by the researcher)." width="100%" />
<p class="caption">
Figure 3.2: Diagram depicting the conceptualisation of natural and quasi-experiments within the evaluation framework of Thad Dunning. Re-drawn from <span class="citation">(<a href="#ref-de2021conceptualising">Vocht et al. 2021</a>)</span>. Note that the same article provides three additional conceptualisations from different frameworks. For example, a different conceptualisation makes a distinction between quasi and natural experiments, arguing that natural experiments describe unplanned events whereas quasi-experiments describe events that are planned (but not controlled by the researcher).
</p>
</div>
<blockquote>
<p>Dunning takes this concept further and defines a ‘natural experiment’ as a quasi-experiment where knowledge about the exposure allocation process provides a strong argument that allocation, although not deliberately manipulated by the researcher, is essentially random, referred to as ‘as-if randomization’. — <span class="citation">(<a href="#ref-de2021conceptualising">Vocht et al. 2021</a>)</span></p>
</blockquote>
<div class="tipbox">
<div data-latex="">
<p><strong>Definitions:</strong></p>
</div>
<p><strong>Target variables</strong>: The target variable of a dataset is the feature of a dataset about which you want to gain a deeper understanding. They also receive the name “dependent variables” because, in an experiment, their values are studied under the supposition or demand that they depend, by some law or rule (e.g., by a mathematical function), on the values of other variables. The dependent variable is the <em>effect</em>. Its value depends on changes in the independent variable.</p>
<p><strong>Independent variables</strong>: It is a variable that stands alone and isn’t changed by the other variables you are trying to measure. The independent variable is the <em>cause</em>. Its value is independent of other variables in your study.</p>
<p><strong>Background variables</strong>: An explanatory variable that can affect other (dependent) variables but cannot be affected by them. For example, one’s schooling may affect one’s subsequent career, but the reverse is unlikely to be true.</p>
</div>
<p>We can recognise five elements in the observation process: the <em>object</em> of observation; the <em>subject</em> (or observer) and its perceptions; the <em>circumstances</em> of observation (e.g. environment of object and subject); the observation <em>media</em> (e.g. senses, instruments, procedures); and the body of <em>knowledge</em> used to relate all the previous elements. The last two can be grouped into <em>tools</em> (concrete and conceptual). So, an observation statement has the form “<span class="math inline">\(w\)</span> observes <span class="math inline">\(x\)</span> under <span class="math inline">\(y\)</span> with the help of <span class="math inline">\(z\)</span>”. <span class="citation">(<a href="#ref-bunge2017philosophy">Bunge 2017</a>)</span></p>
</div>
<div id="observability" class="section level4 hasAnchor" number="3.2.1.2">
<h4><span class="header-section-number">3.2.1.2</span> Observability<a href="empirical-practices.html#observability" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We can try to define observability by stating that a fact is <em>observable</em> “only if there exists at least one subject, one set of circumstances, and one set of observation tools, such that the fact can appear to the subject armed with those tools under those circumstances” <span class="citation">(<a href="#ref-bunge2017philosophy">Bunge 2017</a>)</span>. This definition is rather unsatisfactory since someone could claim the existence of ghosts or aliens. We should define what is objectively observable. Then, <span class="math inline">\(x\)</span> is observable only if there exist at least one recording instrument <span class="math inline">\(w\)</span>, one set of circumstances <span class="math inline">\(Y\)</span>, and one set of observation tools <span class="math inline">\(Z\)</span>, such that <span class="math inline">\(w\)</span> can register <span class="math inline">\(x\)</span> under <span class="math inline">\(y\)</span> helped by <span class="math inline">\(z\)</span>. Here we have eliminated the possibility of the subject’s perceptual delusions, but devices (e.g. a camera) have limitations too.</p>
<p>Observations are often expressed in the form of a rule so that other researchers can reproduce their results under similar conditions. Some facts cannot be repeated, such as the eruption of a volcano or a supernova. So very often, we expect results of the same kind to be reproducible by observers. Exact duplication is desirable but not always achievable. Even independent observers may make the same wrong observations due to faulty equipment or false hypotheses.</p>
</div>
<div id="indicators" class="section level4 hasAnchor" number="3.2.1.3">
<h4><span class="header-section-number">3.2.1.3</span> Indicators<a href="empirical-practices.html#indicators" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Most facts we know about are indirectly observable, i.e. we infer them through an intermediary. For instance, the wind is not directly observable but inferred from bodies apparently moved by it. We <em>objectify</em> an unobservable fact by establishing its relationship to some perceptible fact(s) that serve us as an <em>indicator</em> of the fact. In other words, hypotheses are made concerning unperceived facts and tested through evidence consisting of data about other directly observable facts, assuming that the latter are <strong>collaterally connected with</strong> or <strong>effects</strong> of the former. Of course, that such relationship should hold is as well a hypothesis (see Figure <a href="empirical-practices.html#fig:indicator">3.3</a>).</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:indicator"></span>
<img src="Figures/indicator.png" alt="The physical object-indicator relation, is expressed by a hypothesis enabling us to infer the object from observations made on its indicator. Figure extracted from (Bunge 2017)." width="50%" />
<p class="caption">
Figure 3.3: The physical object-indicator relation, is expressed by a hypothesis enabling us to infer the object from observations made on its indicator. Figure extracted from <span class="citation">(<a href="#ref-bunge2017philosophy">Bunge 2017</a>)</span>.
</p>
</div>
</div>
<div id="data-and-evidence" class="section level4 hasAnchor" number="3.2.1.4">
<h4><span class="header-section-number">3.2.1.4</span> Data and Evidence<a href="empirical-practices.html#data-and-evidence" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Every evidence is a <em>datum</em> but not every datum constitutes <em>evidence</em>. What turns a datum into evidence is that is relevant to some idea, that it makes sense under some theory or body of knowledge. In particular, we believe a datum constitutes an evidence in favour of a theory and assign the theory some <em>credence</em> because it justifies or predicts that evidence. The evidence must be related to a specific hypothesis, and this relationship is justified because of a body of theoretical knowledge. In fact, no evidence is absolute. Consider the following example from <span class="citation">(<a href="#ref-bunge2017philosophy">Bunge 2017</a>)</span>:</p>
<blockquote>
<p>The observed deviation of a magnetic needle in the vicinity of an electric circuit (datum <span class="math inline">\(e\)</span>) supports the hypothesis <span class="math inline">\(h_x\)</span> that electricity is flowing through the circuit, on the theory <span class="math inline">\(⊤_1\)</span> that electric currents produce magnetic fields which in turn interact with the fields of magnetic needles. But exactly the same datum <span class="math inline">\(e\)</span> might be taken as an evidence in favour of the rival hypothesis <span class="math inline">\(h_2\)</span> that a big magnet somewhere nearby has been switched on, on the theory <span class="math inline">\(⊤_2\)</span> that magnets can interact directly with one another. The given datum is then <em>ambiguous</em> and only an independent checking of <span class="math inline">\(h_x\)</span> and <span class="math inline">\(h_2\)</span>, i.e. a test independent of <span class="math inline">\(e\)</span>, will enable us to reach a decision between the two rivals.</p>
</blockquote>
<p>Importantly, the characteristics that make data count as evidence must be agreed prior to observation and on the basis of theory. Sometimes a scientist may obtain data that seems incompatible with a theory. Instead of getting rid of such data (or the theory), the scientist will attempt to reproduce the data and assess whether is anomalous data (e.g. due to a faulty instrument) or not. The <em>raw</em> data may contain any information, but <em>refined</em> data should express only relevant and useful information for the problem at hand. Of course, some information is always lost in the process. In consequence, the refinement process is irreversible. Data are <em>means</em> rather than <em>ends</em> and we aim to systematise data in order to disclose patterns on it. For this reason <em>noise</em> must be removed. The systematization of refined data may involve displaying information in graphs or tables as well as arranging information in data structures such as matrices.</p>
</div>
</div>
<div id="field-laboratory-and-simulation-experiments" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Field, laboratory and simulation experiments<a href="empirical-practices.html#field-laboratory-and-simulation-experiments" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="field-experiments" class="section level4 hasAnchor" number="3.2.2.1">
<h4><span class="header-section-number">3.2.2.1</span> Field experiments<a href="empirical-practices.html#field-experiments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In contrast to observational experiments, <strong>field experiments</strong> randomly assign the sampling units (e.g. study participants) into two groups (treatment and control) to test causal relationships. The same conditions are maintained for both groups only varying the intervention on the factor of interest (e.g. two parts of soil (fertilized/unfertilized)). The background variables are considered as given and not manipulated.</p>
<ul>
<li>No manipulation.</li>
<li>No intervention on the target variable.</li>
<li>Control for the background variable (but not through manipulation).</li>
</ul>
<p>In the example (see Figure <a href="empirical-practices.html#fig:fertiliser">3.4</a>), the background variables are controlled, we do not alter the soil, the number of hours of sun light received by the two groups of plants, nor the watering conditions. The only intervention is giving fertiliser to one side of the field. In this case, the seeds can be randomly assigned the treatment (fertiliser) or control groups.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fertiliser"></span>
<img src="Figures/crop.jpeg" alt="Fertiliser experiment." width="66%" />
<p class="caption">
Figure 3.4: Fertiliser experiment.
</p>
</div>
<p><strong>Potential threats to internal validity</strong></p>
<ul>
<li><p>Excludability: The assumption of excludability states that the randomization does not affect outcomes through other variables than the reception of the treatment. If this assumption is violated, the causal effect identified in a study is a combination of the treatment and other variables <span class="citation">(<a href="#ref-hansen2020systematic">Hansen and Tummers 2020</a>)</span>. For instance, that the two fields do not receive the same amount of light.</p></li>
<li><p>Interference: Interference occurs when experimental units alter each other’s outcomes. This generates a bias that precludes the proper estimation of causal effects by the reseachers.</p></li>
<li><p>Attrition: Attrition occurs when outcome data are missing. Attrition becomes a problem for causal inference when two conditions are present: (1) units with missing outcomes differ systematically on the outcome from those that are not missing and (2) attrition is different in experimental groups. There is greater potential for attrition in field experiments than in laboratory experiments because field experiments confer less control <span class="citation">(<a href="#ref-hansen2020systematic">Hansen and Tummers 2020</a>)</span>. For instance, some participants may leave a study if they do not get any improvement.</p></li>
</ul>
</div>
<div id="laboratory-experiments" class="section level4 hasAnchor" number="3.2.2.2">
<h4><span class="header-section-number">3.2.2.2</span> Laboratory experiments<a href="empirical-practices.html#laboratory-experiments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>On the other side, <strong>laboratory experiments</strong> construct the same background conditions in both groups manipulating the environment (lab settings) and varying the intervention on the factor of interest. Background conditions are controlled through manipulation. For instance, temperature, pressure, humidity can be controlled for a fertiliser trial. Laboratory experiments tend to have higher internal validity, but at the cost of lower external validity (generalistation), owing to the artificial setting in which the study is conducted may not reflect the real world.</p>
</div>
<div id="simulation-experiments" class="section level4 hasAnchor" number="3.2.2.3">
<h4><span class="header-section-number">3.2.2.3</span> Simulation experiments<a href="empirical-practices.html#simulation-experiments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Finally, <strong>simulation experiments</strong> are constructions representing a real system on a computer to perform interventions. This type of experiments are done when it is not feasible to experiment on the real entities (e.g. climate simulations or geological simulations). The important consideration is that all interventions and manipulations are performed on the computer representation instead of the real target itself.</p>
</div>
<div id="wrap-up" class="section level4 hasAnchor" number="3.2.2.4">
<h4><span class="header-section-number">3.2.2.4</span> Wrap-up<a href="empirical-practices.html#wrap-up" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Therefore, an experiment is a controlled observation in which the observer manipulates the real variables (independent variables) that are believed to influence the outcome (dependent variable), both for the purpose of intervention and control. The following article provides a good description of the <a href="https://opentextbc.ca/researchmethods/chapter/experiment-basics/">basics of experiments</a>.</p>
<p>In Chapter <a href="stats-abuse.html#stats-abuse">4</a> we will see some examples of experimental errors (e.g. confirmation bias, selection bias, etc) as well as examples of statistical abuse. All in all, the experiment process is also a craft which entails learning from previous experiments (ours and others), as well as applying all available knowledge (theoretical and experimental) for the design of experiments.</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Definitions:</strong></p>
</div>
<p><strong>Repetition</strong>: An experiment is repeatable if enough information is provided about the used data and the experiment methods and conditions. With such information, it should be possible to repeat the experiment.</p>
<p><strong>Reproduction</strong>: An experiment is considered as reproduced if the repetition of the experiment yields the same result. For instance, in computer science, reproducing involves using the original data and code.</p>
<p><strong>Replication</strong>: An independent experiment, in the spirit of the original experiment produces the same result. For example, in computer science replication entails collecting new data and use similar methods to reach similar conclusions in answer to the same scientific question. Or implementing a new software following similar design principles and reaching similar results.</p>
</div>
</div>
</div>
<div id="how-to-evaluate-experiment-success" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> How to evaluate experiment success<a href="empirical-practices.html#how-to-evaluate-experiment-success" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Very often, success is not defined by a single goal or metric. For instance, the best car is not always the fastest car. In fact, there are many other values to bear in mind, such as gasoline consumption, pollution, ease of manufacture, etc. Similarly an experiment success is rarely assessed with a single metric in mind.</p>
<p>Moreover, some metrics must not be degraded, often called <strong>guardrail metrics</strong>. This type of metrics can include security, speed, robustness, etc. But very often include <em>non-epistemic values</em> too. In this context, non-epistemic values are metrics not directly related to the instance to be designed, such as fairness, justice, or making money (or saving it), in contrast to metrics that make the instance at issue <em>internally</em> or <em>intrinsically</em> better (e.g. speed). For instance, a car is not necessarily a better car depending on its price if what is judged is the <em>car itself</em> in isolation, but a low price might make it easier to sell. In another example, the fastest data processing system might not necessarily be the best choice since other requirements must be considered too (e.g. ease of use).</p>
<p>A non-epistemic value that is always at stake is money, or in a different shape, OPEX (operational expenditure) and CAPEX (capital expenditure). Very often, they condition other metrics, such as performance (e.g. use less/worse resources) or safety (e.g. employ less/worse materials). For example, I had the opportunity to work on the design of enterprise log processing systems. In this case, we wanted to maximise speed while reducing resources, as mid-sized companies often wish to reduce the number of servers deployed, which ultimately affects their operational costs (e.g. space and electricity). Most commercial solutions scale horizontally, requiring the use of on-site server clusters to handle large amounts of data (at prohibitively high prices) or cloud-hosted clusters (impractical due to data protection). Our proposal optimised vertical scalability and coped with tens of millions of events per second with a single server. But of course, such an approach was specifically designed for a particular task, in contrast to the flexibility offered by commercial alternatives.</p>
<p>In data science, success should be defined by how well the analysis answers the research questions. For this reason, setting the research questions at the very beginning of the process remains crucial. They not only determine the data analysis but, more importantly, the data collection design. However, very frequently, the data science process starts with a given dataset. Still, it is essential to assess if the collected data can answer the posed questions.</p>
</div>
</div>
<div id="scientific-models" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Scientific models<a href="empirical-practices.html#scientific-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Scientific models are widespread and varied. These include scale models (e.g. plane models for aerodynamic studies), laboratory animals (e.g. mice for drug trials), simulation models (e.g. computational model for weather forecast). In all the previous cases, a model is made to replace or to stand in for what we are ultimately interested in. Models are characterised by being <strong>representations</strong>, containing <strong>idealisations</strong>, being <strong>purpose dependent</strong>, and <strong>ready to be manipulated</strong>.</p>
<blockquote>
<p>Typically models are representations in which details, that appear inessential for intended uses, are omitted. A model is intended to represent the real thing in certain significant aspects. — Guy Orcutt</p>
</blockquote>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sbml-model"></span>
<img src="Figures/sbml_model.png" alt="Different representations of a biological process. On the right side, the process is encoded in a XML file in Systems Biology Markup Language (SBML) format. " width="100%" />
<p class="caption">
Figure 3.5: Different representations of a biological process. On the right side, the process is encoded in a XML file in Systems Biology Markup Language (SBML) format.
</p>
</div>
<blockquote>
<p>We shall be concerned with model objects and theoretical models as hypothetical sketches of supposedly real, though possibly fictitious, things or facts. Thus a fluid may be modeled as a continuum endowed with certain properties, such as compressibility and viscosity. Such a model object may be grafted onto any of a number of general theories, say classical mechanics, or general relativistic mechanics. Likewise, a learning organism may be modeled as a black box equipped with certain input and output terminals, and this model object may then be expanded into a hypothetico-deductive system. In either case a specific theory, or theoretical model, of a concrete (or supposedly concrete) object, results. What can be subjected to empirical tests are such theoretical models: on the other hand general theories, being unconcerned with particulars, remain empirically untestable unless enriched with models of their referents. — <span class="citation">(<a href="#ref-bunge2012method">Bunge 2012</a>)</span></p>
</blockquote>
<p>For instance, a physical model of DNA on a table represents the real DNA. Obviously, such a model is not a piece of real DNA. It is made of something else (e.g. plastic) and at a different scale. In this case, such a model is useful for pedagogic purposes. Although there are clear differences between models and targets, the key relationship is that <strong>a model represents (in some way) the target</strong>. From the methodological point of view, we must justify why to represent targets with models instead of investigating the targets themselves?. Possible answers include physical impossibility, costs, ethical and legal reasons, etc. However, very often the main justification to employ models is that targets are very complex. Therefore, employing a model that simplifies the target complexity might allow us to get a better understanding of the main factors operating in the target system. Our cognitive limits very often determine how we investigate complex systems, starting with a simpler model and increasing its complexity as we gain understanding.</p>
<blockquote>
<p>A schematic representation of an object may be called a model object. If the represented object (or referent) is concrete or physical, then its model is an idealization of it. The representation may be pictorial, as in the case of a drawing, or conceptual, as in the case of a mathematical formula. It may be figurative, like the ball-and-spoke model of a molecule, of semisymbolic, as in the case of the contour map of the same molecule; or finally symbolic like the hamiltonian operator for that same object. — <span class="citation">(<a href="#ref-bunge2012method">Bunge 2012</a>)</span></p>
</blockquote>
<p>Therefore, we are intentionally choosing or building a model that differs from the target in some properties. Precisely because of this condition, we cannot assume that whatever is the case in the model is also the case in the target. <strong>Models come with idealisations.</strong> Not bearing in mind this key condition of the models can lead us to produce false claims about the target.</p>
<blockquote>
<ul>
<li><strong>Idealized models.</strong> Idealized models are models that involve a deliberate simplification or distortion of something complicated with the objective of making it more tractable or understandable. Frictionless planes, point masses, completely isolated systems, omniscient and fully rational agents, and markets in perfect equilibrium are well-known examples. Idealizations are a crucial means for science to cope with systems that are too difficult to study in their full complexity.</li>
<li><strong>Scale models.</strong> Some models are down-sized or enlarged copies of their target systems (Black 1962). A typical example is a small wooden car that is put into a wind tunnel to explore the actual car’s aerodynamic properties.</li>
<li><strong>Phenomenological models.</strong> Phenomenological models have been defined in different, although related, ways. A common definition takes them to be models that only represent observable properties of their targets and refrain from postulating hidden mechanisms and the like.</li>
<li><strong>Exploratory models.</strong> Exploratory models are models which are not proposed in the first place to learn something about a specific target system or a particular experimentally established phenomenon. Exploratory models function as the starting point of further explorations in which the model is modified and refined.</li>
<li><strong>Models of data.</strong> A model of data (sometimes also “data model”) is a corrected, rectified, regimented, and in many instances idealized version of the data we gain from immediate observation, the so-called raw data. Characteristically, one first eliminates errors (e.g., removes points from the record that are due to faulty observation) and then presents the data in a “neat” way, for instance by drawing a smooth curve through a set of points. These two steps are commonly referred to as “data reduction” and “curve fitting”.
— <span class="citation">(<a href="#ref-sep-models-science">Frigg and Hartmann 2020</a>)</span></li>
</ul>
</blockquote>
<div id="the-models-of-the-atom" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> The models of the atom<a href="empirical-practices.html#the-models-of-the-atom" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For example, Bohr’s model of the atom assumes that electrons orbit the atomic nucleus in circles. The success of such a model relied that the Bohr assumptions reproduced the series that fitted the hydrogen emission spectra. In 1913 it predicted the correct frequencies of the specific colours of light absorbed and emitted by ionised helium. One could say that Bohr was very lucky as despite his model is wrong in some ways, it also has some bits of truth, enough for his predictions about ionised helium to work out.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bohr-model"></span>
<img src="Figures/bohr-atom-model.png" alt="Illustration of bound-bound transition in the Bohr atomic model. Source: Wikipedia Commons." width="33%" />
<p class="caption">
Figure 3.6: Illustration of bound-bound transition in the Bohr atomic model. Source: <a href="https://commons.wikimedia.org/wiki/File:Bohr_atom_model.svg">Wikipedia Commons</a>.
</p>
</div>
<p>However, other predictions about the properties of the atom were wrong, and its implications were not observed in experiments. In the Schrödinger model, the electron of a one-electron atom, rather than travelling in fixed orbits around the nucleus, has a probability distribution allowing the electron to be at almost all locations in space, some being much more likely than others. Bohr theory (1913) was rejected in 1925 after the advent of quantum mechanics, but its model remains because despite its flaws and idealisations, <a href="https://blogs.scientificamerican.com/guest-blog/why-it-s-okay-to-teach-wrong-ideas-in-physics/">Bohr’s model is useful for education</a>.</p>
</div>
<div id="the-models-of-benzene" class="section level3 hasAnchor" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> The models of benzene<a href="empirical-practices.html#the-models-of-benzene" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Models are as well purpose-dependent</strong>. Suppose the next question. Which benzene model is better? A quantum mechanic model, or a structural formula?. On one side, the quantum mechanic model is more precise about the potential position of electrons. Additionally, is more similar to the target as it represents better its relevant properties. The structural model is simpler and easier to work with. In this case, theoretically tractable models such as structural models allow for functional group analysis in chemistry.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:benzene-model"></span>
<img src="Figures/Benzene_Representations.png" alt="Various representations of Benzene. Source: Wikipedia Commons." width="90%" />
<p class="caption">
Figure 3.7: Various representations of Benzene. Source: <a href="https://en.wikipedia.org/wiki/File:Benzene_Representations.svg">Wikipedia Commons</a>.
</p>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:benzene-model-evolution"></span>
<img src="Figures/Historic_Benzene_Formulae.png" alt="Historic benzene structures (from left to right) by Claus (1867), Dewar (1867), Ladenburg (1869), Armstrong (1887), Thiele (1899) and Kekulé (1865). Dewar benzene and prismane are distinct molecules that have Dewar’s and Ladenburg’s structures. Thiele and Kekulé’s structures are used today." width="90%" />
<p class="caption">
Figure 3.8: Historic benzene structures (from left to right) by Claus (1867), Dewar (1867), Ladenburg (1869), Armstrong (1887), Thiele (1899) and Kekulé (1865). Dewar benzene and prismane are distinct molecules that have Dewar’s and Ladenburg’s structures. Thiele and Kekulé’s structures are used today.
</p>
</div>
</div>
<div id="models-as-analogies" class="section level3 hasAnchor" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Models as analogies<a href="empirical-practices.html#models-as-analogies" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<figure class="wrap-figure">
<img src="Figures/mary-hesse.jpeg">
<figcaption>
Prof. Mary Hesse (1924-2016), by Peter Mennim.
</figcaption>
</figure>
<p>Philosopher Mary Hesse (1924-2016) argued that models act as analogies rather than descriptions of the targets. She distinguished between 3 kinds of analogies. In the first place, she considered that <strong>positive analogies</strong> hold between the aspects of a model and its target for which we have reasons to believe they are similar. An example of positive analogies can be found between mice and humans, which have similar hormone systems and physiology. On the other hand, the idealisations constitute <strong>negative analogies</strong>, such as the differences in size or lifespan between mice and humans. These negative analogies cover the properties in which model and target differ. Finally, <strong>neutral analogies</strong> concern the properties that we cannot investigate directly in the target, requiring the model for their study.</p>
<blockquote>
<p>Without analogy there might be no knowledge: the perception of analogies is a first step towards classification and generalization. <span class="citation">(<a href="#ref-bunge2012method">Bunge 2012</a>)</span></p>
</blockquote>
<p>For instance, the reaction to a certain drug or treatment of interest. At the initial stage, is not possible to tell whether the model-target relationships concerning these properties constitute positive or negative analogies because we do not know yet how the relevant target properties are affected. Instead, such properties are investigated in the model, and researchers hypothesise that the model is analogous to the target in such properties. For instance, we assume that the effects of a drug in mice will give us knowledge about its effects in humans.</p>
<blockquote>
<p>The positive analogy between two items consists in the properties or relations they share (both gas molecules and billiard balls have mass); the negative analogy consists in the properties they do not share (billiard balls are colored, gas molecules are not); the neutral analogy comprises the properties of which it is not known (yet) whether they belong to the positive or the negative analogy (do billiard balls and molecules have the same cross section in scattering processes?). Neutral analogies play an important role in scientific research because they give rise to questions and suggest new hypotheses. — <span class="citation">(<a href="#ref-sep-models-science">Frigg and Hartmann 2020</a>)</span></p>
</blockquote>
<p>Consider again the Michelson and Morley experiment. Before the XX century, most physicists considered light as a wave. Their beliefs were justified on the many positive analogies between light, water and sound waves. For instance, light produces a diffraction pattern when encountering an obstacle, just as water and sound waves do. With this model in mind, physicists inferred a neutral analogy, namely, that light needs a medium to travel, as other waves require. They called this medium: luminiferous aether. The experiment from Michelson and Morley is a consequence of such model. However, the experiment revealed that such analogy was indeed a negative analogy, an idealisation. This discovery led people to replace the model of light for more precise models. Therefore, model manipulation allows discovering the effects of neutral analogies.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:aether"></span>
<img src="Figures/luminiferous_aether.png" alt="The luminiferous aether: it was hypothesised that the Earth moves through a &quot;medium&quot; of aether that carries light. Source: Wikipedia Commons." width="50%" />
<p class="caption">
Figure 3.9: The luminiferous aether: it was hypothesised that the Earth moves through a “medium” of aether that carries light. Source: <a href="https://commons.wikimedia.org/wiki/File:AetherWind.svg">Wikipedia Commons</a>.
</p>
</div>
</div>
<div id="differences-between-models-and-experiments" class="section level3 hasAnchor" number="3.3.4">
<h3><span class="header-section-number">3.3.4</span> Differences between Models and Experiments<a href="empirical-practices.html#differences-between-models-and-experiments" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are several commonalities between models and experiments. Setting parameters and variables in models resembles experimental control. In the same way, model manipulation is akin to experimental manipulation. Moreover, model manipulation yields results that are observed, just as in experimental observations.</p>
<p>Notwithstanding, there are also important differences to bear in mind, which mainly concern the source of errors. For instance, the most troubling experimental errors concern internal validity questions, i.e. the degree of confidence that the causal relationship put to test is not influenced by other factors or variables. For these reasons, researchers require careful design and control of experiments. Nonetheless, models are generally less sensitive to these issues since the modeller is aware of the idealisations and mechanisms of its models.</p>
<p>For modelling, the key concern is whether the relevant analogies between model and target hold. Such concern is usually not a problem for experiments, especially those conducted directly on the target. Once internal validity is assessed, researchers are confident that the inferences drawn from the experiment refer to the target. However, inferences drawn from model manipulation constitute neutral analogies considered as hypotheses regarding the target, requiring further testing and justification. This last step is error-prone.</p>
</div>
<div id="what-makes-a-good-model" class="section level3 hasAnchor" number="3.3.5">
<h3><span class="header-section-number">3.3.5</span> What makes a good model?<a href="empirical-practices.html#what-makes-a-good-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Since models are purpose dependent, there is no exhaustive set of sufficient and necessary conditions to define what a good model is. Nonetheless, there are some common criteria (e.g. robustness, simplicity, tractability) that can be balanced, but is often impossible to optimise all criteria at the same because some criteria are complements of each other.</p>
<p>The <strong>similarity</strong> criterion can for example assess physical resemblance. More generally, we could say that a model <span class="math inline">\(M\)</span> is similar to target <span class="math inline">\(X\)</span> if and only if <span class="math inline">\(M\)</span> is similar to <span class="math inline">\(X\)</span> with respect to the set of properties <span class="math inline">\(P\)</span> to a certain degree. However, this definition does not tell us which properties should be optimised. For instance, for a scale model of an air plane aimed at aerodynamic studies, it might be more justified to maximise the similarities of geometric properties over the interior design (e.g. the number of seats might not be relevant since the cabin is closed). Therefore, the purpose of the model justifies maximising one set of properties over another, in particular, the properties that are relevant for the research purpose.</p>
<p><strong>Robustness</strong> expresses how model results are affected by condition changes. Therefore, a model result is robust (w.r.t. some condition) if changing such condition does not alter the result. For example, all properties except one (e.g. plane hull colour) can be kept fixed to test whether painting the plane with a different colour might affect its aerodynamic properties. If the result remains equal, we can say the model is robust with respect to the hull colour. Perhaps such property is not relevant to the research purpose, but that is not enough to justify removing the property.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:prec-vs-acc"></span>
<img src="Figures/prec_vs_acc.png" alt="Accuracy consists of trueness (proximity of measurement results to the true value) and precision (repeatability or reproducibility of the measurement). Source: St. Olaf College." width="66%" />
<p class="caption">
Figure 3.10: Accuracy consists of trueness (proximity of measurement results to the true value) and precision (repeatability or reproducibility of the measurement). Source: <a href="https://wp.stolaf.edu/it/gis-precision-accuracy/">St. Olaf College</a>.
</p>
</div>
<p>Another model criterion to consider is <strong>precision</strong> (w.r.t. parameters). We say that model <span class="math inline">\(M_1\)</span> is more precise than <span class="math inline">\(M_2\)</span> if the parameter specifications of <span class="math inline">\(M_1\)</span> <em>imply</em> those from <span class="math inline">\(M_2\)</span>. This definition is better understood through an example. Consider the following models <span class="math inline">\(M_1\)</span>, <span class="math inline">\(M_2\)</span>, and <span class="math inline">\(M_3\)</span> and below definitions. The first model describes a rate of changes as a function of <span class="math inline">\(X\)</span>. <span class="math inline">\(M_2\)</span> is more precise as describes the rate of changes as a linear function of <span class="math inline">\(X\)</span>. The description of <span class="math inline">\(M_2\)</span> implies the description of <span class="math inline">\(M_1\)</span>. Linear functions of <span class="math inline">\(X\)</span> are a subset of functions of <span class="math inline">\(X\)</span>. Finally, the third model is yet more precise as it indicates an absolute value of the parameter <span class="math inline">\(a\)</span>, reducing the subset of linear functions from the definition of <span class="math inline">\(M_2\)</span> to a particular linear function. Importantly, parameter precision is a property of the model alone, not of the relationship between model and target. Although precision offers potential for high accuracy, it is no warrant for it. For instance, if the actual rate of linear change would be other than <span class="math inline">\(1.2X\)</span>, then the less precise model <span class="math inline">\(M_2\)</span> would be more accurate than <span class="math inline">\(M_3\)</span>. Similarly, if the rate of change would not change linearly, the more general model <span class="math inline">\(M_1\)</span> would be more accurate than the alternatives.</p>
<ul>
<li><span class="math inline">\(M_1: dX/dt = f(X)\)</span></li>
<li><span class="math inline">\(M_2: dX/dt = aX\)</span></li>
<li><span class="math inline">\(M_3: dX/dt = 1.2X\)</span></li>
</ul>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>Questions regarding scientific models also concern Machine Learning models to a great extent. For example, consider the precision and accuracy criteria. The following paragraph is extracted from <a href="https://dl.acm.org/doi/pdf/10.1145/2347736.2347755">the article “A Few Useful Things to Know About Machine Learning” by Pedro Domingos</a>.</p>
<blockquote>
<p>Everyone in machine learning knows about overfitting, but it comes in many forms that are not immediately obvious. One way to understand overfitting is by decomposing generalization error into bias and variance. Bias is a learner’s tendency to consistently learn the same wrong thing. Variance is the tendency to learn random things irrespective of the real signal. Figure illustrates this by an analogy with throwing darts at a board. A linear learner has high bias, because when the frontier between two classes is not a hyperplane the learner is unable to induce it. Decision trees do not have this problem because they can represent any Boolean function, but on the other hand they can suffer from high variance: decision trees learned on different training sets generated by the same phenomenon are often very different, when in fact they should be the same. Similar reasoning applies to the choice of optimization method: beam search has lower bias than greedy search, but higher variance, because it tries more hypotheses. Thus, contrary to intuition, a more powerful learner is not necessarily better than a less powerful one. — <span class="citation">(<a href="#ref-domingos2012few">Domingos 2012</a>)</span></p>
</blockquote>
</div>
<p><strong>Simplicity</strong> is often another criteria that affects models. A simpler model might fit very well its purpose. For example, underground maps often misrepresent distances or omit unnecessary details such as roads, monuments, etc. Such simplification is suited for the particular purpose of travelling in the underground but is not useful for other purposes. We can say a model is simpler if it contains less parameters, considers less variables and uses less operations than another model. Therefore, simplicity is a virtue with respect to the models and not to targets. Is usually a practical criterion that facilitates the model use.</p>
<p>Related to simplicity, we can find <strong>tractability</strong>. We say a model is tractable (w.r.t. a set of rules) if the relevant model result may be obtained by applying certain principles to the model. For instance, models solved through analytical methods (e.g. mathematical proofs) are called analytically tractable in contrast to models for which results can only be approximated through numerical simulations methods. Tractability implies the existence of methods to analyse and solve such models. In this sense, <strong>theoretical tractability</strong> considers theoretical principles to assess the suitability of the model for certain operations. For instance, a structural representation of a chemical compound allows for the application of functional group classification (this is an example of theoretical principle to fulfil). In contrast, a quantum mechanical model is more accurate but does not allow for such operation. Therefore we consider it a less tractable model.</p>
<p>Finally, <strong>transparency</strong> is an epistemic value that assesses the degree to which the model user can cognitively understand how the model result is produced. This criterion is known in artificial intelligence as interpretability and/or explainability. For example, a decision tree is often human-readable while the nature of neural networks creates obfuscated models difficult to interpret. Transparent models allow to back-track the result and understand how it was produced from a given input. A transparent model enables the scientist to check the correctness of the results, which is especially important when employing models developed by third parties.</p>
<p>Again, most of the previous virtues will require certain trade-off. Increasing an epistemic value often entails decreasing another one. Therefore, building or choosing a model requires finding the best trade-off for the model’s purpose.</p>
</div>
<div id="models-as-mirrors" class="section level3 hasAnchor" number="3.3.6">
<h3><span class="header-section-number">3.3.6</span> Models as mirrors<a href="empirical-practices.html#models-as-mirrors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A common way to consider models is as mirrors of the real world. Very often, models are built to be as similar as possible to the target. This is common in highly complex projects such as brain simulations of the neural networks that represent human brain activity or epidemic simulations in which all the available demographic information (e.g. transportation, habits) is considered. The aim of such complex projects is to build a model as a replacement of the actual target system. In the case of epidemic simulations, it is clear that is not feasible to conduct real-world experiments, but the simulation can serve as a way to try different vaccination strategies that might, for instance, prioritise the vaccination of potential super spreaders, i.e. people who are in contact with many people during their daily routine (e.g. supermarket cashiers, waiters). In this sense, we say that the simulation is <em>mirroring</em> the world. Another example from engineering includes finite element analysis (FEA) which is used to divide a complex problem into smaller elements to facilitate calculations.</p>
<p>This type of model is very similar to the target and require high precision modelling. However, these advantages come at a cost. For instance, they compromise the simplicity, transparency and sometimes the tractability of the models. Despite the high similarity of the models to their target systems, it is not enough to avoid external validity issues. For example, FEA employs a mesh consisting of millions of small elements that mould the physical shape of the analysed structure. Then, calculations are made for each element. Such approximations are usually polynomial, which means that the structural elements have been interpolated, and their precision is bounded to the mesh size. Therefore, the accuracy depends on the purpose of the analysis (e.g. car, hardware tools, camera).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fea"></span>
<img src="Figures/FAE_visualization.jpg" alt="A visualization of an asymmetrical collision analysis using the finite element analysis method." width="50%" />
<p class="caption">
Figure 3.11: A visualization of an asymmetrical collision analysis using the finite element analysis method.
</p>
</div>
</div>
<div id="models-as-isolations" class="section level3 hasAnchor" number="3.3.7">
<h3><span class="header-section-number">3.3.7</span> Models as isolations<a href="empirical-practices.html#models-as-isolations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An alternative perspective is to consider models as isolations of particular features of the complex world. This consideration is motivated by the following question. Can models be similar to their target systems and still be simple? We have previously seen that these two factors are very often inversely related. Isolated models choose a particular aspect of the target, disregarding all the rest. Then, a model is built to represent the behaviour of such factors as accurately as possible.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lift"></span>
<img src="Figures/lift.jpg" alt="Reproduction of lift balance used in 1901 wind tunnel; model airfoil in testing position. Source: NPS." width="50%" />
<p class="caption">
Figure 3.12: Reproduction of lift balance used in 1901 wind tunnel; model airfoil in testing position. Source: NPS.
</p>
</div>
<p>During the development of the airplane. George Cayley (1773 - 1857) proposed to separate the airplane system into 3 subsystems: Lift, Propulsion, Control. After this, the problem is divided into three problems, i.e. how to obtain lift, how to provide propulsion, and how to offer control. The Wright Brothers developed a separate model for each of this subsystems. As can be observed in Figure <a href="empirical-practices.html#fig:lift">3.12</a>, the lift balance model does not resemble an airplane. Similarly, their propeller model was not attached to the airplane. Likewise, they employed gliders to test their control systems. This contrast with the approach of other inventors, such as Hiram Maxim, who attempted to build a full scale from scratch.
An overview of the Wright Brothers Invention Process can be found at <a href="https://wright.nasa.gov/overview.htm">NASA’s website</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:brothers"></span>
<img src="Figures/Wright_Brothers.jpg" alt="Historic photo of the Wright brothers’ third test glider being launched at Kill Devil Hills, North Carolina, on October 10, 1902. Wilbur Wright is at the controls, Orville Wright is at left, and Dan Tate (a local resident and friend of the Wright brothers) is at right." width="50%" />
<p class="caption">
Figure 3.13: Historic photo of the Wright brothers’ third test glider being launched at Kill Devil Hills, North Carolina, on October 10, 1902. Wilbur Wright is at the controls, Orville Wright is at left, and Dan Tate (a local resident and friend of the Wright brothers) is at right.
</p>
</div>
<p>However, a limitation of this approach is that the target system must be dividable in different subsystems. Similarly, the results of valid isolating models might not look like the real world phenomena simply because the latter is a combination of effects. On the other side, the model represents a single effect in isolation. Therefore, the validation of isolated models is problematic.</p>
<!--

Models as mirrors. Models as isolations.

--->
</div>
</div>
<div id="examples-2" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Examples<a href="empirical-practices.html#examples-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="willow" class="section level3 hasAnchor" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Willow tree experiment<a href="empirical-practices.html#willow" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<figure class="wrap-figure">
<img src="Figures/Jan_Baptist_van_Helmont_portrait.jpg">
<figcaption>
Portrait of Jan Baptist van Helmont by Mary Beale, c.1674.
</figcaption>
</figure>
<p>Jan Baptist van Helmont (1580 - 1644) was a chemist, physiologist, and physician from the Spanish Netherlands (current Belgium).
In 1634, Jan Baptist was arrested by agents of the Spanish Inquisition for the crime of studying plants and other natural phenomena. During his house arrest, he studied how plants grew. The prevailing theory at the time, stated that plants grew by eating soil, and Jan Baptist conceived an experiment to test this idea. Such prevailing theory has its origins in the ancient Greeks.</p>
<p>Jan Baptist started by weighing a small willow tree (2.28 kg) and then weighed the dry soil (90 kg) in which he planted the tree. To prevent the dust from the surrounding air from mixing with the earth, the rim of the pot was protected, covered with a sheet of iron covered with tin and pierced by many holes. The tree was watered with rainwater or (when necessary) with distilled water. Jan Baptist left the tree for five years. After the five years had passed, Jan Baptist re-weighed the tree, which weighed 169 pounds (about 77 kg). He also re-weighed the dried soil and found the same 200 pounds (90 kg) minus about 2 ounces (56 gm).</p>
<p>He wrongly concluded that the mass gain of the tree was produced by the water, which was his only intervention on the system. Although the experiment was carefully conducted, the conclusions derived from the experiment were wrong because the theory on which it was based was incorrect. Importantly, the fact that Helmont used soil contradicted his hypothesis that only water was needed for plant growth <span class="citation">(<a href="#ref-hershey1991digging">Hershey 1991</a>)</span>.</p>
<p>Jan Baptist did not know anything about photosynthesis. During the photosynthesis, carbon from the air and minerals from the soil are used to generate new plant tissue. Ironically, Helmont has been credited with discovering carbon dioxide <span class="citation">(<a href="#ref-hershey1991digging">Hershey 1991</a>)</span>.</p>
<p>The employment of the balance during van Helmont’s experiment was an important improvement; Jan Baptist believed that the mass of materials had to be accounted for during the study of chemical processes. This experiment is considered the first quantitative experiment in plant nutrition. It is also a great example of how firm conclusions can be misled by lack of knowledge of the studied system. Jan Baptist failed to control for an important background factor.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:van-helmont"></span>
<img src="Figures/Van_Helmont_Experiment.jpg" alt="Illustration of the willow tree experiment. By Lars Ebbersmeyer." width="70%" />
<p class="caption">
Figure 3.14: Illustration of the willow tree experiment. By <a href="https://commons.wikimedia.org/wiki/File:Van_Helmont_Experiment.jpg">Lars Ebbersmeyer</a>.
</p>
</div>
</div>
<div id="john-snow" class="section level3 hasAnchor" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> 1854 Broad Street cholera outbreak<a href="empirical-practices.html#john-snow" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<figure class="wrap-figure">
<img src="Figures/John_Snow.jpg">
<figcaption>
Dr. John Snow (1813-1858), British physician.
</figcaption>
</figure>
<p>The birth of epidemiology and public health is often attributed to the Natural Experiment described by Dr. John Snow in the mid-1800s when he investigated the relationship between drinking contaminated water and the incidence of cholera <span class="citation">(<a href="#ref-applied_stats_healthcare">Montelpare 2021</a>)</span>. The case of Dr. Snow is very popular in public health science and can be found in several books and posts on-line but I recommend the explanation given in Chapter 7 from The Book of Why <span class="citation">(<a href="#ref-book-of-why">Pearl and Mackenzie 2018</a>)</span> as the authors also re-formulate the case in causal terms, using concepts that were not available in the mid-1800s. Below, I give a summarised account of this study.</p>
<blockquote>
<p><em>Miasma</em>: “A vaporous exhalation formerly believed to cause disease.”</p>
</blockquote>
<p>Since the 1830s, various epidemics spread across Europe but were often attributed to social unrest and political upheaval. During the 1850s, there were several theories and misconceptions about the causes of cholera outbreaks. The miasma theory attempted to explain outbreaks of bubonic plague and cholera, stating that they were caused by a form of “bad air”. According to the competing theory, i.e. the germ theory of disease, the cause of the outbreak was a yet unknown germ. However, in 1853, disease-causing germs had not yet been observed under a microscope and the germ theory of disease was not established yet. Louis Pasteur did not demonstrate the relationship between germ and disease until the 1860s. Therefore, the prevailing theory was that a miasma of unhealthy air caused cholera.</p>
<p>In August 1854, a major outbreak of cholera occurred in Soho, London (United Kingdom). In just three days, 127 people died in Broad Street. By September, 500 people had died. John Snow was skeptical of the prevailing miasma theory and theorized that the cause was the presence of an agent in the contaminated water source from certain water supplying companies <span class="citation">(<a href="#ref-applied_stats_healthcare">Montelpare 2021</a>)</span>. Namely, the Southwark and Vauxhall Company and the Lambeth Waterworks Company. The main difference between the two companies was that the former drew its water from London Bridge, which was downstream from London’s sewers. Years earlier, Lambeth had moved its water intake so that it would be upstream of the sewers.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:thames"></span>
<img src="Figures/JohnSnowRiver.png" alt="Water distribution by the Lambeth Water and the Southwark &amp; Vauxhall Companies." width="66%" />
<p class="caption">
Figure 3.15: Water distribution by the Lambeth Water and the Southwark &amp; Vauxhall Companies.
</p>
</div>
<p>Therefore, the customers of the Southwark and Vauxhall Company were getting water contaminated by the excrements of cholera victims, whereas Lambeth users were drinking uncontaminated water.</p>
<p>In consequence, districts supplied by the Southwark and Vauxhall Company had a death rate eight times higher than other districts. At this point, the evidence supporting the hypothesis of water contamination is just circumstantial. The causal diagram from Figure <a href="empirical-practices.html#fig:snow-dia-A">3.16</a> depicts the situation. A proponent of the miasma theory could argue that the effect of miasma was strongest in those districts <span class="citation">(<a href="#ref-book-of-why">Pearl and Mackenzie 2018</a>)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:snow-dia-A"></span>
<img src="Figures/SnowDiagramA.png" alt="Causal diagram for cholera for the case of John Snow." width="33%" />
<p class="caption">
Figure 3.16: Causal diagram for cholera for the case of John Snow.
</p>
</div>
<p>Then, Snow noted that in some districts water was served by both companies (see Fig. <a href="empirical-practices.html#fig:snow-map">3.18</a>), and even there, the death rate was still higher in the houses where water was supplied by the Southwark and Vauxhall Company. Those households did not showcase any difference in terms of poverty or miasma. Snow wrote: “each company supplies to both rich and poor, both large houses and small; there is no difference either in the condition or occupation of the persons receiving the water of the different companies.” <span class="citation">(<a href="#ref-book-of-why">Pearl and Mackenzie 2018</a>)</span>.</p>
<table>
<caption>Relation of the household water source and deaths</caption>
<thead>
<tr class="header">
<th align="left">Source of water</th>
<th align="center">Deaths</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Southwark and Vauxhall company</td>
<td align="center">286</td>
</tr>
<tr class="even">
<td align="left">Lambeth company</td>
<td align="center">14</td>
</tr>
<tr class="odd">
<td align="left">Direct from the river</td>
<td align="center">22</td>
</tr>
<tr class="even">
<td align="left">Pump wells</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="left">Ditches</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="left">Unknown</td>
<td align="center">4</td>
</tr>
</tbody>
</table>
<p><strong>It is precisely at this point where the natural experiment takes all its strength.</strong> Around 300 people of both sexes, every age, and socio-economic class were naturally divided into two groups without them to know. One group received pure water, whereas the other received water mixed with sewage.</p>
<p>The observations of John Snow introduced a new variable into the causal diagram (see Fig. <a href="empirical-practices.html#fig:snow-dia-B">3.17</a>), the <strong>Water Company</strong>. In this new diagram we can see that there is no arrow between Miasma and Water Company, therefore both variables are independent. Moreover, we can note the presence of an arrow between Water Company and Water Purity. Finally, the diagram depicts a third assumption. There is no direct arrow from Water Company to Cholera, i.e. water companies do not deliver cholera to their customers in any other way.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:snow-dia-B"></span>
<img src="Figures/SnowDiagramB.png" alt="Causal diagram after the introduction of an instrumental variable." width="50%" />
<p class="caption">
Figure 3.17: Causal diagram after the introduction of an instrumental variable.
</p>
</div>
<p>A variable that satisfies these properties is called an <strong>instrumental variable</strong>. See <span class="citation">(<a href="#ref-pokropek2016introduction">Pokropek 2016</a>)</span> for examples of valid and invalid instrumental variables and <a href="https://scpoecon.github.io/ScPoEconometrics/IV.html">SciencesPo</a> for econometric examples. <strong>Since there are no confounders of the relation between Water Company and Cholera, any observed association must be causal</strong>. Similarly, the association between Water Purity and Cholera is also causal.</p>
<blockquote>
<p>Specifically, an instrumental variable Z is an additional variable used to estimate the causal effect of variable X on Y. The traditional definition qualifies a variable Z as an instrumental (relative to the pair (X, Y)) if (i) Z is independent of all variables (including error terms) that have an influence on Y that is not mediated by X and (ii) Z is not independent of X. — <span class="citation">(<a href="#ref-pearl2000causality">Pearl 2000</a>)</span></p>
</blockquote>
<p>Although today miasma theory has been discredited, poverty and location are clear confounders. In <span class="citation">(<a href="#ref-book-of-why">Pearl and Mackenzie 2018</a>)</span>, the authors show how instrumental variables can be used to determine the number of lives that could have been saved by purifying the water supply. The instrumental variable <strong>Water Company</strong> allow us to find the effect of <strong>Water Purity</strong> on <strong>Cholera</strong> even without being able to control, or collect data on, the confounder variables (poverty, location, etc.).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:snow-map"></span>
<img src="Figures/snow-cholera-map-crop.jpg" alt="Detail of John Snow’s map of Cholera in the Broad Street outbreak in 1854. Each bar represents one death in a topography that attempted to relate the water source (“Pump”) to pattern of cases in the neighborhood outbreak." width="100%" />
<p class="caption">
Figure 3.18: Detail of John Snow’s map of Cholera in the Broad Street outbreak in 1854. Each bar represents one death in a topography that attempted to relate the water source (“Pump”) to pattern of cases in the neighborhood outbreak.
</p>
</div>
<p>One of the main innovations of John Snow approach was to focus on death rates in districts served by two water companies rather than on data from victims of the Broad Street pump which drew water from a well.</p>
<blockquote>
<p>A transitional period began in the late 1850s with the work of Louis Pasteur. This work was later extended by Robert Koch in the 1880s. By the end of that decade, the miasma theory was struggling to compete with the germ theory of disease. Viruses were initially discovered in the 1890s. Eventually, a “golden era” of bacteriology ensued, during which the germ theory quickly led to the identification of the actual organisms that cause many diseases. — Wikipedia, <a href="https://en.wikipedia.org/wiki/Germ_theory_of_disease">Germ theory of disease</a>.</p>
</blockquote>
</div>
<div id="causal-models" class="section level3 hasAnchor" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> Causal models: Estimating treatment effect in the pressence of a confounder<a href="empirical-practices.html#causal-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This example illustrates the use of a causal model and causal inference methods to estimate the effect of <code>study hours</code> (per week) in the final exam <code>scores</code>. Our outcome again is students’ scores. We aim to estimate the causal effect that the “<em>treatment</em>” <code>study hours</code> has on students’ <code>scores</code> (effect). Our beliefs and assumptions are encoded into a causal model. We assume that <code>study hours</code> (per week) is directly related to <code>scores</code> but also that the <code>prior knowledge</code> affects both the effect and the cause (i.e., it is a confounder). For this exercise we will employ Python language and the library <a href="https://www.pywhy.org">doWhy</a>.</p>
<p>This example shows how to estimate the effect while controlling for the confounder. Remember that a confounder <code>Z</code> affects both the cause <code>X</code> and the effect/outcome <code>Y</code>.</p>
<p>We import the necessary packages to work.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="empirical-practices.html#cb19-1" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb19-2"><a href="empirical-practices.html#cb19-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-3"><a href="empirical-practices.html#cb19-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-4"><a href="empirical-practices.html#cb19-4" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb19-5"><a href="empirical-practices.html#cb19-5" tabindex="-1"></a><span class="im">import</span> dowhy</span>
<span id="cb19-6"><a href="empirical-practices.html#cb19-6" tabindex="-1"></a><span class="im">from</span> dowhy <span class="im">import</span> CausalModel</span></code></pre></div>
<p>Then, we begin by creating a synthetic dataset in which study hours and prior knowledge are random variables normally distributed. Then, exam score is a function of both study hours and prior knowledge. In a real world scenario, we would normally not know about this function because is what we are trying to estimate. Note the values in the function, specifically, the <code>2 * data["study_hours"]</code>.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="empirical-practices.html#cb20-1" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb20-2"><a href="empirical-practices.html#cb20-2" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb20-3"><a href="empirical-practices.html#cb20-3" tabindex="-1"></a>    <span class="st">&quot;study_hours&quot;</span>: np.random.normal(<span class="dv">10</span>, <span class="dv">2</span>, <span class="dv">1000</span>),  </span>
<span id="cb20-4"><a href="empirical-practices.html#cb20-4" tabindex="-1"></a>    <span class="st">&quot;prior_knowledge&quot;</span>: np.random.normal(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1000</span>),</span>
<span id="cb20-5"><a href="empirical-practices.html#cb20-5" tabindex="-1"></a>    <span class="st">&quot;exam_score&quot;</span>: np.zeros(<span class="dv">1000</span>)  <span class="co"># Placeholder for exam score</span></span>
<span id="cb20-6"><a href="empirical-practices.html#cb20-6" tabindex="-1"></a>})</span>
<span id="cb20-7"><a href="empirical-practices.html#cb20-7" tabindex="-1"></a></span>
<span id="cb20-8"><a href="empirical-practices.html#cb20-8" tabindex="-1"></a><span class="co"># Define the relationship: </span></span>
<span id="cb20-9"><a href="empirical-practices.html#cb20-9" tabindex="-1"></a><span class="co"># Exam score is influenced by both study hours and prior knowledge</span></span>
<span id="cb20-10"><a href="empirical-practices.html#cb20-10" tabindex="-1"></a>data[<span class="st">&quot;exam_score&quot;</span>] <span class="op">=</span> (<span class="dv">5</span> <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> data[<span class="st">&quot;study_hours&quot;</span>] </span>
<span id="cb20-11"><a href="empirical-practices.html#cb20-11" tabindex="-1"></a>                       <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> data[<span class="st">&quot;prior_knowledge&quot;</span>] </span>
<span id="cb20-12"><a href="empirical-practices.html#cb20-12" tabindex="-1"></a>                       <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>))</span>
<span id="cb20-13"><a href="empirical-practices.html#cb20-13" tabindex="-1"></a></span>
<span id="cb20-14"><a href="empirical-practices.html#cb20-14" tabindex="-1"></a>data.head(<span class="dv">5</span>)</span></code></pre></div>
<pre><code>##    study_hours  prior_knowledge  exam_score
## 0    10.993428         4.399355   39.509745
## 1     9.723471         3.924634   36.076325
## 2    11.295377         3.059630   35.977225
## 3    13.046060         2.353063   37.843348
## 4     9.531693         3.698223   33.264442</code></pre>
<p>Now, we will define the model and visualize it.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="empirical-practices.html#cb22-1" tabindex="-1"></a>model <span class="op">=</span> CausalModel(</span>
<span id="cb22-2"><a href="empirical-practices.html#cb22-2" tabindex="-1"></a>    data<span class="op">=</span>data,</span>
<span id="cb22-3"><a href="empirical-practices.html#cb22-3" tabindex="-1"></a>    treatment<span class="op">=</span><span class="st">&quot;study_hours&quot;</span>,</span>
<span id="cb22-4"><a href="empirical-practices.html#cb22-4" tabindex="-1"></a>    outcome<span class="op">=</span><span class="st">&quot;exam_score&quot;</span>,</span>
<span id="cb22-5"><a href="empirical-practices.html#cb22-5" tabindex="-1"></a>    common_causes<span class="op">=</span>[<span class="st">&quot;prior_knowledge&quot;</span>])</span>
<span id="cb22-6"><a href="empirical-practices.html#cb22-6" tabindex="-1"></a></span>
<span id="cb22-7"><a href="empirical-practices.html#cb22-7" tabindex="-1"></a>model.view_model(size<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">3</span>))</span>
<span id="cb22-8"><a href="empirical-practices.html#cb22-8" tabindex="-1"></a>plt.tight_layout(w_pad<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="POSDE_bookdown_files/figure-html/unnamed-chunk-30-1.png" width="768" /></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="empirical-practices.html#cb23-1" tabindex="-1"></a>identified_estimand <span class="op">=</span> model.identify_effect()</span>
<span id="cb23-2"><a href="empirical-practices.html#cb23-2" tabindex="-1"></a>estimate <span class="op">=</span> model.estimate_effect(identified_estimand, </span>
<span id="cb23-3"><a href="empirical-practices.html#cb23-3" tabindex="-1"></a>   method_name<span class="op">=</span><span class="st">&quot;backdoor.linear_regression&quot;</span>)</span></code></pre></div>
<p>The result below means that, according to our causal model, an additional hour of study per week is estimated to increase the exam score by approximately 2 points. This effect is derived after accounting for the confounder (in this case, <code>prior knowledge</code>) using the backdoor criterion. If this estimate is accurate, it suggests a positive causal relationship between study hours and exam score, where more study hours lead to higher scores.</p>
<p>As can be seen, this estimation is very close to the degree stated in the equation of our synthetic data in <code>2 * data["study_hours"]</code>.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="empirical-practices.html#cb24-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Causal Estimate of Study Hours on Exam Score:&quot;</span>, </span>
<span id="cb24-2"><a href="empirical-practices.html#cb24-2" tabindex="-1"></a>     estimate.value)</span></code></pre></div>
<pre><code>## Causal Estimate of Study Hours on Exam Score: 2.010902911319434</code></pre>
<p>A placebo test in causal inference is a refutation technique designed to test the robustness of our causal estimate by using a “fake” treatment variable. The idea is to see if our model incorrectly detects a causal effect when there should be none, which would indicate potential bias or flaws in the model. The placebo test helps us check if this estimated causal effect could be due to biases in the model rather than a true causal relationship.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="empirical-practices.html#cb26-1" tabindex="-1"></a>refute_result <span class="op">=</span> model.refute_estimate(identified_estimand, </span>
<span id="cb26-2"><a href="empirical-practices.html#cb26-2" tabindex="-1"></a>  estimate, method_name<span class="op">=</span><span class="st">&quot;placebo_treatment_refuter&quot;</span>)</span></code></pre></div>
<p>This test replaces the actual treatment (study hours) with a “placebo” or random variable that should have no causal effect on the outcome (exam score).</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="empirical-practices.html#cb27-1" tabindex="-1"></a><span class="bu">print</span>(refute_result)</span></code></pre></div>
<pre><code>## Refute: Use a Placebo Treatment
## Estimated effect:2.010902911319434
## New effect:0.0
## p value:2.0</code></pre>
<ul>
<li><p>New effect (0.0): This shows that the placebo treatment has no effect on the outcome, as expected (since it’s a random variable unrelated to exam score).</p></li>
<li><p>Original effect (2.01) vs. New effect (0.0): The fact that the original effect remains 2.01 while the placebo effect is 0 suggests that the observed causal effect of study hours on exam score is not due to random bias. Instead, it’s likely a true effect.</p></li>
<li><p>p-value (2.0): A high p-value indicates that there is no statistically significant effect with the placebo treatment. This further supports that any observed effect in the placebo scenario is likely due to chance.</p></li>
</ul>
<p>The placebo test confirms that our causal model appears robust, as it detects no effect when a placebo treatment is used. Therefore, we can have more confidence that the estimated effect of 2.01 is a genuine causal effect of study hours on exam score, rather than an artifact of model bias or unmeasured confounding.</p>
<p>These results suggest that our initial model is likely valid, meaning that the relationship we estimated is trustworthy given the data and assumptions. But things could still be wrong… as we will see in the next example.</p>
<div id="backdoor-criterion" class="section level4 hasAnchor" number="3.4.3.1">
<h4><span class="header-section-number">3.4.3.1</span> Backdoor criterion<a href="empirical-practices.html#backdoor-criterion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The backdoor criterion is a method used in causal inference to control for confounders—variables that influence both the treatment and the outcome. By satisfying the backdoor criterion, we aim to isolate the causal effect of the treatment on the outcome by “blocking” other paths of influence. Suppose we have a causal structure where a variable<code>Z</code> (like prior knowledge) affects both our treatment <code>X</code> (study hours) and outcome <code>Y</code> (exam score). The backdoor criterion tells us to condition on (i.e., adjust for) variables like <code>Z</code> which lie on “backdoor paths” that might introduce bias in estimating the effect of <code>X</code> on <code>Y</code>. By conditioning on <code>Z</code>, we effectively “block” any non-causal paths from <code>X</code> to
<code>Y</code>, allowing us to observe the effect of <code>X</code> on <code>Y</code> without interference from confounding.</p>
<p>When we adjust for a variable like <code>Z</code> in causal inference, we’re essentially isolating the relationship between the treatment <code>X</code>(e.g., study hours) and the outcome <code>Y</code> (e.g., exam score) by removing the influence of <code>Z</code> (e.g., prior knowledge) on both <code>X</code>and <code>Y</code>. This adjustment is typically done in one of a few statistical ways, such as conditioning, stratification, or regression. Here a summary of them:</p>
<ul>
<li><p>Conditioning on <code>Z</code>: Conditioning involves looking at the relationship between <code>X</code> and <code>Y</code> within subgroups defined by different values of <code>Z</code>. By examining these subgroups, we can remove the influence of <code>Z</code> on <code>X</code> and <code>Y</code>. For instance, if <code>Z</code> represents prior knowledge levels (low, medium, high), we can separately look at the effect of study hours on exam scores within each of these prior knowledge groups. This way, any relationship between <code>X</code> and <code>Y</code> is not confounded by <code>Z</code>.</p></li>
<li><p>Stratification by <code>Z</code>: Stratification divides the data into strata (groups) based on the values of <code>Z</code>, and then estimates the effect of <code>X</code> on <code>Y</code> within each stratum. The overall effect is a weighted average of the effect within each stratum. In our example, if <code>Z</code> (prior knowledge) has three levels, we could stratify our analysis into three groups and then calculate the effect of study hours on exam scores within each level of prior knowledge. By averaging these effects, we get a more accurate estimate that accounts for the confounding effect of <code>Z</code>.</p></li>
<li><p>Regression Adjustment: Regression adjustment uses statistical models (usually linear or logistic regression) to “hold constant” the effects of <code>Z</code> on both <code>X</code> and <code>Y</code>. By including <code>Z</code> as a variable in the regression model, we can estimate the relationship between <code>X</code> and <code>Y</code> while “controlling” for <code>Z</code>.</p></li>
</ul>
<p>Adjusting for <code>Z</code>removes any indirect associations between <code>X</code> and <code>Y</code> that arise because <code>Z</code> influences both. By blocking this confounding pathway, we effectively “close” the backdoor path and allow the model to estimate a more accurate causal effect between <code>X</code> and <code>Y</code>. In causal inference, this adjustment step is crucial because it attempts to mimic a randomized experiment where all confounders would ideally be balanced, allowing us to make stronger causal claims about <code>X</code> and <code>Y</code>.</p>
</div>
</div>
<div id="causal-models-overestimation" class="section level3 hasAnchor" number="3.4.4">
<h3><span class="header-section-number">3.4.4</span> Causal models: Detecting an overestimation<a href="empirical-practices.html#causal-models-overestimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This example illustrates the use of a first causal model that is <strong>WRONG</strong> because it leaves out an important variable (either because we don’t know about it or because we <strong>believe</strong> it does not have an effect on the outcome).</p>
<ul>
<li>Our <strong>outcome</strong> again is students’ <code>grades</code>.</li>
<li>We aim to estimate the causal effect that the “<em>treatment</em>” <code>private tutoring</code> has on students’ grades (<strong>effect</strong>).</li>
<li>We <strong>believe</strong> that <code>study hours</code> (per week) is the only variable that affects both tutoring and grades (i.e., it is a <strong>confounder</strong>)</li>
</ul>
<p>We will see how to <strong>detect that the model is wrong</strong> and how once corrected it estimates the effect properly.</p>
<p>We generate a synthetic data with different random values. As you can see <code>parental involvement</code> is biased with a 70% probability to be 0 and 30% of being 1. In the last two lines we fill tutoring and grade as we have synthetically made them to depend on the study hours and parental involvement. Imagine that instead of being synthetically created this data was given to you from data collection (e.g. via surveys).</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="empirical-practices.html#cb29-1" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb29-2"><a href="empirical-practices.html#cb29-2" tabindex="-1"></a><span class="co">#generate synthetic data</span></span>
<span id="cb29-3"><a href="empirical-practices.html#cb29-3" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb29-4"><a href="empirical-practices.html#cb29-4" tabindex="-1"></a>    <span class="st">&quot;study_hours&quot;</span>: np.random.normal(<span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">1000</span>),  </span>
<span id="cb29-5"><a href="empirical-practices.html#cb29-5" tabindex="-1"></a>    <span class="st">&quot;parental_involvement&quot;</span>: np.random.choice([<span class="dv">0</span>, <span class="dv">1</span>], </span>
<span id="cb29-6"><a href="empirical-practices.html#cb29-6" tabindex="-1"></a>                                             size<span class="op">=</span><span class="dv">1000</span>, </span>
<span id="cb29-7"><a href="empirical-practices.html#cb29-7" tabindex="-1"></a>                                             p<span class="op">=</span>[<span class="fl">0.7</span>, <span class="fl">0.3</span>]),  </span>
<span id="cb29-8"><a href="empirical-practices.html#cb29-8" tabindex="-1"></a>    <span class="st">&quot;tutoring&quot;</span>: np.zeros(<span class="dv">1000</span>),  <span class="co"># Placeholder for tutoring</span></span>
<span id="cb29-9"><a href="empirical-practices.html#cb29-9" tabindex="-1"></a>    <span class="st">&quot;grade&quot;</span>: np.zeros(<span class="dv">1000</span>)  <span class="co"># Placeholder for grade</span></span>
<span id="cb29-10"><a href="empirical-practices.html#cb29-10" tabindex="-1"></a>})</span>
<span id="cb29-11"><a href="empirical-practices.html#cb29-11" tabindex="-1"></a></span>
<span id="cb29-12"><a href="empirical-practices.html#cb29-12" tabindex="-1"></a><span class="co"># Assume tutoring is influenced by </span></span>
<span id="cb29-13"><a href="empirical-practices.html#cb29-13" tabindex="-1"></a><span class="co"># both study hours and parental involvement</span></span>
<span id="cb29-14"><a href="empirical-practices.html#cb29-14" tabindex="-1"></a>data[<span class="st">&quot;tutoring&quot;</span>] <span class="op">=</span> (data[<span class="st">&quot;study_hours&quot;</span>] </span>
<span id="cb29-15"><a href="empirical-practices.html#cb29-15" tabindex="-1"></a>            <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> data[<span class="st">&quot;parental_involvement&quot;</span>] </span>
<span id="cb29-16"><a href="empirical-practices.html#cb29-16" tabindex="-1"></a>            <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1000</span>) <span class="op">&gt;</span> <span class="dv">6</span>).astype(<span class="bu">int</span>)</span>
<span id="cb29-17"><a href="empirical-practices.html#cb29-17" tabindex="-1"></a></span>
<span id="cb29-18"><a href="empirical-practices.html#cb29-18" tabindex="-1"></a>data[<span class="st">&quot;grade&quot;</span>] <span class="op">=</span> (<span class="dv">50</span> <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> data[<span class="st">&quot;tutoring&quot;</span>] </span>
<span id="cb29-19"><a href="empirical-practices.html#cb29-19" tabindex="-1"></a>                    <span class="op">+</span> <span class="dv">5</span> <span class="op">*</span> data[<span class="st">&quot;study_hours&quot;</span>] </span>
<span id="cb29-20"><a href="empirical-practices.html#cb29-20" tabindex="-1"></a>                    <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> data[<span class="st">&quot;parental_involvement&quot;</span>] </span>
<span id="cb29-21"><a href="empirical-practices.html#cb29-21" tabindex="-1"></a>                    <span class="op">+</span> np.random.normal(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1000</span>))</span>
<span id="cb29-22"><a href="empirical-practices.html#cb29-22" tabindex="-1"></a></span>
<span id="cb29-23"><a href="empirical-practices.html#cb29-23" tabindex="-1"></a>data.tail(<span class="dv">10</span>)</span></code></pre></div>
<pre><code>##      study_hours  parental_involvement  tutoring      grade
## 990     5.441033                     0         1  86.784749
## 991     5.178793                     0         0  75.005558
## 992     4.200578                     1         1  92.496516
## 993     5.240788                     0         0  74.929059
## 994     5.289121                     1         1  98.189120
## 995     5.412871                     0         0  77.813355
## 996     4.801601                     0         0  76.318058
## 997     5.094192                     1         1  96.811745
## 998     3.852389                     0         0  67.153054
## 999     4.641886                     0         0  71.478162</code></pre>
<p>Next we create our <strong>initial causal model</strong> in which we <strong>wrongly</strong> assume that <code>parental involvement</code> does not affect anything else. Again, the reasons for this error could be two:</p>
<ul>
<li>We don’t know about this variable. So we didn’t even captured it to begin with (e.g. we didn’t ask in the survey).</li>
<li>We captured this variable (but we asked so many things in our survey !) but we believe not to affect the other variables.</li>
</ul>
<p>Note that, whether unknown to us or wrongly assumed by us, variables can be affected by <code>parental involvement</code> in reality. The model shows that <code>study hours</code> is a <strong>confounder</strong> of both <code>tutoring</code> and <code>grade</code>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="empirical-practices.html#cb31-1" tabindex="-1"></a><span class="co"># Create a causal model excluding parental involvement initially</span></span>
<span id="cb31-2"><a href="empirical-practices.html#cb31-2" tabindex="-1"></a>model <span class="op">=</span> CausalModel(</span>
<span id="cb31-3"><a href="empirical-practices.html#cb31-3" tabindex="-1"></a>    data<span class="op">=</span>data,</span>
<span id="cb31-4"><a href="empirical-practices.html#cb31-4" tabindex="-1"></a>    treatment<span class="op">=</span><span class="st">&quot;tutoring&quot;</span>,</span>
<span id="cb31-5"><a href="empirical-practices.html#cb31-5" tabindex="-1"></a>    outcome<span class="op">=</span><span class="st">&quot;grade&quot;</span>,</span>
<span id="cb31-6"><a href="empirical-practices.html#cb31-6" tabindex="-1"></a>    common_causes<span class="op">=</span>[<span class="st">&quot;study_hours&quot;</span>])</span>
<span id="cb31-7"><a href="empirical-practices.html#cb31-7" tabindex="-1"></a></span>
<span id="cb31-8"><a href="empirical-practices.html#cb31-8" tabindex="-1"></a>model.view_model(size<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">3</span>))</span>
<span id="cb31-9"><a href="empirical-practices.html#cb31-9" tabindex="-1"></a>plt.tight_layout(w_pad<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="POSDE_bookdown_files/figure-html/unnamed-chunk-36-3.png" width="768" /></p>
<p>Our initial results show an estimated effect of 14.98 meaning that having <code>private tutoring</code> is estimated to increase a student’s final <code>grade</code> by approximately 17 points. This effect estimate was obtained after controlling for <code>study hours</code> but without considering the additional confounder <code>parental involvement</code>. At this point we could be naively happy with this result. But what if we are overestimating or underestimating the effect of <code>tutoring</code>?</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="empirical-practices.html#cb32-1" tabindex="-1"></a>identified_estimand <span class="op">=</span> model.identify_effect()</span>
<span id="cb32-2"><a href="empirical-practices.html#cb32-2" tabindex="-1"></a>estimate <span class="op">=</span> model.estimate_effect(identified_estimand, </span>
<span id="cb32-3"><a href="empirical-practices.html#cb32-3" tabindex="-1"></a>            method_name<span class="op">=</span><span class="st">&quot;backdoor.linear_regression&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="empirical-practices.html#cb33-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Estimated Effect (initial model):&quot;</span>, </span>
<span id="cb33-2"><a href="empirical-practices.html#cb33-2" tabindex="-1"></a>      estimate.value)</span></code></pre></div>
<pre><code>## Estimated Effect (initial model): 17.585373682989484</code></pre>
<p>Again, the placebo test below replaces the actual treatment (in this case, <code>tutoring</code>) with a “placebo” or random variable that has no relationship to the outcome (final <code>grade</code>).</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="empirical-practices.html#cb35-1" tabindex="-1"></a>refutation <span class="op">=</span> model.refute_estimate(identified_estimand, estimate, </span>
<span id="cb35-2"><a href="empirical-practices.html#cb35-2" tabindex="-1"></a>                         method_name<span class="op">=</span><span class="st">&quot;placebo_treatment_refuter&quot;</span>)</span></code></pre></div>
<p>The placebo test here suggests that the original model’s structure is robust, meaning that the observed effect of tutoring on grades is not due to random bias. However, this does not yield out the possibility that the obtained estimate could be biased due to an unmeasured confounder.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="empirical-practices.html#cb36-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Placebo Test Result:&quot;</span>, refutation)</span></code></pre></div>
<pre><code>## Placebo Test Result: Refute: Use a Placebo Treatment
## Estimated effect:17.585373682989484
## New effect:0.0
## p value:2.0</code></pre>
<p>We could ask ourselves too whether the estimated effect changes significantly when we replace the given dataset with bootstrapped samples from the same dataset? (Hint: It should not).</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="empirical-practices.html#cb38-1" tabindex="-1"></a>bootstrap_refutation <span class="op">=</span> model.refute_estimate(identified_estimand, </span>
<span id="cb38-2"><a href="empirical-practices.html#cb38-2" tabindex="-1"></a>                                 estimate, </span>
<span id="cb38-3"><a href="empirical-practices.html#cb38-3" tabindex="-1"></a>                                 method_name<span class="op">=</span><span class="st">&quot;bootstrap_refuter&quot;</span>)</span></code></pre></div>
<p>As seen below, the effect does not deviate much from the original estimated effect. Still, something else could be going on.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="empirical-practices.html#cb39-1" tabindex="-1"></a><span class="bu">print</span>(bootstrap_refutation)</span></code></pre></div>
<pre><code>## Refute: Bootstrap Sample Dataset
## Estimated effect:17.585373682989484
## New effect:17.616872980690538
## p value:0.8</code></pre>
<p>If we suspect about the presence of unknown confounders, we could test how sensitive is the effect estimate when we add an additional common cause (confounder) to the dataset that is correlated with the treatment and the outcome. (Hint: It should not be too sensitive).</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="empirical-practices.html#cb41-1" tabindex="-1"></a>sensitivity_analysis <span class="op">=</span> model.refute_estimate(identified_estimand, </span>
<span id="cb41-2"><a href="empirical-practices.html#cb41-2" tabindex="-1"></a>                      estimate, </span>
<span id="cb41-3"><a href="empirical-practices.html#cb41-3" tabindex="-1"></a>                      method_name<span class="op">=</span><span class="st">&quot;add_unobserved_common_cause&quot;</span>)</span></code></pre></div>
<p>In this case we see a huge drop. This may indicate that we over estimated the effect of <code>tutoring</code> on the <code>grades</code> and that we are missing an important confounder.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="empirical-practices.html#cb42-1" tabindex="-1"></a><span class="bu">print</span>(sensitivity_analysis)</span></code></pre></div>
<pre><code>## Refute: Add an Unobserved Common Cause
## Estimated effect:17.585373682989484
## New effect:3.0797827732011314</code></pre>
<p>At this point we should get back to the design table and see that we missed an important variable. In our case we knew already: <code>Parental involvement</code>. In real life, we would either ask the students again (through new surveys) or if we already had this variable in our surveys we would add it to the model as a confounder affecting the <code>grades</code> and the <code>tutoring</code>. Note that in “our reality” <code>parental involvement</code> did not affect <code>study hours</code> directly.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="empirical-practices.html#cb44-1" tabindex="-1"></a><span class="co"># Realize missing confounder: Parental involvement</span></span>
<span id="cb44-2"><a href="empirical-practices.html#cb44-2" tabindex="-1"></a>model_v2 <span class="op">=</span> CausalModel(</span>
<span id="cb44-3"><a href="empirical-practices.html#cb44-3" tabindex="-1"></a>    data<span class="op">=</span>data,</span>
<span id="cb44-4"><a href="empirical-practices.html#cb44-4" tabindex="-1"></a>    treatment<span class="op">=</span><span class="st">&quot;tutoring&quot;</span>,</span>
<span id="cb44-5"><a href="empirical-practices.html#cb44-5" tabindex="-1"></a>    outcome<span class="op">=</span><span class="st">&quot;grade&quot;</span>,</span>
<span id="cb44-6"><a href="empirical-practices.html#cb44-6" tabindex="-1"></a>    common_causes<span class="op">=</span>[<span class="st">&quot;study_hours&quot;</span>, <span class="st">&quot;parental_involvement&quot;</span>])</span>
<span id="cb44-7"><a href="empirical-practices.html#cb44-7" tabindex="-1"></a></span>
<span id="cb44-8"><a href="empirical-practices.html#cb44-8" tabindex="-1"></a><span class="co"># Visualize the causal graph</span></span>
<span id="cb44-9"><a href="empirical-practices.html#cb44-9" tabindex="-1"></a>model_v2.view_model(size<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">3</span>))</span>
<span id="cb44-10"><a href="empirical-practices.html#cb44-10" tabindex="-1"></a>plt.tight_layout(w_pad<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="POSDE_bookdown_files/figure-html/unnamed-chunk-45-5.png" width="768" /></p>
<p>We then re-run our estimation.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="empirical-practices.html#cb45-1" tabindex="-1"></a>identified_estimand_with_confounder <span class="op">=</span> model_v2.identify_effect()</span>
<span id="cb45-2"><a href="empirical-practices.html#cb45-2" tabindex="-1"></a>estimate_with_confounder <span class="op">=</span> model_v2.estimate_effect(</span>
<span id="cb45-3"><a href="empirical-practices.html#cb45-3" tabindex="-1"></a>  identified_estimand_with_confounder,</span>
<span id="cb45-4"><a href="empirical-practices.html#cb45-4" tabindex="-1"></a>  method_name<span class="op">=</span><span class="st">&quot;backdoor.linear_regression&quot;</span>)</span></code></pre></div>
<p>As can be seen, this value is closer to the degree of our synthetic data <code>10 * data["tutoring"]</code>. Still, in real world scenarios we do not necessarily know the functions that describe the behaviour of real world phenomena.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="empirical-practices.html#cb46-1" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Estimated Effect (revised model):&quot;</span>, </span>
<span id="cb46-2"><a href="empirical-practices.html#cb46-2" tabindex="-1"></a>      estimate_with_confounder.value)</span></code></pre></div>
<pre><code>## Estimated Effect (revised model): 10.095828768814414</code></pre>
<!-- [write]


<!--
[write]

https://www.technologyreview.com/2019/02/04/137602/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix/

-->
<!--
## Takeaway Messages


-->

</div>
</div>
</div>
<h3> References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-bunge2012method" class="csl-entry">
Bunge, Mario. 2012. <em>Method, Model and Matter</em>. Vol. 44. Springer Science &amp; Business Media.
</div>
<div id="ref-bunge2017philosophy" class="csl-entry">
———. 2017. <em>Philosophy of Science: Volume 2, from Explanation to Justification</em>. Routledge.
</div>
<div id="ref-dinardo2010natural" class="csl-entry">
DiNardo, John. 2010. <span>“Natural Experiments and Quasi-Natural Experiments.”</span> In <em>Microeconometrics</em>, 139–53. Springer.
</div>
<div id="ref-domingos2012few" class="csl-entry">
Domingos, Pedro. 2012. <span>“A Few Useful Things to Know about Machine Learning.”</span> <em>Communications of the ACM</em> 55 (10): 78–87.
</div>
<div id="ref-sep-models-science" class="csl-entry">
Frigg, Roman, and Stephan Hartmann. 2020. <span>“<span class="nocase">Models in Science</span>.”</span> In <em>The <span>Stanford</span> Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, <span>S</span>pring 2020. <a href="https://plato.stanford.edu/archives/spr2020/entries/models-science/" class="uri">https://plato.stanford.edu/archives/spr2020/entries/models-science/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-hansen2020systematic" class="csl-entry">
Hansen, Jesper Asring, and Lars Tummers. 2020. <span>“A Systematic Review of Field Experiments in Public Administration.”</span> <em>Public Administration Review</em> 80 (6): 921–31.
</div>
<div id="ref-hershey1991digging" class="csl-entry">
Hershey, David R. 1991. <span>“Digging Deeper into Helmont’s Famous Willow Tree Experiment.”</span> <em>The American Biology Teacher</em> 53 (8): 458–60.
</div>
<div id="ref-applied_stats_healthcare" class="csl-entry">
Montelpare, William J. 2021. <em>Applied Statistics in Healthcare Research</em>. University of Prince Edward Island.
</div>
<div id="ref-pearl2000causality" class="csl-entry">
Pearl, Judea. 2000. <span>“Causality: Models, Reasoning and Inference Cambridge University Press.”</span> <em>Cambridge, MA, USA</em> 9: 10–11.
</div>
<div id="ref-book-of-why" class="csl-entry">
Pearl, Judea, and Dana Mackenzie. 2018. <em>The Book of Why: The New Science of Cause and Effect</em>. 1st ed. USA: Basic Books, Inc.
</div>
<div id="ref-pokropek2016introduction" class="csl-entry">
Pokropek, Artur. 2016. <span>“Introduction to Instrumental Variables and Their Application to Large-Scale Assessment Data.”</span> <em>Large-Scale Assessments in Education</em> 4 (1): 1–20.
</div>
<div id="ref-rossi1985evaluation" class="csl-entry">
Rossi, Peter H, Howard E Freeman, and Sonia R Wright. 1985. <span>“Evaluation: A Systematic Approach. Beverly Hills.”</span> CA: sage.
</div>
<div id="ref-de2021conceptualising" class="csl-entry">
Vocht, Frank de, Srinivasa Vittal Katikireddi, Cheryl McQuire, Kate Tilling, Matthew Hickman, and Peter Craig. 2021. <span>“Conceptualising Natural and Quasi Experiments in Public Health.”</span> <em>BMC Medical Research Methodology</em> 21 (1): 1–8.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="scientific-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="stats-abuse.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["POSDE_bookdown.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
