<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Empirical Practices and Models | Applied Philosophy of Science and Data Ethics</title>
  <meta name="description" content="A tutorial and working resources for writing open-source textbooks using open-source tools" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Empirical Practices and Models | Applied Philosophy of Science and Data Ethics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A tutorial and working resources for writing open-source textbooks using open-source tools" />
  <meta name="github-repo" content="carlosvega/PoS-DE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Empirical Practices and Models | Applied Philosophy of Science and Data Ethics" />
  
  <meta name="twitter:description" content="A tutorial and working resources for writing open-source textbooks using open-source tools" />
  

<meta name="author" content="Dr. Carlos Vega" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="scientific-inference.html"/>
<link rel="next" href="stats-abuse.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-79429674-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-79429674-2');
</script>


<script type="text/javascript">
mattcrump=1;
</script>
 -->



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Philosophy of Science and Data Ethics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html"><i class="fa fa-check"></i><b>1</b> Scientific Goals, Methods and Knowledge</a>
<ul>
<li class="chapter" data-level="1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#what-is-science"><i class="fa fa-check"></i><b>1.1</b> What is Science?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#scientific-goals-and-knowledge"><i class="fa fa-check"></i><b>1.1.1</b> Scientific Goals and Knowledge</a>
<ul>
<li class="chapter" data-level="1.1.1.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#data-information-and-knowledge"><i class="fa fa-check"></i><b>1.1.1.1</b> Data, information and knowledge</a></li>
</ul></li>
<li class="chapter" data-level="1.1.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#what-is-philosophy-of-science"><i class="fa fa-check"></i><b>1.1.2</b> What is Philosophy of Science?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#sci-method"><i class="fa fa-check"></i><b>1.2</b> The scientific method</a></li>
<li class="chapter" data-level="1.3" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#methodology"><i class="fa fa-check"></i><b>1.3</b> Methodology</a></li>
<li class="chapter" data-level="1.4" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#examples"><i class="fa fa-check"></i><b>1.4</b> Examples</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#neptune-vulcan"><i class="fa fa-check"></i><b>1.4.1</b> Neptune and Vulcan</a></li>
<li class="chapter" data-level="1.4.2" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#michelson-morley"><i class="fa fa-check"></i><b>1.4.2</b> The most famous “failed” experiment</a></li>
<li class="chapter" data-level="1.4.3" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#eddington-expeditions"><i class="fa fa-check"></i><b>1.4.3</b> Eddington expeditions</a></li>
<li class="chapter" data-level="1.4.4" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#smoke-debate"><i class="fa fa-check"></i><b>1.4.4</b> The smoke debate</a></li>
<li class="chapter" data-level="1.4.5" data-path="scientific-goals-methods-and-knowledge.html"><a href="scientific-goals-methods-and-knowledge.html#kekulés-dream"><i class="fa fa-check"></i><b>1.4.5</b> Kekulé’s dream</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="scientific-inference.html"><a href="scientific-inference.html"><i class="fa fa-check"></i><b>2</b> Scientific Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="scientific-inference.html"><a href="scientific-inference.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="scientific-inference.html"><a href="scientific-inference.html#types-of-inferences"><i class="fa fa-check"></i><b>2.2</b> Types of inferences</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="scientific-inference.html"><a href="scientific-inference.html#deduction-and-induction"><i class="fa fa-check"></i><b>2.2.1</b> Deduction and Induction</a></li>
<li class="chapter" data-level="2.2.2" data-path="scientific-inference.html"><a href="scientific-inference.html#modus"><i class="fa fa-check"></i><b>2.2.2</b> Modus ponens and Modus tollens</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="scientific-inference.html"><a href="scientific-inference.html#problem-induction"><i class="fa fa-check"></i><b>2.3</b> The problem(s) of induction</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="scientific-inference.html"><a href="scientific-inference.html#david-humes-problem-of-induction"><i class="fa fa-check"></i><b>2.3.1</b> David Hume’s Problem of Induction</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="scientific-inference.html"><a href="scientific-inference.html#the-hypothetico-deductive-method"><i class="fa fa-check"></i><b>2.4</b> The Hypothetico-deductive Method</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="scientific-inference.html"><a href="scientific-inference.html#a-good-hypothesis"><i class="fa fa-check"></i><b>2.4.1</b> A good hypothesis</a></li>
<li class="chapter" data-level="2.4.2" data-path="scientific-inference.html"><a href="scientific-inference.html#falsification"><i class="fa fa-check"></i><b>2.4.2</b> Falsification</a></li>
<li class="chapter" data-level="2.4.3" data-path="scientific-inference.html"><a href="scientific-inference.html#confirmation"><i class="fa fa-check"></i><b>2.4.3</b> Confirmation</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="scientific-inference.html"><a href="scientific-inference.html#other-types-of-inference"><i class="fa fa-check"></i><b>2.5</b> Other types of inference</a></li>
<li class="chapter" data-level="2.6" data-path="scientific-inference.html"><a href="scientific-inference.html#non-monotonic-logic-and-defeasible-reasoning"><i class="fa fa-check"></i><b>2.6</b> Non-Monotonic logic and defeasible reasoning</a></li>
<li class="chapter" data-level="2.7" data-path="scientific-inference.html"><a href="scientific-inference.html#explanation"><i class="fa fa-check"></i><b>2.7</b> Explanation</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="scientific-inference.html"><a href="scientific-inference.html#explanation-and-causality"><i class="fa fa-check"></i><b>2.7.1</b> Explanation and causality</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="scientific-inference.html"><a href="scientific-inference.html#examples-1"><i class="fa fa-check"></i><b>2.8</b> Examples</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="scientific-inference.html"><a href="scientific-inference.html#semmelweis"><i class="fa fa-check"></i><b>2.8.1</b> The problem is in your hands!</a>
<ul>
<li class="chapter" data-level="2.8.1.1" data-path="scientific-inference.html"><a href="scientific-inference.html#how-a-hypothesis-is-tested"><i class="fa fa-check"></i><b>2.8.1.1</b> How a hypothesis is tested</a></li>
</ul></li>
<li class="chapter" data-level="2.8.2" data-path="scientific-inference.html"><a href="scientific-inference.html#wason"><i class="fa fa-check"></i><b>2.8.2</b> Wason selection task</a></li>
<li class="chapter" data-level="2.8.3" data-path="scientific-inference.html"><a href="scientific-inference.html#u.s.a.-presidents"><i class="fa fa-check"></i><b>2.8.3</b> U.S.A. Presidents</a></li>
<li class="chapter" data-level="2.8.4" data-path="scientific-inference.html"><a href="scientific-inference.html#yersinia-pestis"><i class="fa fa-check"></i><b>2.8.4</b> Yersinia pestis</a></li>
<li class="chapter" data-level="2.8.5" data-path="scientific-inference.html"><a href="scientific-inference.html#risks-of-induction-and-non-epistemic-values-in-ml"><i class="fa fa-check"></i><b>2.8.5</b> Risks of induction and non-epistemic values in ML</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="empirical-practices.html"><a href="empirical-practices.html"><i class="fa fa-check"></i><b>3</b> Empirical Practices and Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="empirical-practices.html"><a href="empirical-practices.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="empirical-practices.html"><a href="empirical-practices.html#what-is-an-experiment"><i class="fa fa-check"></i><b>3.2</b> What is an experiment?</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="empirical-practices.html"><a href="empirical-practices.html#observational-studies"><i class="fa fa-check"></i><b>3.2.1</b> Observational studies</a>
<ul>
<li class="chapter" data-level="3.2.1.1" data-path="empirical-practices.html"><a href="empirical-practices.html#observability"><i class="fa fa-check"></i><b>3.2.1.1</b> Observability</a></li>
<li class="chapter" data-level="3.2.1.2" data-path="empirical-practices.html"><a href="empirical-practices.html#indicators"><i class="fa fa-check"></i><b>3.2.1.2</b> Indicators</a></li>
<li class="chapter" data-level="3.2.1.3" data-path="empirical-practices.html"><a href="empirical-practices.html#data-and-evidence"><i class="fa fa-check"></i><b>3.2.1.3</b> Data and Evidence</a></li>
</ul></li>
<li class="chapter" data-level="3.2.2" data-path="empirical-practices.html"><a href="empirical-practices.html#field-laboratory-and-simulation-experiments"><i class="fa fa-check"></i><b>3.2.2</b> Field, laboratory and simulation experiments</a></li>
<li class="chapter" data-level="3.2.3" data-path="empirical-practices.html"><a href="empirical-practices.html#how-to-evaluate-experiment-success"><i class="fa fa-check"></i><b>3.2.3</b> How to evaluate experiment success</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="empirical-practices.html"><a href="empirical-practices.html#scientific-models"><i class="fa fa-check"></i><b>3.3</b> Scientific models</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="empirical-practices.html"><a href="empirical-practices.html#differences-between-models-and-experiments"><i class="fa fa-check"></i><b>3.3.1</b> Differences between Models and Experiments</a></li>
<li class="chapter" data-level="3.3.2" data-path="empirical-practices.html"><a href="empirical-practices.html#what-makes-a-good-model"><i class="fa fa-check"></i><b>3.3.2</b> What makes a good model?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="empirical-practices.html"><a href="empirical-practices.html#examples-2"><i class="fa fa-check"></i><b>3.4</b> Examples</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="empirical-practices.html"><a href="empirical-practices.html#john-snow"><i class="fa fa-check"></i><b>3.4.1</b> 1854 Broad Street cholera outbreak</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="stats-abuse.html"><a href="stats-abuse.html"><i class="fa fa-check"></i><b>4</b> Statistical abuse, Biases and Confounders</a>
<ul>
<li class="chapter" data-level="4.1" data-path="stats-abuse.html"><a href="stats-abuse.html#overview-2"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="stats-abuse.html"><a href="stats-abuse.html#experimental-control"><i class="fa fa-check"></i><b>4.2</b> Experimental Control</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="stats-abuse.html"><a href="stats-abuse.html#other-experimental-control-techniques"><i class="fa fa-check"></i><b>4.2.1</b> Other experimental control techniques</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="stats-abuse.html"><a href="stats-abuse.html#randomised-control-trials"><i class="fa fa-check"></i><b>4.3</b> Randomised Control Trials</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="stats-abuse.html"><a href="stats-abuse.html#origins-of-rcts"><i class="fa fa-check"></i><b>4.3.1</b> Origins of RCTs</a></li>
<li class="chapter" data-level="4.3.2" data-path="stats-abuse.html"><a href="stats-abuse.html#validity"><i class="fa fa-check"></i><b>4.3.2</b> Validity</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="stats-abuse.html"><a href="stats-abuse.html#cross-validation-in-machine-learning"><i class="fa fa-check"></i><b>4.4</b> Cross-validation in Machine Learning</a></li>
<li class="chapter" data-level="4.5" data-path="stats-abuse.html"><a href="stats-abuse.html#data-is-not-enough"><i class="fa fa-check"></i><b>4.5</b> Data alone is not enough</a></li>
<li class="chapter" data-level="4.6" data-path="stats-abuse.html"><a href="stats-abuse.html#bias-and-confounders"><i class="fa fa-check"></i><b>4.6</b> Bias and Confounders</a>
<ul>
<li class="chapter" data-level="4.6.0.1" data-path="stats-abuse.html"><a href="stats-abuse.html#confirmation-bias"><i class="fa fa-check"></i><b>4.6.0.1</b> Confirmation bias</a></li>
<li class="chapter" data-level="4.6.0.2" data-path="stats-abuse.html"><a href="stats-abuse.html#selection-bias"><i class="fa fa-check"></i><b>4.6.0.2</b> Selection bias</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="stats-abuse.html"><a href="stats-abuse.html#visualizations-can-lie"><i class="fa fa-check"></i><b>4.7</b> Visualizations can lie</a></li>
<li class="chapter" data-level="4.8" data-path="stats-abuse.html"><a href="stats-abuse.html#more"><i class="fa fa-check"></i><b>4.8</b> More…</a></li>
<li class="chapter" data-level="4.9" data-path="stats-abuse.html"><a href="stats-abuse.html#examples-3"><i class="fa fa-check"></i><b>4.9</b> Examples</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="stats-abuse.html"><a href="stats-abuse.html#covid-israel"><i class="fa fa-check"></i><b>4.9.1</b> Covid-19: How can efficacy versus severe disease be strong when 60% of hospitalized are vaccinated?</a></li>
<li class="chapter" data-level="4.9.2" data-path="stats-abuse.html"><a href="stats-abuse.html#viz-hurricane"><i class="fa fa-check"></i><b>4.9.2</b> Misinterpretations of hurricane forecast maps</a></li>
<li class="chapter" data-level="4.9.3" data-path="stats-abuse.html"><a href="stats-abuse.html#the-smoke-debate-part-ii"><i class="fa fa-check"></i><b>4.9.3</b> The smoke debate (part II)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ethics-and-responsibility.html"><a href="ethics-and-responsibility.html"><i class="fa fa-check"></i><b>5</b> Ethics and Responsibility</a></li>
<li class="chapter" data-level="6" data-path="wont-fix.html"><a href="wont-fix.html"><i class="fa fa-check"></i><b>6</b> Extra Material</a>
<ul>
<li class="chapter" data-level="6.1" data-path="wont-fix.html"><a href="wont-fix.html#history-of-science"><i class="fa fa-check"></i><b>6.1</b> History of science</a></li>
<li class="chapter" data-level="6.2" data-path="wont-fix.html"><a href="wont-fix.html#theory-relatedness-of-observations"><i class="fa fa-check"></i><b>6.2</b> Theory-relatedness of observations</a></li>
<li class="chapter" data-level="6.3" data-path="wont-fix.html"><a href="wont-fix.html#gettier-problems"><i class="fa fa-check"></i><b>6.3</b> Gettier problems</a></li>
<li class="chapter" data-level="6.4" data-path="wont-fix.html"><a href="wont-fix.html#realism"><i class="fa fa-check"></i><b>6.4</b> Realism and anti-realism</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Philosophy of Science and Data Ethics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="empirical-practices" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Empirical Practices and Models</h1>
<div class="notebox">
<div class="center">
<p><strong>Course Note:</strong></p>
</div>
<p>This chapter is under construction. Some content is hidden.</p>
</div>
<div id="overview-1" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Overview</h2>
<blockquote>
<p><em>Empirical</em>: based on, concerned with, or verifiable by observation or experience rather than theory or pure logic.</p>
</blockquote>
<p>I would like to introduce this chapter in the same way the Book of Why <span class="citation">(<a href="#ref-book-of-why" role="doc-biblioref">Pearl and Mackenzie 2018</a>)</span> introduces its fourth chapter “Slaying the lurking variable”. During the times of Babylonian King Nebuchadnezzar (642 BC - 562 BC), one captive – Daniel – refused to eat royal meat offered by the King as part of their education and service in the court since it did not comply with his religious beliefs. Instead, Daniel asked to be fed on a vegetable diet. The overseer was reluctant as he thought the servants would lose weight and become weaker. Daniel proposed an experiment to convince his overseer. For ten days, one group of servants would be given a vegetable diet, while another group of servants would eat the king’s meat. Then, the overseer would compare both groups and see that the vegetable diet did not reduce their strength. Of course, the experiment was a success, and the king was so impressed that he granted Daniel a favoured place in the court.</p>
<p>This example synthesizes the process of controlled experiments employed nowadays in experimental science. The overseer poses a question, <em>will the vegetarian diet cause my servants to lose weight?</em>. There it is our hypothesis. To address the question, Daniel proposed a methodology. Divide the servants in two identical groups. Give one group a new treatment (e.g. diet or a drug), while another group (control) remains under no special treatment. Of course, the two groups should be comparable and representative of some population in order to transfer the conclusions to the population at large. This process allowed Daniel to show the <em>causal effect</em> (beware, we will tackle this in Chapter <a href="stats-abuse.html#stats-abuse">4</a>) of the diet. Moreover, Daniel’s experiment was prospective (in contrast to retrospective studies) as the groups were chosen in advance. Prospective controlled trials are a common characteristic of sound science. Still, Daniel didn’t think of everything, but we will see that in Chapter <a href="stats-abuse.html#stats-abuse">4</a>.</p>
</div>
<div id="what-is-an-experiment" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> What is an experiment?</h2>
<p>Many data scientists believe their role should be limited to data analysis, but experiment design is fundamental for data collection, which conditions the data to be analysed. Conclusions drawn from data can be biased or determined by decisions and errors taken during experiment design. Understanding this can help you spot issues during the data analysis and ask the right questions to your colleagues in charge of the experiments.</p>
<p>An experiment is an observation process in which we control background variables through manipulation, intervene on target variable (through manipulation) and observe the difference produced by such intervention thanks to measurements.</p>
<blockquote>
<p>Experiment is the kind of scientific experience in which some change is deliberately provoked, and its outcome observed, recorded and interpreted with a cognitive aim. — <span class="citation">(<a href="#ref-bunge2017philosophy" role="doc-biblioref">Bunge 2017</a>)</span></p>
</blockquote>
<!-- consider adding mill's method of difference -->
<div id="observational-studies" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Observational studies</h3>
<p>However, there are whole research areas were scientists cannot make experiments. For instance, astrophysics is mainly observational and theoretical as is not possible to manipulate the observed entities (e.g. stars). It aims to find out measurable implications of physical models. Sometimes is not feasible, legal or ethical to conduct certain types of experiments, conducting observational studies instead. So, in <strong>observational studies</strong> there is no manipulation, no intervention on the target variable, neither control of background variables. <a href="https://en.wikipedia.org/wiki/Natural_experiment"><strong>Natural experiments</strong></a> on the other side share the first two characteristics but is possible to control background variables (but not through manipulation though). See § <a href="empirical-practices.html#john-snow">3.4.1</a> for an example of the latter.</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Definitions:</strong></p>
</div>
<p><strong>Target variables</strong>: The target variable of a dataset is the feature of a dataset about which you want to gain a deeper understanding. They also receive the name “dependent variables” because, in an experiment, their values are studied under the supposition or demand that they depend, by some law or rule (e.g., by a mathematical function), on the values of other variables. The dependent variable is the <em>effect</em>. Its value depends on changes in the independent variable.</p>
<p><strong>Independent variables</strong>:: It is a variable that stands alone and isn’t changed by the other variables you are trying to measure. The independent variable is the <em>cause</em>. Its value is independent of other variables in your study.</p>
<p><strong>Background variables</strong>: An explanatory variable that can affect other (dependent) variables but cannot be affected by them. For example, one’s schooling may affect one’s subsequent career, but the reverse is unlikely to be true.</p>
</div>
<p>We can recognise five elements in the observation process: the <em>object</em> of observation; the <em>subject</em> (or observer) and its perceptions; the <em>circumstances</em> of observation (e.g. environment of object and subject); the observation <em>media</em> (e.g. senses, instruments, procedures); and the body of <em>knowledge</em> used to relate all the previous elements. The last two can be grouped into <em>tools</em> (concrete and conceptual). So, an observation statement has the form “<span class="math inline">\(w\)</span> observes <span class="math inline">\(x\)</span> under <span class="math inline">\(y\)</span> with the help of <span class="math inline">\(z\)</span>”. <span class="citation">(<a href="#ref-bunge2017philosophy" role="doc-biblioref">Bunge 2017</a>)</span></p>
<div id="observability" class="section level4" number="3.2.1.1">
<h4><span class="header-section-number">3.2.1.1</span> Observability</h4>
<p>We can try to define observability by stating that a fact is <em>observable</em> “only if there exists at least one subject, one set of circumstances, and one set of observation tools, such that the fact can appear to the subject armed with those tools under those circumstances” <span class="citation">(<a href="#ref-bunge2017philosophy" role="doc-biblioref">Bunge 2017</a>)</span>. This definition is rather unsatisfactory since someone could claim the existence of ghosts or aliens. We should define what is objectively observable. Then, <span class="math inline">\(x\)</span> is observable only if there exist at least one recording instrument <span class="math inline">\(w\)</span>, one set of circumstances <span class="math inline">\(Y\)</span>, and one set of observation tools <span class="math inline">\(Z\)</span>, such that <span class="math inline">\(w\)</span> can register <span class="math inline">\(x\)</span> under <span class="math inline">\(y\)</span> helped by <span class="math inline">\(z\)</span>. Here we have eliminated the possibility of the subject’s perceptual delusions, but devices (e.g. a camera) have limitations too.</p>
<p>Observations are often expressed in the form of a rule so that other researchers can reproduce their results under similar conditions. Some facts cannot be repeated, such as the eruption of a volcano or a supernova. So very often, we expect results of the same kind to be reproducible by observers. Exact duplication is desirable but not always achievable. Even independent observers may make the same wrong observations due to faulty equipment or false hypotheses.</p>
</div>
<div id="indicators" class="section level4" number="3.2.1.2">
<h4><span class="header-section-number">3.2.1.2</span> Indicators</h4>
<p>Most facts we know about are indirectly observable, i.e. we infer them through an intermediary. For instance, the wind is not directly observable but inferred from bodies apparently moved by it. We <em>objectify</em> an observable fact by establishing its relationship to some perceptible fact(s) that serve us as an <em>indicator</em> of the fact. In other words, hypotheses are made concerning unperceived facts and tested through evidence consisting of data about other directly observable facts, assuming that the latter are <strong>collaterally connected with</strong> or <strong>effects</strong> of the former. Of course, that such relationship should hold is as well a hypothesis (see Figure <a href="empirical-practices.html#fig:indicator">3.1</a>).</p>

<div class="figure" style="text-align: center"><span id="fig:indicator"></span>
<img src="Figures/indicator.png" alt="The physical object-indicator relation, is expressed by a hypothesis enabling us to infer the object from observations made on its indicator. Figure extracted from (Bunge 2017)." width="50%" />
<p class="caption">
Figure 3.1: The physical object-indicator relation, is expressed by a hypothesis enabling us to infer the object from observations made on its indicator. Figure extracted from <span class="citation">(<a href="#ref-bunge2017philosophy" role="doc-biblioref">Bunge 2017</a>)</span>.
</p>
</div>
</div>
<div id="data-and-evidence" class="section level4" number="3.2.1.3">
<h4><span class="header-section-number">3.2.1.3</span> Data and Evidence</h4>
<p>Every evidence is a <em>datum</em> but not every datum constitutes <em>evidence</em>. What turns a datum into evidence is that is relevant to some idea, that it makes sense under some theory or body of knowledge. In particular, we believe a datum constitutes an evidence in favour of a theory and assign the theory some <em>credence</em> because it justifies or predicts that evidence. The evidence must be related to a specific hypothesis, and this relationship is justified because of a body of theoretical knowledge. In fact, no evidence is absolute. Consider the following example from <span class="citation">(<a href="#ref-bunge2017philosophy" role="doc-biblioref">Bunge 2017</a>)</span>:</p>
<blockquote>
<p>The observed deviation of a magnetic needle in the vicinity of an electric circuit (datum <span class="math inline">\(e\)</span>) supports the hypothesis <span class="math inline">\(h_x\)</span> that electricity is flowing through the circuit, on the theory <span class="math inline">\(⊤_1\)</span> that electric currents produce magnetic fields which in turn interact with the fields of magnetic needles. But exactly the same datum <span class="math inline">\(e\)</span> might be taken as an evidence in favour of the rival hypothesis <span class="math inline">\(h_2\)</span> that a big magnet somewhere nearby has been switched on, on the theory <span class="math inline">\(⊤_2\)</span> that magnets can interact directly with one another. The given datum is then <em>ambiguous</em> and only an independent checking of <span class="math inline">\(h_x\)</span> and <span class="math inline">\(h_2\)</span>, i.e. a test independent of <span class="math inline">\(e\)</span>, will enable us to reach a decision between the two rivals.</p>
</blockquote>
<p>Importantly, the characteristics that make data count as evidence must be agreed prior to observation and on the basis of theory. Sometimes a scientist may obtain data that seems incompatible with a theory. Instead of getting rid of such data (or the theory), the scientist will attempt to reproduce the data and assess whether is anomalous data (e.g. due to a faulty instrument) or not. The <em>raw</em> data may contain any information, but <em>refined</em> data should express only relevant and useful information for the problem at hand. Of course, some information is always lost in the process. In consequence, the refinement process is irreversible. Data are <em>means</em> rather than <em>ends</em> and we aim to systematise data in order to disclose patterns on it. For this reason <em>noise</em> must be removed. The systematization of refined data may involve displaying information in graphs or tables as well as arranging information in data structures such as matrices.</p>
</div>
</div>
<div id="field-laboratory-and-simulation-experiments" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Field, laboratory and simulation experiments</h3>
<p>In contrast to observational experiments, <strong>field experiments</strong> randomly assing the sampling units (e.g. study participants) into two groups (treatment and control) to test causal relationships. The same conditions are maintained for both groups only varying the intervention on the factor of interest (e.g. two parts of soil (fertilized/unfertilized)). The background variables are considered as given and not manipulated. On the other side, <strong>laboratory experiments</strong> construct the same background conditions in both groups manipulating the environment (lab settings) and varying the intervention on the factor of interest. Finally, <strong>simulation experiments</strong> are constructions representing a real system on a computer to perform interventions. This type of experiments are done when is not feasible to experiment on the real entities (e.g. climate simulations or geological simulations).</p>
<p>Therefore, an experiment is a controlled observation in which the observer manipulates the real variables (independent variables) that are believed to influence the outcome (dependent variable), both for the purpose of intervention and control. The following article provides a good description of the <a href="https://opentextbc.ca/researchmethods/chapter/experiment-basics/">basics of experiments</a>.</p>
<p>In Chapter <a href="stats-abuse.html#stats-abuse">4</a> we will see some examples of experimental errors (e.g. confirmation bias, selection bias, etc) as well as examples of statistical abuse. All in all, the experiment process is also a craft which entails learning from previous experiments (ours and others), as well as applying all available knowledge (theoretical and experimental) for the design of experiments.</p>
<div class="tipbox">
<div data-latex="">
<p><strong>Definitions:</strong></p>
</div>
<p><strong>Repetition</strong>: An experiment is repeatable if enough information is provided about the used data and the experiment methods and conditions. With such information, it should be possible to repeat the experiment.</p>
<p><strong>Reproduction</strong>: An experiment is considered as reproduced if the repetition of the experiment yields the same result. For instance, in computer science, reproducing involves using the original data and code.</p>
<p><strong>Replication</strong>: An independent experiment, in the spirit of the original experiment produces the same result. For example, in computer science replication entails collecting new data and use similar methods to reach similar conclusions in answer to the same scientific question. Or implementing a new software following similar design principles and reaching similar results.</p>
</div>
</div>
<div id="how-to-evaluate-experiment-success" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> How to evaluate experiment success</h3>
<p>Very often, success is not defined by a single goal or metric. For instance, the best car is not always the fastest car. In fact, there are many other values to bear in mind, such as gasoline consumption, pollution, ease of manufacture, etc. Similarly an experiment success is rarely assessed with a single metric in mind.</p>
<p>Moreover, some metrics must not be degraded, often called <strong>guardrail metrics</strong>. This type of metrics can include security, speed, robustness, etc. But very often include <em>non-epistemic values</em> too. In this context, non-epistemic values are metrics not directly related to the instance to be designed, such as fairness, justice, or making money (or saving it), in contrast to metrics that make the instance at issue <em>internally</em> or <em>intrinsically</em> better (e.g. speed). For instance, a car is not necessarily a better car depending on its price if what is judged is the <em>car itself</em> in isolation, but a low price might make it easier to sell. In another example, the fastest data processing system might not necessarily be the best choice since other requirements must be considered too (e.g. ease of use).</p>
<p>A non-epistemic value that is always at stake is money, or in a different shape, OPEX (operational expenditure) and CAPEX (capital expenditure). Very often, they condition other metrics, such as performance (e.g. use less/worse resources) or safety (e.g. employ less/worse materials). For example, I had the opportunity to work on the design of enterprise log processing systems. In this case, we wanted to maximise speed while reducing resources, as mid-sized companies often wish to reduce the number of servers deployed, which ultimately affects their operational costs (e.g. space and electricity). Most commercial solutions scale horizontally, requiring the use of on-site server clusters to handle large amounts of data (at prohibitively high prices) or cloud-hosted clusters (impractical due to data protection). Our proposal optimised vertical scalability and coped with tens of millions of events per second with a single server. But of course, such an approach was specifically designed for a particular task, in contrast to the flexibility offered by commercial alternatives.</p>
<p>In data science, success should be defined by how well the analysis answers the research questions. For this reason, setting the research questions at the very beginning of the process remains crucial. They not only determine the data analysis but, more importantly, the data collection design. However, very frequently, the data science process starts with a given dataset. Still, it is essential to assess if the collected data can answer the posed questions.</p>
</div>
</div>
<div id="scientific-models" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Scientific models</h2>
<p>Scientific models are widespread and varied. These include scale models (e.g. plane models for aerodynamic studies), laboratory animals (e.g. mice for drug trials), simulation models (e.g. computational model for weather forecast). In all the previous cases, a model is made to replace or to stand in for what we are ultimately interested in. Models are characterised by being representations, containing idealisations, being purpose dependent, and ready to be manipulated.</p>
<div class="figure" style="text-align: center"><span id="fig:sbml-model"></span>
<img src="Figures/sbml_model.png" alt="Different representations of a biological process. On the right side, the process is encoded in a XML file in Systems Biology Markup Language (SBML) format. " width="100%" />
<p class="caption">
Figure 3.2: Different representations of a biological process. On the right side, the process is encoded in a XML file in Systems Biology Markup Language (SBML) format.
</p>
</div>
<p>For instance, a physical model of DNA on a table represents the real DNA. Obviously, such a model is not a piece of real DNA. It is made of something else (e.g. plastic) and at a different scale. In this case, such a model is useful for pedagogic purposes. Although there are clear differences between models and targets, the key relationship is that <strong>a model represents (in some way) the target</strong>. From the methodological point of view, we must justify why to represent targets with models instead of investigating the targets themselves?. Possible answers include physical impossibility, costs, ethical and legal reasons, etc. However, very often the main justification to employ models is that targets are very complex. Therefore, employing a model that simplifies the target complexity might allow us to get a better understanding of the main factors operating in the target system. Our cognitive limits very often determine how we investigate complex systems, starting with a simpler model and increasing its complexity as we gain understanding.</p>
<p>Therefore, we are intentionally choosing or building a model that differs from the target in some properties. Precisely because of this condition, we cannot assume that whatever is the case in the model is also the case in the target. <strong>Models come with idealisations.</strong> Not bearing in mind this key condition of the models can lead us to produce false claims about the target.</p>
<blockquote>
<ul>
<li><strong>Idealized models.</strong> Idealized models are models that involve a deliberate simplification or distortion of something complicated with the objective of making it more tractable or understandable. Frictionless planes, point masses, completely isolated systems, omniscient and fully rational agents, and markets in perfect equilibrium are well-known examples. Idealizations are a crucial means for science to cope with systems that are too difficult to study in their full complexity.</li>
<li><strong>Scale models.</strong> Some models are down-sized or enlarged copies of their target systems (Black 1962). A typical example is a small wooden car that is put into a wind tunnel to explore the actual car’s aerodynamic properties.</li>
<li><strong>Phenomenological models.</strong> Phenomenological models have been defined in different, although related, ways. A common definition takes them to be models that only represent observable properties of their targets and refrain from postulating hidden mechanisms and the like.</li>
<li><strong>Exploratory models.</strong> Exploratory models are models which are not proposed in the first place to learn something about a specific target system or a particular experimentally established phenomenon.</li>
<li><strong>Models of data.</strong> A model of data (sometimes also “data model”) is a corrected, rectified, regimented, and in many instances idealized version of the data we gain from immediate observation, the so-called raw data. Characteristically, one first eliminates errors (e.g., removes points from the record that are due to faulty observation) and then presents the data in a “neat” way, for instance by drawing a smooth curve through a set of points. These two steps are commonly referred to as “data reduction” and “curve fitting”.
— <span class="citation">(<a href="#ref-sep-models-science" role="doc-biblioref">Frigg and Hartmann 2020</a>)</span></li>
</ul>
</blockquote>
<p>For example, Bohr’s model of the atom assumes that electrons orbit the atomic nucleus in circles. The success of such a model relied that the Bohr assumptions reproduced the series that fitted the hydrogen emission spectra. In 1913 it predicted the correct frequencies of the specific colours of light absorbed and emitted by ionised helium. One could say that Bohr was very lucky as despite his model is wrong in some ways, it also has some bits of truth, enough for his predictions about ionised helium to work out. However, other predictions about the properties of the atom were wrong, and its implications were not observed in experiments. In the Schrödinger model, the electron of a one-electron atom, rather than travelling in fixed orbits around the nucleus, has a probability distribution allowing the electron to be at almost all locations in space, some being much more likely than others. Bohr theory (1913) was rejected in 1925 after the advent of quantum mechanics, but its model remains because despite its flaws and idealisations, <a href="https://blogs.scientificamerican.com/guest-blog/why-it-s-okay-to-teach-wrong-ideas-in-physics/">Bohr’s model is useful for education</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:bohr-model"></span>
<img src="Figures/bohr-atom-model.png" alt="Illustration of bound-bound transition in the Bohr atomic model. Source: Wikipedia Commons." width="40%" />
<p class="caption">
Figure 3.3: Illustration of bound-bound transition in the Bohr atomic model. Source: <a href="https://commons.wikimedia.org/wiki/File:Bohr_atom_model.svg">Wikipedia Commons</a>.
</p>
</div>
<p><strong>Models are as well purpose-dependent</strong>. Suppose the next question. Which benzene model is better? A quantum mechanic model, or a structural formula?. On one side, the quantum mechanic model is more precise about the potential position of electrons. Additionally, is more similar to the target as it represents better its relevant properties. The structural model is simpler and easier to work with. In this case, theoretically tractable models such as structural models allow for functional group analysis in chemistry.</p>

<div class="figure" style="text-align: center"><span id="fig:benzene-model"></span>
<img src="Figures/Benzene_Representations.png" alt="Various representations of Benzene. Source: Wikipedia Commons." width="100%" />
<p class="caption">
Figure 3.4: Various representations of Benzene. Source: <a href="https://en.wikipedia.org/wiki/File:Benzene_Representations.svg">Wikipedia Commons</a>.
</p>
</div>

<div class="figure" style="text-align: center"><span id="fig:benzene-model-evolution"></span>
<img src="Figures/Historic_Benzene_Formulae.png" alt="Historic benzene structures (from left to right) by Claus (1867), Dewar (1867), Ladenburg (1869), Armstrong (1887), Thiele (1899) and Kekulé (1865). Dewar benzene and prismane are distinct molecules that have Dewar’s and Ladenburg’s structures. Thiele and Kekulé’s structures are used today." width="100%" />
<p class="caption">
Figure 3.5: Historic benzene structures (from left to right) by Claus (1867), Dewar (1867), Ladenburg (1869), Armstrong (1887), Thiele (1899) and Kekulé (1865). Dewar benzene and prismane are distinct molecules that have Dewar’s and Ladenburg’s structures. Thiele and Kekulé’s structures are used today.
</p>
</div>
<p>Philosopher Mary Hesse (1924-2016) argued that models act as analogies rather than descriptions of the targets. She distinguished between 3 kinds of analogies. In the first place, she considered that <strong>positive analogies</strong> hold between the aspects of a model and its target for which we have reasons to believe they are similar. An example of positive analogies can be found between mice and humans, which have similar hormone systems and physiology. On the other hand, the idealisations constitute <strong>negative analogies</strong>, such as the differences in size or lifespan between mice and humans. These negative analogies cover the properties in which model and target differ. Finally, <strong>neutral analogies</strong> concern the properties that we cannot investigate directly in the target, requiring the model for their study. For instance, the reaction to a certain drug or treatment of interest. At the initial stage, is not possible to tell whether the model-target relationships concerning these properties constitute positive or negative analogies because we do not know yet how the relevant target properties are affected. Instead, such properties are investigated in the model, and researchers hypothesise that the model is analogous to the target in such properties. For instance, we assume that the effects of a drug in mice will give us knowledge about its effects in humans.</p>
<blockquote>
<p>The positive analogy between two items consists in the properties or relations they share (both gas molecules and billiard balls have mass); the negative analogy consists in the properties they do not share (billiard balls are colored, gas molecules are not); the neutral analogy comprises the properties of which it is not known (yet) whether they belong to the positive or the negative analogy (do billiard balls and molecules have the same cross section in scattering processes?). Neutral analogies play an important role in scientific research because they give rise to questions and suggest new hypotheses. — <span class="citation">(<a href="#ref-sep-models-science" role="doc-biblioref">Frigg and Hartmann 2020</a>)</span></p>
</blockquote>
<p>Consider again the Michelson and Morley experiment. Before the XX century, most physicists considered light as a wave. Their beliefs were justified on the many positive analogies between light, water and sound waves. For instance, light produces a diffraction pattern when encountering an obstacle, just as water and sound waves do. With this model in mind, physicists inferred a neutral analogy, namely, that light needs a medium to travel, as other waves require. They called this medium: luminiferous aether. The experiment from Michelson and Morley is a consequence of such model. However, the experiment revealed that such analogy was indeed a negative analogy, an idealisation. This discovery led people to replace the model of light for more precise models. Therefore, model manipulation allows discovering the effects of neutral analogies.</p>

<div class="figure" style="text-align: center"><span id="fig:aether"></span>
<img src="Figures/luminiferous_aether.png" alt="The luminiferous aether: it was hypothesised that the Earth moves through a &quot;medium&quot; of aether that carries light. Source: Wikipedia Commons." width="50%" />
<p class="caption">
Figure 3.6: The luminiferous aether: it was hypothesised that the Earth moves through a “medium” of aether that carries light. Source: <a href="https://commons.wikimedia.org/wiki/File:AetherWind.svg">Wikipedia Commons</a>.
</p>
</div>
<div id="differences-between-models-and-experiments" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Differences between Models and Experiments</h3>
<p>There are several commonalities between models and experiments. Setting parameters and variables in models resembles experimental control. In the same way, model manipulation is akin to experimental manipulation. Finally, model manipulation yields results that are observed, just as in experimental observations. Notwithstanding, there are also important differences to bear in mind, which mainly concern the source of errors. For instance, the most troubling experimental errors concern internal validity questions, i.e. the degree of confidence that the causal relationship put to test is not influenced by other factors or variables. For these reasons, researchers require careful design and control of experiments. Nonetheless, models are generally less sensitive to these issues since the modeller is aware of the idealisations and mechanisms of its models. For modelling, the key concern is whether the relevant analogies between model and target hold. Such concern is usually not a problem for experiments, especially those conducted directly on the target. Once internal validity is assessed, researchers are confident that the inferences drawn from the experiment refer to the target. However, inferences drawn from model manipulation constitute neutral analogies considered as hypotheses regarding the target, requiring further testing and justification. This last step is error-prone.</p>
</div>
<div id="what-makes-a-good-model" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> What makes a good model?</h3>
<p>Since models are purpose dependent, there is no exhaustive set of sufficient and necessary conditions to define what a good model is. Nonetheless, there are some common criteria (e.g. robustness, simplicity, tractability) that can be balanced, but is often impossible to optimise all criteria at the same because some criteria are complements of each other.</p>
<p>The <strong>similarity</strong> criterion can for example assess physical resemblance. More generally, we could say that a model <span class="math inline">\(M\)</span> is similar to target <span class="math inline">\(X\)</span> if and only if <span class="math inline">\(M\)</span> is similar to <span class="math inline">\(X\)</span> with respect to the set of properties <span class="math inline">\(P\)</span> to a certain degree. However, this definition does not tell us which properties should be optimised. For instance, for a scale model of an air plane aimed at aerodynamic studies, it might be more justified to maximise the similarities of geometric properties over the interior design (e.g. the number of seats might not be relevant since the cabin is closed). Therefore, the purpose of the model justifies maximising one set of properties over another, in particular, the properties that are relevant for the research purpose.</p>
<p><strong>Robustness</strong> expresses how model results are affected by condition changes. Therefore, a model result is robust (w.r.t. some condition) if changing such condition does not alter the result. For example, all properties except one (e.g. plane hull colour) can be kept fixed to test whether painting the plane with a different colour might affect its aerodynamic properties. If the result remains equal, we can say the model is robust with respect to the hull colour. Perhaps such property is not relevant to the research purpose, but that is not enough to justify removing the property.</p>

<div class="figure" style="text-align: center"><span id="fig:prec-vs-acc"></span>
<img src="Figures/prec_vs_acc.png" alt="Accuracy consists of trueness (proximity of measurement results to the true value) and precision (repeatability or reproducibility of the measurement). Source: St. Olaf College." width="66%" />
<p class="caption">
Figure 3.7: Accuracy consists of trueness (proximity of measurement results to the true value) and precision (repeatability or reproducibility of the measurement). Source: <a href="https://wp.stolaf.edu/it/gis-precision-accuracy/">St. Olaf College</a>.
</p>
</div>
<p>Another model criterion to consider is <strong>precision</strong> (w.r.t. parameters). We say that model <span class="math inline">\(M_1\)</span> is more precise than <span class="math inline">\(M_2\)</span> if the parameter specifications of <span class="math inline">\(M_1\)</span> <em>imply</em> those from <span class="math inline">\(M_2\)</span>. This definition is better understood through an example. Consider the following models <span class="math inline">\(M_1\)</span>, <span class="math inline">\(M_2\)</span>, and <span class="math inline">\(M_3\)</span> and below definitions. The first model describes a rate of changes as a function of <span class="math inline">\(X\)</span>. <span class="math inline">\(M_2\)</span> is more precise as describes the rate of changes as a linear function of <span class="math inline">\(X\)</span>. The description of <span class="math inline">\(M_2\)</span> implies the description of <span class="math inline">\(M_1\)</span>. Linear functions of <span class="math inline">\(X\)</span> are a subset of functions of <span class="math inline">\(X\)</span>. Finally, the third model is yet more precise as it indicates an absolute value of the parameter <span class="math inline">\(a\)</span>, reducing the subset of linear functions from the definition of <span class="math inline">\(M_2\)</span> to a particular linear function. Importantly, parameter precision is a property of the model alone, not of the relationship between model and target. Although precision offers potential for high accuracy, it is no warrant for it. For instance, if the actual rate of linear change would be other than <span class="math inline">\(1.2X\)</span>, then the less precise model <span class="math inline">\(M_2\)</span> would be more accurate than <span class="math inline">\(M_3\)</span>. Similarly, if the rate of change would not change linearly, the more general model <span class="math inline">\(M_1\)</span> would be more accurate than the alternatives.</p>
<ul>
<li><span class="math inline">\(M_1: dX/dt = f(X)\)</span></li>
<li><span class="math inline">\(M_2: dX/dt = aX\)</span></li>
<li><span class="math inline">\(M_3: dX/dt = 1.2X\)</span></li>
</ul>
<div class="tipbox">
<div data-latex="">
<p><strong>Note for data scientists!</strong></p>
</div>
<p>Questions regarding scientific models also concern Machine Learning models to a great extent. For example, consider the precision and accuracy criteria. The following paragraph is extracted from <a href="https://dl.acm.org/doi/pdf/10.1145/2347736.2347755">the article “A Few Useful Things to Know About Machine Learning” by Pedro Domingos</a>.</p>
<blockquote>
<p>Everyone in machine learning knows about overfitting, but it comes in many forms that are not immediately obvious. One way to understand overfitting is by decomposing generalization error into bias and variance. Bias is a learner’s tendency to consistently learn the same wrong thing. Variance is the tendency to learn random things irrespective of the real signal. Figure illustrates this by an analogy with throwing darts at a board. A linear learner has high bias, because when the frontier between two classes is not a hyperplane the learner is unable to induce it. Decision trees do not have this problem because they can represent any Boolean function, but on the other hand they can suffer from high variance: decision trees learned on different training sets generated by the same phenomenon are often very different, when in fact they should be the same. Similar reasoning applies to the choice of optimization method: beam search has lower bias than greedy search, but higher variance, because it tries more hypotheses. Thus, contrary to intuition, a more powerful learner is not necessarily better than a less powerful one. — <span class="citation">(<a href="#ref-domingos2012few" role="doc-biblioref">Domingos 2012</a>)</span></p>
</blockquote>
</div>
<p><strong>Simplicity</strong> is often another criteria that affects models. A simpler model might fit very well its purpose. For example, underground maps often misrepresent distances or omit unnecessary details such as roads, monuments, etc. Such simplification is suited for the particular purpose of travelling in the underground but is not useful for other purposes. We can say a model is simpler if it contains less parameters, considers less variables and uses less operations than another model. Therefore, simplicity is a virtue w.r.t. models and not to targets. Is usually a practical criterion that facilitates the model use.</p>
<p>Related to simplicity, we can find <strong>tractability</strong>. We say a model is tractable (w.r.t. a set of rules) if the relevant model result may be obtained by applying certain principles to the model. For instance, models solved through analytical methods (e.g. mathematical proofs) are called analytically tractable in contrast to models for which results can only be approximated through numerical simulations methods. Tractability implies the existence of methods to analyse and solve such models. In this sense, <strong>theoretical tractability</strong> considers theoretical principles to assess the suitability of the model for certain operations. For instance, a structural representation of a chemical compound allows for the application of functional group classification (this is an example of theoretical principle to fulfil). In contrast, a quantum mechanical model is more accurate but does not allow for such operation. Therefore we consider it a less tractable model.</p>
<p>Finally, <strong>transparency</strong> is an epistemic value that assesses the degree to which the model user can cognitively understand how the model result is produced. This criterion is known in artificial intelligence as interpretability and/or explainability. For example, a decision tree is often human-readable while the nature of neural networks creates obfuscated models difficult to interpret. Transparent models allow to back-track the result and understand how it was produced from a given input. A transparent model enables the scientist to check the correctness of the results, which is especially important when employing models developed by third parties.</p>
<p>Again, most of the previous virtues will require certain trade-off. Increasing an epistemic value often entails decreasing another one. Therefore, building or choosing a model requires finding the best trade-off for the model’s purpose.</p>
<!--

Models as mirrors. Models as isolations.

--->
</div>
</div>
<div id="examples-2" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Examples</h2>
<div id="john-snow" class="section level3" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> 1854 Broad Street cholera outbreak</h3>
<!-- [write]

This case is very popular and can be found in several books and posts on-line but I recommend the explanation given in Chapter 7 from The Book of Why [@book-of-why] as the authors also re-formulate the case in causal terms.


### Study about honesty is retracted over fake data

<!--
[write]

https://www.buzzfeednews.com/article/stephaniemlee/dan-ariely-honesty-study-retraction

https://twitter.com/jpsimmon/status/1427628315939049491
-->
<!--
## Takeaway Messages


-->

</div>
</div>
</div>
<h3> References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bunge2017philosophy" class="csl-entry">
Bunge, Mario. 2017. <em>Philosophy of Science: Volume 2, from Explanation to Justification</em>. Routledge.
</div>
<div id="ref-domingos2012few" class="csl-entry">
Domingos, Pedro. 2012. <span>“A Few Useful Things to Know about Machine Learning.”</span> <em>Communications of the ACM</em> 55 (10): 78–87.
</div>
<div id="ref-sep-models-science" class="csl-entry">
Frigg, Roman, and Stephan Hartmann. 2020. <span>“<span class="nocase">Models in Science</span>.”</span> In <em>The <span>Stanford</span> Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, <span>S</span>pring 2020. <a href="https://plato.stanford.edu/archives/spr2020/entries/models-science/">https://plato.stanford.edu/archives/spr2020/entries/models-science/</a>; Metaphysics Research Lab, Stanford University.
</div>
<div id="ref-book-of-why" class="csl-entry">
Pearl, Judea, and Dana Mackenzie. 2018. <em>The Book of Why: The New Science of Cause and Effect</em>. 1st ed. USA: Basic Books, Inc.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="scientific-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="stats-abuse.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["POSDE_bookdown.pdf"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
